{
  "timestamp": 1750803750.9424493,
  "input_path": "reasoning_tree.json",
  "output_path": "reasoning_tree_validated.json",
  "validated_data": {
    "Phase 1: Foundational Framework and Core Orchestrator": {
      "Task 1.1: Initialize core project structure, including package.json, tsconfig.json, and dependency management.": [
        {
          "step 1": "Initialize a new Node.js project. Use the `npm init -y` command to create a default `package.json` file. This will serve as the manifest for our project, defining its metadata and dependencies.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Use the `npm init -y` command"
              ],
              "key_entities_dependencies": [
                "`package.json` file"
              ],
              "technology_hints": [
                "Node.js",
                "npm"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a `package.json` is the foundational action for initializing a Node.js project, directly contributing to the task of setting up the core project structure.",
              "sequence_critique": "The sequence is logical. Initializing the project with `npm init` is the correct first step before managing dependencies or configuring TypeScript, which would be subsequent steps within this task.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the exact command (`npm init -y`) to be executed, ensuring an AI agent can perform the task without ambiguity."
            }
          }
        },
        {
          "step 2": "Install the necessary TypeScript-related development dependencies. Use npm to install `typescript`, `ts-node`, and `@types/node`. These are required for compiling and running our TypeScript code. Ensure they are saved as dev dependencies. Command: `npm install --save-dev typescript ts-node @types/node`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "npm install --save-dev typescript ts-node @types/node"
              ],
              "key_entities_dependencies": [],
              "technology_hints": [
                "npm",
                "typescript",
                "ts-node",
                "@types/node"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Installing core TypeScript development dependencies is a fundamental and necessary action for the task of initializing a TypeScript-based project, which directly supports building the foundational framework.",
              "sequence_critique": "The logical sequence is correct, assuming a preceding step has already initialized a `package.json` file (e.g., via `npm init`). The `npm install` command requires `package.json` to exist in order to save the dependencies.",
              "clarity_critique": "The step is exceptionally clear and actionable. It explicitly states the purpose, the exact packages to install, the dependency type (`--save-dev`), and provides the precise command, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 3": "Create the TypeScript configuration file, `tsconfig.json`, in the project root. This file specifies the compiler options required to compile the project. Populate it with a modern, strict configuration suitable for a Node.js backend application. Use the following configuration: \n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"CommonJS\",\n    \"rootDir\": \"./src\",\n    \"outDir\": \"./dist\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"resolveJsonModule\": true,\n    \"sourceMap\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"**/*.spec.ts\", \"**/*.test.ts\"]\n}",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tsconfig.json",
                "./src",
                "./dist",
                "node_modules",
                "**/*.spec.ts",
                "**/*.test.ts"
              ],
              "technology_hints": [
                "TypeScript",
                "tsconfig.json",
                "Node.js",
                "ES2022",
                "CommonJS"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned with the task of initializing the project structure. The specified configuration (strict, modern) supports the overall goal of building a robust, production-ready framework by enforcing high code quality standards from the beginning.",
              "sequence_critique": "The step's placement is generally logical. However, the configuration references a `src` directory (`\"rootDir\": \"./src\"` and `\"include\": [\"src/**/*\"]`). A prerequisite step to create the `src` directory should exist before this step to ensure the project structure is valid.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the exact filename, location, and verbatim content, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 4": "Create the core source directory structure as defined in `tsconfig.json`. Create a directory named `src` in the project root. Inside the `src` directory, create an initial entry point file named `index.ts`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tsconfig.json",
                "src",
                "index.ts"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of initializing the core project structure. Creating the `src` directory and an initial `index.ts` file is a fundamental and necessary action for setting up a TypeScript-based application, which the orchestrator framework is.",
              "sequence_critique": "The sequence is logical. This step correctly assumes that configuration files like `tsconfig.json` (which would define the source directory) have been created in prior steps, as implied by the parent task's description. Creating the directory before the file within it is the correct order.",
              "clarity_critique": "The step is clear and actionable. It provides both the high-level context ('as defined in `tsconfig.json`') and the specific, unambiguous commands ('Create a directory named `src`... create a file named `index.ts`'). This combination makes the instruction robust and easy for an AI agent to execute without misinterpretation."
            }
          }
        },
        {
          "step 5": "Populate the `src/index.ts` file with a simple 'Hello, World!' style message to verify that the project setup works. Add the following code: `console.log('Autonomous Software Development Framework Orchestrator starting up...');`",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/index.ts",
                "console.log"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Adding a simple log message to the main entry point is a standard and effective way to verify that the core project setup (compiler configuration, package scripts) from the preceding steps is functional before building more complex logic.",
              "sequence_critique": "The step's position as a final verification action within the project initialization task is logical. It correctly assumes that prerequisite steps, such as creating the `src/index.ts` file, have already been completed.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the exact file path and the precise code content to be added, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 6": "Install additional development tooling for a better developer experience. Install `nodemon` as a dev dependency to automatically restart the application on file changes. Command: `npm install --save-dev nodemon`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Install `nodemon` as a dev dependency using the command: `npm install --save-dev nodemon`"
              ],
              "key_entities_dependencies": [],
              "technology_hints": [
                "nodemon",
                "npm"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned. Installing `nodemon` is a standard and logical action for setting up the development environment of the orchestrator itself, directly contributing to the task of initializing the core project structure for a better developer experience.",
              "sequence_critique": "The sequence appears logical. Installing development-specific tooling like `nodemon` typically follows the initial creation of `package.json` and installation of core dependencies, which is appropriate for a setup task.",
              "clarity_critique": "The step is perfectly clear and actionable. It explicitly states the tool to install (`nodemon`), its purpose (auto-restarting on file changes), and provides the exact command to execute."
            }
          }
        },
        {
          "step 7": "Update the `scripts` section of your `package.json` file to include commands for building, starting, and developing the application. Add the following scripts:\n- `\"build\": \"tsc\"`\n- `\"start\": \"node dist/index.js\"`\n- `\"dev\": \"nodemon --watch 'src/**/*.ts' --exec 'ts-node' src/index.ts\"`",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "package.json",
                "dist/index.js",
                "src/index.ts"
              ],
              "technology_hints": [
                "tsc",
                "node",
                "nodemon",
                "ts-node"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned. Adding standard build, start, and development scripts is a fundamental part of initializing a modern TypeScript project, which is the stated goal of the task. This directly supports the creation of the foundational framework.",
              "sequence_critique": "The step is logically placed, assuming that preceding steps have already initialized the `package.json` file and installed the necessary dev dependencies (`typescript`, `ts-node`, `nodemon`). The `start` script correctly depends on the output of the `build` script, which is a standard and logical convention.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the target file (`package.json`), the section to modify (`scripts`), and provides the exact key-value pairs to be added, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 8": "Create a `.gitignore` file in the project root to prevent common generated files, sensitive information, and local dependencies from being committed to version control. Add the following entries:\n/node_modules\n/dist\n.env\nnpm-debug.log\n.DS_Store",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                ".gitignore",
                "/node_modules",
                "/dist",
                ".env",
                "npm-debug.log",
                ".DS_Store"
              ],
              "technology_hints": [
                "git",
                "npm"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a `.gitignore` file is a fundamental and necessary action for the task of initializing a core project structure, ensuring proper version control hygiene for the overall framework development.",
              "sequence_critique": "The step is logically placed. While it could be done at any point during initial setup, its inclusion within this task is standard practice. There are no prerequisite or ordering issues.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to create, its location (`project root`), and provides the precise content to include, making it unambiguous for an AI agent to execute."
            }
          }
        },
        {
          "step 9": "Install the first core production dependency, `zod`. This library will be fundamental for enforcing the 'Schema-Enforced Communication' principle outlined in the system architecture. Command: `npm install zod`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "npm install zod"
              ],
              "key_entities_dependencies": [
                "zod"
              ],
              "technology_hints": [
                "zod",
                "npm"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Installing `zod` directly supports the 'Schema-Enforced Communication' principle, which is a foundational pillar of the overall goal. It is a logical and necessary dependency for the current task of setting up the core project framework.",
              "sequence_critique": "The sequence is logical. As a foundational library for the entire system's communication protocol, installing `zod` early in the project setup phase is appropriate, assuming preceding steps have initialized the `package.json` file.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides both the rationale for the action and the precise, unambiguous command (`npm install zod`) for an AI agent to execute."
            }
          }
        }
      ],
      "Task 1.2: Define all core JSON schemas (Reasoning Tree, Module Contract, Contract Document, Builder Output).": [
        {
          "step 1": "Create a new directory `src/schemas` to house all the JSON schema definitions and their corresponding TypeScript types for the project.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "`src/schemas` directory"
              ],
              "technology_hints": [
                "JSON schema",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dedicated directory is a foundational and necessary organizational step for defining the core schemas, which is a key principle ('Schema-Enforced Communication') of the overall project goal.",
              "sequence_critique": "The sequence is logical. Creating a directory to house the schema files is the correct first step before the subsequent steps of defining and writing those files.",
              "clarity_critique": "The instruction is clear, specific, and immediately actionable. It specifies the exact directory path (`src/schemas`) and its intended purpose, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "Create a new file named `src/schemas/reasoning_tree.schema.ts`. In this file, define and export a JSON schema constant named `REASONING_TREE_NODE_SCHEMA`. This schema will represent a node in the hierarchical plan. According to the system overview, this plan is a tree of Goal -> Phases -> Tasks -> Steps. A node should have the following properties:\n- `type`: A string enum that can be one of 'goal', 'phase', 'task', or 'step'.\n- `description`: A string detailing the node's purpose.\n- `children`: An array of child nodes, which should recursively conform to this same schema.\nAfter defining the schema, also define and export a corresponding TypeScript type `ReasoningTreeNode` for use within the orchestrator. The root of a complete plan will be a single `ReasoningTreeNode` of type 'goal'.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/reasoning_tree.schema.ts",
                "REASONING_TREE_NODE_SCHEMA",
                "ReasoningTreeNode"
              ],
              "technology_hints": [
                "JSON schema",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the `REASONING_TREE_NODE_SCHEMA` is a critical and foundational action for implementing the 'Hierarchical Planning' stage (Stage 0) and enforcing the 'Schema-Enforced Communication' principle. The specified properties (`type`, `description`, `children`) directly map to the requirements outlined in the system overview.",
              "sequence_critique": "The sequence is logical. Defining the schema for the first artifact in the system's workflow (`reasoning_tree.json`) is a sensible starting point for the parent task of defining all core schemas.",
              "clarity_critique": "The step is highly clear and actionable. The instructions on file naming, constant naming, properties, and types are specific and unambiguous. The inclusion of the corresponding TypeScript type (`ReasoningTreeNode`) is a good practice for internal system consistency."
            }
          }
        },
        {
          "step 3": "Create a new file named `src/schemas/module_contract.schema.ts`. In this file, you will define the most critical schema: `MODULE_CONTRACT_SCHEMA`. This schema is the blueprint for a single, isolated software module. Based on the system architecture document, define and export it as a JSON schema constant with the following properties:\n- `moduleName`: A string for the module's unique identifier (e.g., 'AuthenticationService').\n- `purpose`: A detailed string explaining what the module does.\n- `dependencies`: An array of strings, where each string is the `moduleName` of another module this one depends on.\n- `constructorParams`: An array of objects, each with `name` (string) and `type` (string, e.g., 'AuthenticationService'), describing parameters for dependency injection.\n- `publicAPI`: An object defining the exposed parts, containing:\n    - `functionSignatures`: An array of strings, each representing a public function signature (e.g., 'login(user: User): Promise<string>').\n    - `dataStructures`: An array of strings, each a self-contained TypeScript interface or type definition required by the public API (e.g., 'interface User { id: string; }').\n- `internalLogic`: An object describing the private implementation details, containing:\n    - `promptInstructions`: An array of strings containing detailed, step-by-step implementation instructions derived from the reasoning tree.\n    - `acceptanceTests`: An array of strings describing high-level acceptance criteria or test cases (e.g., 'Should return a JWT on successful login').\nFinally, define and export the corresponding TypeScript type `ModuleContract`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/module_contract.schema.ts",
                "MODULE_CONTRACT_SCHEMA",
                "ModuleContract"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON schema"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the `MODULE_CONTRACT_SCHEMA` is a cornerstone of the 'Contract-First Design' and 'Schema-Enforced Communication' principles outlined in the overall goal. It is a direct and essential contribution to the current task of defining core schemas.",
              "sequence_critique": "The logical sequence is sound. This step fits correctly within the task of defining all core schemas for the foundational framework. No prerequisite steps appear to be missing.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise file path, a constant name, and a detailed, property-by-property breakdown with data types and illustrative examples (e.g., 'AuthenticationService', 'login(user: User): Promise<string>'). The instructions are specific enough for an AI agent to execute without ambiguity."
            }
          }
        },
        {
          "step 4": "Create a new file named `src/schemas/contract_document.schema.ts`. This schema will represent the full architectural plan, which is a collection of module contracts. In this file:\n1. Import the `MODULE_CONTRACT_SCHEMA` constant and the `ModuleContract` type from `./module_contract.schema.ts`.\n2. Define and export a JSON schema constant named `CONTRACT_DOCUMENT_SCHEMA`. This schema must describe an object with a single top-level property: `modules`, which is an array where each item must conform to the imported `MODULE_CONTRACT_SCHEMA`.\n3. Define and export the corresponding TypeScript type `ContractDocument`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/contract_document.schema.ts",
                "MODULE_CONTRACT_SCHEMA",
                "ModuleContract",
                "./module_contract.schema.ts",
                "CONTRACT_DOCUMENT_SCHEMA",
                "ContractDocument"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON schema"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the `CONTRACT_DOCUMENT_SCHEMA` is a core requirement of the parent task and fundamental to the overall system architecture, serving as the primary artifact connecting Stage 1 (Contract Generation) and Stage 2 (Parallel Module Implementation).",
              "sequence_critique": "The logical sequence is correct. The step explicitly requires importing the `MODULE_CONTRACT_SCHEMA`, correctly establishing that the schema for an individual module must be defined before defining the schema for the document that contains a collection of them.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They are specific about file names, constant/type names, structural properties ('a single top-level property: `modules`'), and dependencies (importing from `./module_contract.schema.ts`), making the task unambiguous for an AI agent."
            }
          }
        },
        {
          "step 5": "Create a new file named `src/schemas/builder_output.schema.ts`. This file will define the schema for the JSON object returned by a Module Builder agent after it generates code. In this file:\n1. Define and export a JSON schema constant named `BUILDER_OUTPUT_SCHEMA`. It must describe an object with two required string properties:\n    - `implementationCode`: A string to hold the generated source code for the module.\n    - `testCode`: A string to hold the generated test suite for the module.\n2. Define and export the corresponding TypeScript type `BuilderOutput`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/builder_output.schema.ts",
                "BUILDER_OUTPUT_SCHEMA",
                "implementationCode",
                "testCode",
                "BuilderOutput"
              ],
              "technology_hints": [
                "JSON schema",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the 'Schema-Enforced Communication' principle by defining the data structure for the output of the 'Module Builder' agent, which is a critical component described in 'Stage 2: Parallel Module Implementation'.",
              "sequence_critique": "The step is logically placed within the broader task of defining all core schemas. No prerequisites seem to be missing.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They specify the exact file path, constant name, property names, and data types, leaving no room for ambiguity for an AI coding agent."
            }
          }
        },
        {
          "step 6": "To ensure clean and manageable imports throughout the application, create an `index.ts` file inside the `src/schemas` directory. This file should act as a barrel file, exporting all the schemas and types you've just created from `reasoning_tree.schema.ts`, `module_contract.schema.ts`, `contract_document.schema.ts`, and `builder_output.schema.ts`. Use the `export * from './filename';` syntax for each file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "index.ts",
                "src/schemas",
                "reasoning_tree.schema.ts",
                "module_contract.schema.ts",
                "contract_document.schema.ts",
                "builder_output.schema.ts"
              ],
              "technology_hints": [
                "TypeScript",
                "barrel file"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a barrel file is a standard best practice for organizing modules in a TypeScript project. It directly supports the task of defining the core schemas by making them easily and cleanly importable throughout the application, which is essential for building the 'Foundational Framework' mentioned in the phase goal.",
              "sequence_critique": "The sequence is logical. This step correctly assumes the individual schema files have already been created and now need to be aggregated for export. Placing it after the creation of the individual schema files is the correct order.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact filename (`index.ts`), its location (`src/schemas`), its purpose (barrel file), the exact syntax to use (`export * from './filename';`), and the specific files to export from. An AI agent would have no ambiguity in executing this."
            }
          }
        }
      ],
      "Task 1.3: Implement a configuration module for managing API keys, model names, and system settings.": [
        {
          "step 1": "Create a new directory named 'config' inside the 'src' directory. This directory will house all the configuration-related logic for the application.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "'config' directory",
                "'src' directory"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dedicated 'config' directory is a standard and logical first action for implementing a configuration module, establishing the necessary structure for subsequent files.",
              "sequence_critique": "The sequence is logical. Creating a directory to house the module's files is the correct prerequisite step before any files are created within it.",
              "clarity_critique": "The instruction is clear, atomic, and highly actionable. It specifies the exact name and location of the directory to be created, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "Install the necessary libraries for type-safe configuration management. Use pip to install 'pydantic' and 'pydantic-settings'. Add these libraries to your 'requirements.txt' file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Use pip to install 'pydantic' and 'pydantic-settings'.",
                "Add these libraries to your 'requirements.txt' file."
              ],
              "key_entities_dependencies": [
                "requirements.txt"
              ],
              "technology_hints": [
                "pip",
                "pydantic",
                "pydantic-settings"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Installing 'pydantic' and 'pydantic-settings' directly provides the necessary tools for creating a robust, type-safe configuration module, which is a foundational component for the orchestrator.",
              "sequence_critique": "The sequence is logical. Installing dependencies is a necessary prerequisite that must occur before writing the code that utilizes them. Placing this step early in the task is appropriate.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the exact libraries to install, the tool to use ('pip'), and the crucial secondary action of updating the 'requirements.txt' file for project dependency management."
            }
          }
        },
        {
          "step 3": "Create a new file named 'settings.py' inside the 'src/config' directory. In this file, you will define the application's configuration model using Pydantic.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "settings.py",
                "src/config"
              ],
              "technology_hints": [
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a Pydantic settings model is a direct and modern approach to implementing a configuration module, which is a foundational requirement for the overall system that will need to manage API keys and model names.",
              "sequence_critique": "The step is a logical unit of work. Its position as 'step 3' is sound, assuming that preceding steps have already created the necessary 'src/config' directory.",
              "clarity_critique": "The instruction is clear and actionable. It specifies the exact file to create, its location, and the technology (Pydantic) to use for defining the configuration model. This is specific enough for an AI agent to execute without ambiguity."
            }
          }
        },
        {
          "step 4": "In 'src/config/settings.py', define a class named 'Settings' that inherits from 'pydantic_settings.BaseSettings'. This class will define all the configuration variables for the system. Include the following fields:\n- `OPENAI_API_KEY`: Use `pydantic.SecretStr` for this to prevent accidental exposure in logs.\n- `PLANNER_MODEL_NAME`: A `str` with a default value of 'gpt-4-turbo-preview'.\n- `ARCHITECT_MODEL_NAME`: A `str` with a default value of 'gpt-4-turbo-preview'.\n- `BUILDER_MODEL_NAME`: A `str` with a default value of 'gpt-4-turbo-preview'.\n- `CORRECTOR_MODEL_NAME`: A `str` with a default value of 'gpt-4-turbo-preview'.\n- `MAX_CORRECTION_RETRIES`: An `int` with a default value of 3.\n- `PROJECT_DIR`: A `str` with a default value of 'generated_projects'.\n\nConfigure the class's `model_config` to load variables from a '.env' file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/config/settings.py",
                "Settings",
                "pydantic_settings.BaseSettings",
                "OPENAI_API_KEY",
                "pydantic.SecretStr",
                "PLANNER_MODEL_NAME",
                "ARCHITECT_MODEL_NAME",
                "BUILDER_MODEL_NAME",
                "CORRECTOR_MODEL_NAME",
                "MAX_CORRECTION_RETRIES",
                "PROJECT_DIR",
                "model_config",
                ".env"
              ],
              "technology_hints": [
                "pydantic_settings",
                "pydantic",
                "gpt-4-turbo-preview",
                ".env"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. The defined settings (e.g., `PLANNER_MODEL_NAME`, `ARCHITECT_MODEL_NAME`, `MAX_CORRECTION_RETRIES`) directly map to the specific agents and processes outlined in the system architecture, providing the necessary configuration for the orchestrator to function.",
              "sequence_critique": "Assuming prior steps created the necessary directory (`src/config`) and installed dependencies (`pydantic-settings`), this step is in the correct logical sequence. It represents the core implementation of the configuration module.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The prompt specifies the exact file path, class name, inheritance, field names, data types (including the security-conscious `SecretStr`), default values, and configuration for `.env` loading. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 5": "At the bottom of 'src/config/settings.py', create a single, globally accessible instance of your `Settings` class. Name this instance 'settings'. This will act as a singleton that can be imported throughout the application.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/config/settings.py",
                "Settings",
                "settings"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a globally accessible singleton instance is a standard and effective pattern for a configuration module, which is a necessary component for the foundational framework described in the task.",
              "sequence_critique": "The step's placement is logical, assuming the `Settings` class has been defined in the preceding steps within the same file. Instantiating the class after its definition is the correct order.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the file, the location within the file, the class to use, the exact name for the instance, and the design pattern it implements (singleton), which is unambiguous for an AI agent."
            }
          }
        },
        {
          "step 6": "Create a file named '__init__.py' inside the 'src/config' directory. In this file, import the 'settings' instance from your 'settings.py' module and expose it for easier importing. The file should contain the line: `from .settings import settings`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "__init__.py",
                "src/config",
                "settings",
                "settings.py"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly contributes to the task of creating a configuration module. Using an '__init__.py' to expose the settings object is a standard Python practice that makes the module cleaner and easier to use, which aligns with the goal of building a robust foundational framework.",
              "sequence_critique": "The step logically follows the creation of the 'settings.py' file from which it imports. Assuming preceding steps created 'src/config/settings.py', the sequence is correct.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the exact file path, the exact line of code to include, and the reason for doing so, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 7": "In the root directory of the project, create a file named '.env.example'. This file will serve as a template for users. List all the environment variables defined in your `Settings` class, especially the required `OPENAI_API_KEY`, with placeholder values. For example: `OPENAI_API_KEY=\"your_api_key_here\"`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                ".env.example",
                "Settings",
                "OPENAI_API_KEY"
              ],
              "technology_hints": [
                "OpenAI"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating an `.env.example` file is a standard best practice for a configuration module, directly contributing to the task of managing settings in a user-friendly and secure way. This is essential for the overall system which requires API keys to function.",
              "sequence_critique": "The sequence is logical. This step correctly assumes that a `Settings` class defining the necessary environment variables has already been created. Documenting these variables in an example file is a logical concluding step for the configuration task.",
              "clarity_critique": "The step is clear and actionable. It specifies the filename, its location in the project structure, its purpose, and the exact content required, including a concrete example. An AI agent would have no ambiguity in executing this instruction."
            }
          }
        },
        {
          "step 8": "Ensure that the actual '.env' file is not committed to version control. Add a line with `.env` to your project's `.gitignore` file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                ".env",
                ".gitignore"
              ],
              "technology_hints": [
                "git"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing a configuration module that handles API keys necessitates the security best-practice of ensuring the '.env' file containing those keys is never committed to version control. This directly supports the overall goal of creating a 'production-ready' framework.",
              "sequence_critique": "The step is logically sound. It's a standard and crucial action to take when implementing an environment variable-based configuration system. It should ideally be performed as soon as the decision to use a '.env' file is made.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It states the desired outcome ('Ensure that the actual '.env' file is not committed') and provides the exact, unambiguous command to achieve it ('Add a line with `.env` to your project's `.gitignore` file')."
            }
          }
        },
        {
          "step 9": "Create a new test file 'tests/test_config.py'. Write unit tests using 'pytest' to verify the configuration module. Use 'pytest.monkeypatch' to set and unset environment variables during tests. Your tests should cover:\n1. Successful loading of settings from environment variables.\n2. Pydantic raising a `ValidationError` if a required variable like `OPENAI_API_KEY` is not set.\n3. Verification that default values are correctly applied when corresponding environment variables are not set.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/test_config.py",
                "configuration module",
                "pytest.monkeypatch",
                "ValidationError",
                "OPENAI_API_KEY"
              ],
              "technology_hints": [
                "pytest",
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Writing robust unit tests for a core configuration module directly contributes to the task of implementing that module and supports the overall project's philosophy of building a reliable, verifiable system.",
              "sequence_critique": "The step's placement is logical. Writing tests should occur after the initial implementation of the code to be tested, which is presumably what happened in the preceding steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the testing framework (`pytest`), the exact tool for the job (`pytest.monkeypatch`), and provides a precise, enumerated list of test cases to be implemented, including expected outcomes like specific exceptions (`ValidationError`)."
            }
          }
        },
        {
          "step 10": "Update the main `README.md` file. Add a new 'Configuration' section that explains how to set up the project. Instruct the user to copy `.env.example` to `.env` and fill in their `OPENAI_API_KEY`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "README.md",
                ".env.example",
                ".env",
                "OPENAI_API_KEY"
              ],
              "technology_hints": [
                "OpenAI API"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Documenting how to use the configuration module is a critical and final part of implementing it, which is essential for the foundational framework.",
              "sequence_critique": "The sequence is logical. As 'step 10', it correctly comes after the assumed implementation of the configuration module and creation of the `.env.example` file. Documentation is an appropriate final action for this task.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the exact file to modify (`README.md`), the new section to add ('Configuration'), and the precise instructions to include for the user, making it unambiguous for an AI agent."
            }
          }
        }
      ],
      "Task 1.4: Create a generic LLM client abstraction for handling API requests, responses, and retries.": [
        {
          "step 1": "First, set up the directory structure for the new LLM client module. Create a new directory `src/llm_client`. Inside this directory, create the following empty files: `__init__.py`, `base.py`, `config.py`, and `openai_client.py`. This structure will house the abstraction, the concrete implementation, and its configuration.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client",
                "__init__.py",
                "base.py",
                "config.py",
                "openai_client.py"
              ],
              "technology_hints": [
                "Python",
                "OpenAI"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. The proposed file structure (`base.py` for the abstraction, `openai_client.py` for a concrete implementation) directly supports the task of creating a generic LLM client. This is a crucial foundational component for the overall system.",
              "sequence_critique": "The sequence is correct. Establishing the file and directory structure is the logical first action to take when creating a new software module.",
              "clarity_critique": "The instructions are clear, specific, and directly actionable. An AI agent can easily execute the commands to create the specified directory and empty files."
            }
          }
        },
        {
          "step 2": "In `src/llm_client/config.py`, define a Pydantic model named `LLMConfig` to hold the configuration for the LLM client. It should include fields for `api_key` (using `SecretStr` for security), `model_name` (e.g., 'gpt-4-turbo'), `temperature`, and `max_tokens`. Make all fields optional with sensible defaults, except for the `api_key`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client/config.py",
                "LLMConfig",
                "SecretStr",
                "api_key",
                "model_name",
                "temperature",
                "max_tokens"
              ],
              "technology_hints": [
                "Pydantic",
                "Python",
                "SecretStr",
                "gpt-4-turbo"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a Pydantic configuration model is a foundational and logical part of building a generic, reusable LLM client abstraction. This directly supports the overall project goal, which relies heavily on structured, reliable communication with LLMs.",
              "sequence_critique": "The sequence is logical. Defining the configuration data structure is a necessary prerequisite before implementing the client class that will consume it. This step correctly precedes the implementation of the client's logic.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, technology (Pydantic), field names, and specific implementation details like using `SecretStr` for security and making certain fields optional with defaults. An AI agent would have no ambiguity in executing this instruction."
            }
          }
        },
        {
          "step 3": "In `src/llm_client/base.py`, define the abstract interface for all LLM clients. Create an abstract base class `LLMClient` using Python's `abc` module. It should have an `__init__` that accepts an `LLMConfig` object. Define an abstract method `create_chat_completion(self, messages: list[dict], response_model: type[BaseModel] | None = None) -> BaseModel | str`. This method will be the core function for interacting with the LLM, with `response_model` being an optional Pydantic model to enforce the structure of the LLM's output.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client/base.py",
                "LLMClient",
                "LLMConfig",
                "create_chat_completion",
                "BaseModel"
              ],
              "technology_hints": [
                "Python",
                "abc",
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Creating an abstract LLM client is fundamental to the framework's modularity. The inclusion of a `response_model` parameter directly supports the core philosophy of 'Schema-Enforced Communication' by enabling structured, Pydantic-validated outputs from the LLM.",
              "sequence_critique": "The step is logically sound. Defining an abstract base class is the correct foundational action for this task, preceding any concrete implementations. It correctly assumes an `LLMConfig` object exists, which would logically be defined in a prior step.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, base class module (`abc`), and method signature, including precise type hints. This level of detail minimizes ambiguity for an AI coding agent."
            }
          }
        },
        {
          "step 4": "Now, create the concrete implementation for OpenAI. In `src/llm_client/openai_client.py`, create a class `OpenAIClient` that inherits from `LLMClient`. Implement the `__init__` method to accept the `LLMConfig` and initialize the official `openai` client. For the `create_chat_completion` method, implement the basic logic to call the OpenAI API. If a `response_model` is provided, add a system message instructing the model to respond in JSON format matching the provided schema. Hint: You can get the schema from `response_model.model_json_schema()`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client/openai_client.py",
                "OpenAIClient",
                "LLMClient",
                "__init__",
                "LLMConfig",
                "create_chat_completion",
                "response_model",
                "response_model.model_json_schema()"
              ],
              "technology_hints": [
                "OpenAI",
                "openai",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of creating a generic LLM client abstraction. Building a concrete implementation for a specific provider (OpenAI) is a necessary and direct contribution to this task. This foundational component is essential for the overall system, which relies entirely on LLM communication.",
              "sequence_critique": "The sequence is logical. The phrasing \"Now, create the concrete implementation...\" correctly implies that a preceding step defined the abstract `LLMClient` from which this new class will inherit. This is the correct order of operations: define the interface, then implement it.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific details including the file path (`src/llm_client/openai_client.py`), class name (`OpenAIClient`), inheritance, and method-specific requirements. The instruction to handle JSON responses via a system message, along with the hint to use `response_model.model_json_schema()`, is precise and directly supports the system's 'Schema-Enforced Communication' principle."
            }
          }
        },
        {
          "step 5": "Enhance the `OpenAIClient` with robust error handling and automatic retries. Install the `tenacity` library. Use the `@retry` decorator from `tenacity` on the `create_chat_completion` method (or a private helper method that makes the actual API call). Configure the retry logic to handle specific exceptions like `openai.RateLimitError`, `openai.APITimeoutError`, and `openai.APIStatusError` (for 5xx codes). Use `wait_exponential` for the backoff strategy and `stop_after_attempt` to limit the number of retries.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Install the `tenacity` library"
              ],
              "key_entities_dependencies": [
                "OpenAIClient",
                "create_chat_completion",
                "openai.RateLimitError",
                "openai.APITimeoutError",
                "openai.APIStatusError"
              ],
              "technology_hints": [
                "tenacity",
                "@retry",
                "wait_exponential",
                "stop_after_attempt",
                "openai"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of creating a robust LLM client. Building a resilient client with automatic retries is a critical foundational requirement for the overall goal, as the entire multi-stage system depends on reliable communication with the LLM.",
              "sequence_critique": "The step's placement is logical, assuming preceding steps established the basic `OpenAIClient` class. Enhancing an existing class with resiliency features is a standard and correct workflow.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact library to use (`tenacity`), the design pattern (`@retry` decorator), the specific exceptions to handle, and the precise configuration for backoff and retry limits. This level of detail is ideal for an AI agent to execute successfully."
            }
          }
        },
        {
          "step 6": "Implement the response parsing and validation logic within `create_chat_completion` in `openai_client.py`. After receiving the response from the OpenAI API, check if a `response_model` was provided. If so, attempt to parse the JSON content of the response into an instance of that Pydantic model. Wrap this parsing logic in a `try...except` block to catch `pydantic.ValidationError` and `json.JSONDecodeError`. If parsing fails, you should raise a custom exception, for example, `LLMResponseParsingError`. If no `response_model` is given, return the raw string content of the response.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "create_chat_completion",
                "openai_client.py",
                "response_model",
                "pydantic.ValidationError",
                "json.JSONDecodeError",
                "LLMResponseParsingError"
              ],
              "technology_hints": [
                "OpenAI API",
                "Pydantic",
                "json"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Creating a robust parsing and validation mechanism using Pydantic models is a direct and essential implementation of the system's core principle of 'Schema-Enforced Communication', which is critical for the reliability of the entire framework.",
              "sequence_critique": "The step is in a logical sequence. It correctly assumes that the API request has already been made and focuses on the subsequent, necessary action of processing the response. This is a natural progression within the implementation of a client's request/response function.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact function (`create_chat_completion`), file (`openai_client.py`), error types to handle (`pydantic.ValidationError`, `json.JSONDecodeError`), the use of a custom exception, and the precise fallback behavior, leaving no room for ambiguity for the AI agent."
            }
          }
        },
        {
          "step 7": "Create custom exceptions to improve error signaling. In a new file `src/llm_client/exceptions.py`, define a base exception `LLMClientError` and a more specific exception `LLMResponseParsingError` that inherits from it. Use these exceptions in your `openai_client.py` implementation.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client/exceptions.py",
                "LLMClientError",
                "LLMResponseParsingError",
                "openai_client.py"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating custom exceptions is a fundamental aspect of building a robust abstraction, which is the goal of the task. It directly supports the overall project's philosophy of 'strict process controls' and 'reliability' by enabling more specific and manageable error handling within the orchestrator.",
              "sequence_critique": "The step appears to be in a logical sequence. It's common practice to establish basic functionality first (presumably in prior steps) and then enhance it with robust error handling like custom exceptions. The instruction correctly presumes the existence of `openai_client.py` to modify.",
              "clarity_critique": "The step is very clear and actionable. It specifies the exact file path, the class names to create, their inheritance relationship, and the subsequent action of applying them in another file. This level of specificity is excellent for an AI coding agent."
            }
          }
        },
        {
          "step 8": "Prepare for testing. Create a new test file `tests/test_llm_client.py`. In this file, set up a `unittest.TestCase` class. You will need to mock the OpenAI API to avoid making real network calls. Use `unittest.mock.patch` to mock the `openai.resources.chat.completions.Completions.create` method.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/test_llm_client.py",
                "unittest.TestCase",
                "unittest.mock.patch",
                "openai.resources.chat.completions.Completions.create"
              ],
              "technology_hints": [
                "Python",
                "unittest",
                "OpenAI API"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating tests and mocking external dependencies is a critical part of building a robust and reliable LLM client abstraction, which is a foundational component for the entire system.",
              "sequence_critique": "The sequence is logical. This step correctly sets up the testing framework and mocks, which is a necessary prerequisite before writing the actual test cases that will validate the client's behavior.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific instructions on the file to create (`tests/test_llm_client.py`), the class to use (`unittest.TestCase`), the tool for mocking (`unittest.mock.patch`), and the precise API method to mock. This level of detail is ideal for an AI agent."
            }
          }
        },
        {
          "step 9": "Write unit tests in `tests/test_llm_client.py` to cover the main success scenarios. First, test the case where a `response_model` is provided. Configure your mock to return a valid JSON string that matches the schema of a sample Pydantic model. Assert that the client returns a correctly parsed Pydantic object. Second, test the case where no `response_model` is provided and assert that the raw string response is returned.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/test_llm_client.py",
                "response_model"
              ],
              "technology_hints": [
                "Pydantic",
                "JSON",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Testing the LLM client's ability to parse responses into a Pydantic model directly supports the project's core principle of 'Schema-Enforced Communication'. It is a critical step for ensuring the reliability of the foundational component described in the task.",
              "sequence_critique": "The step's position, focusing on testing success scenarios after initial implementation, is logical. It correctly prioritizes verifying the two main operational modes of the client (structured and unstructured responses). Assuming preceding steps covered the basic implementation, this sequence is appropriate.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file, the two distinct scenarios to test, the required mock behavior, and the precise assertions to make for each case. The instructions are specific enough for an AI agent to execute without ambiguity."
            }
          }
        },
        {
          "step 10": "Write unit tests to verify the error handling and retry logic. Configure your mock to raise `openai.RateLimitError` on the first call and then return a successful response on the second call. Use `mock_obj.call_count` to assert that the API call was attempted twice. Also, write a test where the mock returns a malformed JSON string and assert that your custom `LLMResponseParsingError` is raised.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "openai.RateLimitError",
                "mock_obj.call_count",
                "LLMResponseParsingError"
              ],
              "technology_hints": [
                "openai",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly supports the task's goal of creating a robust LLM client by explicitly requiring tests for the crucial features of retry logic and error handling. This aligns perfectly with the overall system's philosophy of reliability and schema-enforced communication.",
              "sequence_critique": "Assuming the preceding steps involved implementing the client's retry and error-handling logic, this step is perfectly sequenced as it focuses on verifying that implementation. Writing tests after implementation is a standard and logical workflow.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific instructions on how to set up mocks (`openai.RateLimitError`, malformed JSON), what behavior to simulate (fail first, then succeed), and which assertions to make (`mock_obj.call_count`, `LLMResponseParsingError`), leaving little room for ambiguity."
            }
          }
        },
        {
          "step 11": "Finally, clean up the module's public interface. In `src/llm_client/__init__.py`, import and export the key classes and exceptions so they can be easily accessed from other parts of the application. For example: `from .base import LLMClient`, `from .openai_client import OpenAIClient`, `from .config import LLMConfig`, `from .exceptions import LLMClientError, LLMResponseParsingError`. Review all new files for proper type hinting, docstrings, and code clarity.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm_client/__init__.py",
                "LLMClient",
                "OpenAIClient",
                "LLMConfig",
                "LLMClientError",
                "LLMResponseParsingError",
                ".base",
                ".openai_client",
                ".config",
                ".exceptions"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of creating a robust, reusable LLM client abstraction. Exposing a clean public interface through `__init__.py` and performing a final quality review are essential for creating professional, production-ready foundational code, which directly supports the overall project goal.",
              "sequence_critique": "The step begins with \"Finally...\" and is numbered as step 11, which logically places it at the end of the module's creation process. It correctly assumes that the files and classes it needs to export have already been created in prior steps. The sequence is appropriate.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to modify, explains the purpose of the change, and provides concrete code examples. The final instruction to review for type hinting, docstrings, and clarity sets a clear quality standard for the AI agent."
            }
          }
        }
      ],
      "Task 1.5: Implement the main Orchestrator class/script to manage the sequential flow through all four stages.": [
        {
          "step 1": "Create a new file at `src/types.ts`. Based on the system architecture document, define the core data structures and interfaces that will be passed between stages. Create placeholder interfaces for `ReasoningTree`, `ModuleContract`, `GeneratedModule`, and `FinalProject`. For `ModuleContract`, include fields like `moduleName`, `purpose`, `dependencies`, `functionSignatures`, `promptInstructions`, and `acceptanceTests` as described in the 'Contract Generation' stage.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/types.ts",
                "ReasoningTree",
                "ModuleContract",
                "GeneratedModule",
                "FinalProject",
                "moduleName",
                "purpose",
                "dependencies",
                "functionSignatures",
                "promptInstructions",
                "acceptanceTests"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the data structures that are passed between stages is a fundamental prerequisite for building an orchestrator that manages the flow of that data. This directly contributes to the task of implementing the main orchestrator.",
              "sequence_critique": "The sequence is logical. Defining types and interfaces in a dedicated file is the correct first step before writing any code (like the orchestrator class) that will depend on them.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the exact file to create, the names of the interfaces to define (`ReasoningTree`, `ModuleContract`, etc.), and provides specific fields for the `ModuleContract` while correctly referencing the system architecture document for the full specification. This is an excellent instruction for an AI agent."
            }
          }
        },
        {
          "step 2": "Create the main orchestrator file at `src/orchestrator.ts`. Define an `Orchestrator` class. Import the types from `src/types.ts`. The class should have private properties to hold the artifacts from each stage (e.g., `private reasoningTree: ReasoningTree | null = null;`, `private contracts: ModuleContract[] | null = null;`, etc.). Also, create an empty public async method `run(initialGoal: string): Promise<void>`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/orchestrator.ts",
                "Orchestrator",
                "src/types.ts",
                "ReasoningTree",
                "ModuleContract",
                "reasoningTree",
                "contracts",
                "run",
                "initialGoal"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of implementing the main orchestrator. Creating the class structure, defining state properties for artifacts from each stage, and establishing the main `run` method are foundational and logical first actions that directly contribute to the task and the overall system goal.",
              "sequence_critique": "The sequence is logical. This step correctly establishes the skeleton of the `Orchestrator` class. It is a prerequisite for subsequent steps that will implement the logic for calling each stage of the pipeline. There are no missing steps or ordering issues.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, property structure (with examples), and method signature (including visibility, async keyword, parameters, and return type). An AI agent can execute this instruction with high precision."
            }
          }
        },
        {
          "step 3": "To simulate the work of different agents without implementing their full logic yet, create a file at `src/agents.ts`. In this file, define placeholder 'Agent' classes for each stage: `PlannerAgent`, `InterfaceArchitectAgent`, `ModuleBuilderAgent`, and `CorrectorAndIntegratorAgent`. Each class should have a single public async `execute` method. These methods should return mock data that conforms to the interfaces in `src/types.ts`. For example, `InterfaceArchitectAgent.execute` should accept a mock `ReasoningTree` and return a hardcoded array of `ModuleContract` objects.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents.ts",
                "PlannerAgent",
                "InterfaceArchitectAgent",
                "ModuleBuilderAgent",
                "CorrectorAndIntegratorAgent",
                "execute",
                "src/types.ts",
                "ReasoningTree",
                "ModuleContract"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating placeholder agents is a necessary prerequisite for implementing and testing the orchestrator's sequential logic without the complexity of the final agent implementations.",
              "sequence_critique": "The sequence is logical. The mock agents must be created before the orchestrator's main execution method, which depends on them, can be implemented.",
              "clarity_critique": "The instructions are clear and actionable, specifying file paths, class names, method signatures, and providing a helpful example. The consolidation of the 'Corrector' and 'Integrator' into a single placeholder agent is a reasonable simplification for this development stage."
            }
          }
        },
        {
          "step 4": "In the `Orchestrator` class, implement the private methods for the first two stages: `private async runStage0_Planning(goal: string): Promise<void>` and `private async runStage1_ContractGeneration(): Promise<void>`. In each method, instantiate the corresponding agent from `src/agents.ts`, call its `execute` method, store the result in the appropriate class property (e.g., `this.reasoningTree = ...`), and add console logs to indicate the start and successful completion of the stage. Wrap the logic in a `try...catch` block for error handling.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Orchestrator",
                "runStage0_Planning",
                "runStage1_ContractGeneration",
                "src/agents.ts",
                "execute",
                "this.reasoningTree"
              ],
              "technology_hints": [
                "async/await"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing the methods for the first two stages is a direct and logical contribution to building the main orchestrator that manages the sequential flow.",
              "sequence_critique": "The sequence is logical. It correctly addresses the implementation of Stage 0 and Stage 1, which are the first two stages in the overall system workflow. The step correctly builds upon the implied existence of the Orchestrator class and agent definitions from previous tasks.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific method signatures (name, visibility, async, parameters, return type), outlines the precise internal logic (instantiate, execute, store result), and includes requirements for logging and error handling. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 5": "In the `Orchestrator` class, implement the private methods for the final two stages: `private async runStage2_Implementation(): Promise<void>` and `private async runStage3_Integration(): Promise<void>`. For `runStage2_Implementation`, simulate the parallel nature by iterating through `this.contracts` and calling the `ModuleBuilderAgent.execute` method for each, collecting the results. For `runStage3_Integration`, pass the collected modules to the `CorrectorAndIntegratorAgent.execute` method. As before, add logging and error handling for each stage.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Orchestrator",
                "runStage2_Implementation",
                "runStage3_Integration",
                "this.contracts",
                "ModuleBuilderAgent.execute",
                "CorrectorAndIntegratorAgent.execute"
              ],
              "technology_hints": [
                "async",
                "Promise"
              ]
            },
            "step_critique": {
              "alignment_critique": "Steps are well-aligned with the task and overall goal, correctly implementing the logic for Stage 2 (Implementation) and Stage 3 (Integration) of the system workflow.",
              "sequence_critique": "The sequence is logical. However, the step significantly simplifies the multi-part Stage 3 ('Verification, Correction, and Integration') into a single agent call. The method name `runStage3_Integration` is also a misnomer, as it omits the critical 'Verification' and 'Correction' aspects described in the architecture document for that stage.",
              "clarity_critique": "The instructions are actionable but create a potential discrepancy with the detailed architecture. The architecture describes a complex loop involving separate verification, correction, and integration processes. This step bundles that entire logic into a single call to a `CorrectorAndIntegratorAgent`, merging distinct architectural roles. While this may be an intentional simplification for the initial implementation, the step should acknowledge this to avoid confusion."
            }
          }
        },
        {
          "step 6": "Now, fully implement the main `public async run(initialGoal: string)` method in the `Orchestrator` class. This method will act as the master controller. It should call the private stage methods (`runStage0_Planning`, `runStage1_ContractGeneration`, etc.) in the correct sequential order. Ensure that the output of one stage is available for the next (by checking that the corresponding class property is not null). Wrap the entire sequence of calls in a single `try...catch` block to handle any failure during the process and log a final 'Orchestration completed' or 'Orchestration failed' message.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "run",
                "initialGoal",
                "Orchestrator",
                "runStage0_Planning",
                "runStage1_ContractGeneration"
              ],
              "technology_hints": [
                "async",
                "try...catch"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing the `run` method to sequentially call the stage-specific methods is the central purpose of the Orchestrator, directly contributing to the task of managing the end-to-end workflow.",
              "sequence_critique": "The sequence described within the step (calling stage methods in order) is logical and correctly reflects the overall system architecture. The instruction to check for the output of the previous stage before proceeding is a crucial and correctly placed prerequisite check.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method signature, the sequence of internal calls, the data hand-off logic (checking non-null properties), and the required error handling and logging pattern. This provides a precise blueprint for implementation."
            }
          }
        },
        {
          "step 7": "Create a main entry point file at `src/main.ts`. This script will initialize and run the entire system. Import the `Orchestrator` class. Instantiate it, define a sample high-level user goal (e.g., 'Build a real-time chat application with a React frontend'), and invoke the `orchestrator.run(goal)` method. Add a top-level `.catch()` to the invocation to handle any unhandled promise rejections from the orchestrator.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/main.ts",
                "Orchestrator",
                "orchestrator.run(goal)"
              ],
              "technology_hints": [
                "TypeScript",
                "Promises"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the main entry point to instantiate and run the `Orchestrator` is the final and necessary action to fulfill the task of implementing the orchestrator script. It directly contributes to the overall goal by providing the 'ignition switch' for the entire autonomous framework.",
              "sequence_critique": "The step is logically sequenced. It correctly assumes that the `Orchestrator` class has been defined in previous steps. Creating the entry point to use the class is the correct final step for this task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to create (`src/main.ts`), the class to import, the method to invoke (`orchestrator.run(goal)`), provides a concrete example for the input, and includes a specific instruction for robust error handling (`.catch()`)."
            }
          }
        },
        {
          "step 8": "To make the simulation tangible, create a utility for saving artifacts. Create `src/utils.ts` and add an async function `saveArtifact(filePath: string, data: any): Promise<void>` that uses the `fs/promises` module to write data to the disk as a formatted JSON string. Create a directory named `build` at the root of the project. Update the `Orchestrator` stage methods to call this utility after each stage successfully completes, saving `reasoning_tree.json`, `contracts.json`, etc., into the `build` directory. This will allow you to inspect the mock data flow.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Create a directory named `build` at the root of the project"
              ],
              "key_entities_dependencies": [
                "src/utils.ts",
                "saveArtifact",
                "Orchestrator",
                "reasoning_tree.json",
                "contracts.json",
                "build"
              ],
              "technology_hints": [
                "fs/promises",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Saving the output artifacts of each stage is a core responsibility of the Orchestrator. This makes the multi-stage process tangible and debuggable, directly contributing to the task of implementing the orchestrator's flow and the overall system goal.",
              "sequence_critique": "The sequence is logical. It correctly involves creating a necessary utility and then integrating it into the main orchestrator logic. This is a standard and effective approach.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path (`src/utils.ts`), a precise function signature, implementation details (`fs/promises`, formatted JSON), and clear instructions on where to integrate the new functionality, making it easy to execute."
            }
          }
        }
      ],
      "Task 1.6: Implement a file-based artifact management system for passing data between stages (e.g., reasoning_tree.json, contracts.json).": [
        {
          "step 1": "Create a new directory `src/core`. Inside this new directory, create a Python file named `artifact_manager.py`. This module will encapsulate all file-based artifact handling logic.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/core",
                "artifact_manager.py"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dedicated `artifact_manager.py` module within a `src/core` directory is the logical starting point for building a centralized system to handle data handoffs between the described architectural stages.",
              "sequence_critique": "The sequence is correct. Creating the file and its parent directory is the necessary prerequisite before any functions or classes for artifact management can be implemented.",
              "clarity_critique": "The step is clear, specific, and actionable. It precisely names the directory and file to be created and provides helpful context about the module's intended purpose."
            }
          }
        },
        {
          "step 2": "In `src/core/artifact_manager.py`, define a class named `ArtifactManager`. The constructor `__init__(self, base_path: str)` should accept the root directory path for storing artifacts. It should store this path as an instance attribute and immediately ensure the directory exists using `os.makedirs(base_path, exist_ok=True)`. Import the necessary modules: `os`, `json`, and `typing`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/core/artifact_manager.py",
                "ArtifactManager",
                "__init__",
                "base_path",
                "os.makedirs"
              ],
              "technology_hints": [
                "os",
                "json",
                "typing"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the `ArtifactManager` class and its constructor to manage a base storage directory is the foundational action required to build a file-based system for passing artifacts between stages, which is critical for the overall pipeline architecture.",
              "sequence_critique": "The sequence is logical. Defining the class and its constructor is the correct first implementation step for this task, establishing the core component before adding methods to it.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The step specifies the exact file path, class name, method signature, constructor logic, and necessary imports, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 3": "Within the `ArtifactManager` class, implement a `save` method with the signature `save(self, filename: str, data: typing.Union[dict, list]) -> None`. This method will take a filename and a JSON-serializable Python object, construct the full file path by joining the `base_path` with the `filename`, and write the data to that file as a pretty-printed JSON string (use `json.dump` with `indent=2` for readability). Include a comprehensive docstring and type hints.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ArtifactManager",
                "save",
                "base_path",
                "filename",
                "data",
                "json.dump",
                "typing.Union"
              ],
              "technology_hints": [
                "JSON",
                "json",
                "typing"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing a `save` method for JSON artifacts is a core requirement for the specified task of creating a file-based artifact management system. This directly supports the overall goal of passing structured data between the distinct stages of the software development pipeline.",
              "sequence_critique": "The step is logically sound. It describes the implementation of a core method within a class. Assuming preceding steps define the `ArtifactManager` class and its `base_path` attribute, this step fits correctly into the task's workflow.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise method signature, specifies the exact implementation logic (path construction, using `json.dump`), includes formatting requirements (`indent=2`), and calls for standard best practices like docstrings and type hints. An AI agent would have no ambiguity in executing this instruction."
            }
          }
        },
        {
          "step 4": "In the `ArtifactManager` class, implement a `load` method with the signature `load(self, filename: str) -> typing.Union[dict, list]`. This method will take a filename, construct the full file path, read the file, and parse it from JSON into a Python object using `json.load`. It should be designed to propagate the `FileNotFoundError` if the artifact does not exist, as the calling code will need to handle this case. Include a comprehensive docstring and type hints.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ArtifactManager",
                "load",
                "FileNotFoundError",
                "json.load"
              ],
              "technology_hints": [
                "Python",
                "JSON",
                "typing"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing a `load` method is a fundamental requirement for an artifact management system, which is essential for passing data between the defined stages of the autonomous framework (e.g., loading `reasoning_tree.json` for Stage 1).",
              "sequence_critique": "Assuming prior steps established the `ArtifactManager` class and its constructor, this step is in a logical position. Implementing the loading of artifacts is a core function that complements the saving of artifacts.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact class, method signature, return types, implementation details (using `json.load`), and a crucial design constraint regarding error propagation (`FileNotFoundError`). This level of detail is ideal for an AI agent."
            }
          }
        },
        {
          "step 5": "Create a new test file at `tests/test_artifact_manager.py`. Using the `pytest` framework, write unit tests for the `ArtifactManager`. Use the `tmp_path` pytest fixture to supply a temporary directory to the `ArtifactManager` constructor during tests. Your test suite must verify the following behaviors: 1. The artifact directory is successfully created upon class initialization. 2. The `save` method creates a file with the correct content. 3. The `load` method correctly retrieves and deserializes the content from a saved file. 4. The `load` method correctly raises a `FileNotFoundError` when attempting to access a non-existent file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/test_artifact_manager.py",
                "ArtifactManager",
                "tmp_path",
                "save",
                "load",
                "FileNotFoundError"
              ],
              "technology_hints": [
                "pytest"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Writing unit tests for the `ArtifactManager` is a critical part of implementing a robust foundational component, directly supporting the task's goal of creating a reliable system for passing data between stages. This aligns with the overall project's core philosophy of verification and building a production-ready framework.",
              "sequence_critique": "The sequence is logical. This step presumes the `ArtifactManager` class has already been implemented in a previous step, and writing tests is the correct subsequent action to verify that implementation. No issues are identified.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, testing framework (`pytest`), a specific and appropriate fixture (`tmp_path`), and provides a precise, enumerated list of required test cases, including success paths and error handling. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 6": "Integrate the `ArtifactManager` into the main system orchestrator, located at `src/core/orchestrator.py`. If this file doesn't exist, create a basic placeholder class `Orchestrator` within it. Perform the following refactoring: \n1. Import `ArtifactManager` from `src.core.artifact_manager`. \n2. In the `Orchestrator`'s `__init__` method, create an instance attribute `self.artifacts = ArtifactManager('artifacts')` to manage I/O. \n3. Modify the logic for Stage 0 (Planning). Instead of returning its result (`reasoning_tree_data`) in memory, it should now use `self.artifacts.save('reasoning_tree.json', reasoning_tree_data)` to persist the output. \n4. Modify the logic for Stage 1 (Contract Generation). Instead of receiving the `reasoning_tree` as a method argument, it must now load its input at the beginning of its execution using `reasoning_tree_data = self.artifacts.load('reasoning_tree.json')`. \n5. At the conclusion of Stage 1, save its output (`contracts_data`) to a file using `self.artifacts.save('contracts.json', contracts_data)`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ArtifactManager",
                "src/core/orchestrator.py",
                "Orchestrator",
                "src.core.artifact_manager",
                "__init__",
                "self.artifacts",
                "self.artifacts.save",
                "reasoning_tree.json",
                "reasoning_tree_data",
                "self.artifacts.load",
                "contracts.json",
                "contracts_data"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It directly implements the core requirement of creating a file-based artifact system by integrating the `ArtifactManager` into the `Orchestrator`, thereby enabling data persistence and handoff between Stage 0 and Stage 1, which is a foundational element of the overall system architecture.",
              "sequence_critique": "The sequence of sub-steps is logical and correct. It follows a standard software development pattern: import necessary modules, instantiate the class in the constructor, and then refactor the dependent methods in the order of data flow (Stage 0 produces, Stage 1 consumes and then produces).",
              "clarity_critique": "The instructions are exceptionally clear and actionable for an AI agent. The step specifies exact file paths, class names, variable names, and method calls. The use of a numbered list and explicit descriptions of the refactoring (e.g., 'Instead of returning... it should now use...') effectively removes ambiguity."
            }
          }
        }
      ],
      "Task 1.7: Integrate the 'Hierarchical Planner' logic as Stage 0 of the orchestrator.": [
        {
          "step 1": "First, establish the directory structure for Stage 0. Create a new directory: `src/stages/stage_0_planning`. This directory will house all the logic related to the hierarchical planning process.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dedicated directory for Stage 0 is a foundational and necessary action for integrating the planner logic into the overall orchestrator structure as described in the system architecture.",
              "sequence_critique": "The sequence is logical. Establishing the directory structure is the correct prerequisite before adding or modifying any code files for this stage.",
              "clarity_critique": "The instruction is exceptionally clear, specific, and unambiguous. It provides an exact directory path and a simple command, making it easily executable by an AI agent."
            }
          }
        },
        {
          "step 2": "Recreate the core data models from the Hierarchical Planner inside the new directory. Create a file `src/stages/stage_0_planning/models.py`. In this file, define Pydantic models for `Step`, `Task`, `Phase`, and `Goal`. These models should form a nested structure, where a `Goal` contains a list of `Phases`, a `Phase` contains a list of `Tasks`, and a `Task` contains a list of `Steps`. Ensure the final top-level model, which will represent the entire reasoning tree, is clearly defined.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Hierarchical Planner",
                "src/stages/stage_0_planning/models.py",
                "Step",
                "Task",
                "Phase",
                "Goal"
              ],
              "technology_hints": [
                "Pydantic",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the data models for the reasoning tree (Goal, Phase, Task, Step) is a foundational and necessary action to integrate the 'Hierarchical Planner' logic, which is the explicit goal of the current task.",
              "sequence_critique": "The sequence is logical. Establishing the data structures (models) is a prerequisite for writing any of the business logic that will create or manipulate them. This step correctly comes before any implementation of the planner's execution flow.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the exact file path, the technology to use (Pydantic), the names of the models, and their precise nested relationship. The instruction to clearly define the top-level model is a good guardrail for the AI agent."
            }
          }
        },
        {
          "step 3": "Now, implement the core planning logic. Create a file `src/stages/stage_0_planning/planner.py`. In this file, create a `PlannerAgent` class. This class will be responsible for interacting with the LLM. It should have three primary methods: `plan_phases(goal: str) -> list[str]`, `plan_tasks(phase_description: str) -> list[str]`, and `plan_steps(task_description: str) -> list[str]`. These methods will take a high-level description and return a list of decomposed items. Use placeholder logic for now if direct LLM integration is not yet available.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning/planner.py",
                "PlannerAgent",
                "plan_phases(goal: str) -> list[str]",
                "plan_tasks(phase_description: str) -> list[str]",
                "plan_steps(task_description: str) -> list[str]"
              ],
              "technology_hints": [
                "LLM"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Creating a `PlannerAgent` with methods to decompose goals into phases, phases into tasks, and tasks into steps directly implements the core logic described for 'Stage 0: Hierarchical Planning'.",
              "sequence_critique": "The sequence is logical. This step correctly focuses on creating the foundational agent responsible for decomposition. It's a necessary prerequisite before an orchestrator can call this agent to build the complete planning tree.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, class name, and precise method signatures (names, arguments, and return types). The instruction to use placeholder logic is also a clear directive that enables incremental development."
            }
          }
        },
        {
          "step 4": "Create an orchestrator for Stage 0 that uses the models and the planner agent to build the complete reasoning tree. In `src/stages/stage_0_planning/planner.py`, create a function `generate_plan(goal: str) -> Goal`. This function will: \n1. Take the initial user goal.\n2. Instantiate `PlannerAgent`.\n3. Call `plan_phases` to get phase descriptions.\n4. For each phase description, call `plan_tasks` to get task descriptions.\n5. For each task description, call `plan_steps` to get step descriptions.\n6. Assemble the results into the nested `Goal` Pydantic model you defined in `models.py`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning/planner.py",
                "generate_plan",
                "Goal",
                "PlannerAgent",
                "plan_phases",
                "plan_tasks",
                "plan_steps",
                "models.py"
              ],
              "technology_hints": [
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the core logic for 'Stage 0: Hierarchical Planning' by orchestrating the top-down decomposition from a user goal into a nested plan (the reasoning tree), which is the explicit goal of the current task.",
              "sequence_critique": "The sequence is logical. The top-down decomposition (Phases -> Tasks -> Steps) is the correct order for hierarchical planning. The step correctly assumes the agent and models are defined, which is appropriate for an integration task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, a complete function signature, and a numbered, procedural guide for the implementation. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 5": "Create a formal interface for the entire stage that the main system orchestrator will interact with. Create a new file `src/stages/stage_0_planning/main.py`. In this file, define a class `PlanningStage`. This class should have a single public method: `execute(goal: str, output_path: str) -> str`. This method will: \n1. Call the `generate_plan` function from the previous step.\n2. Serialize the resulting `Goal` model to a JSON string.\n3. Save the JSON string to a file named `reasoning_tree.json` at the provided `output_path`.\n4. Return the full path to the created file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning/main.py",
                "PlanningStage",
                "execute",
                "generate_plan",
                "Goal",
                "reasoning_tree.json",
                "output_path"
              ],
              "technology_hints": [
                "Python",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of integrating the planner as Stage 0. Creating a formal class with a standardized `execute` method is the correct approach to make the planner a modular, pluggable component for the main orchestrator. The inputs and outputs defined in the step precisely match the requirements for Stage 0 as described in the overall system architecture.",
              "sequence_critique": "The sequence is logical. The step correctly builds upon a presumed previous step where the core `generate_plan` function was created. The internal sequence of actions within the `execute` method (generate, serialize, save, return path) is also in a correct and logical order.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific file paths, class names, and a fully-typed method signature. The numbered list of implementation requirements is unambiguous and leaves no room for misinterpretation by a coding agent."
            }
          }
        },
        {
          "step 6": "Integrate the `PlanningStage` into the main system orchestrator. Open the main orchestrator file (e.g., `src/orchestrator.py`). Import `PlanningStage` from `src/stages/stage_0_planning/main.py`. In the orchestrator's main execution flow, instantiate `PlanningStage` and call its `execute` method, passing the user's initial goal. Log the path of the returned `reasoning_tree.json` artifact.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "PlanningStage",
                "src/orchestrator.py",
                "src/stages/stage_0_planning/main.py",
                "execute",
                "reasoning_tree.json"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It directly describes the actions required to plug the 'Hierarchical Planner' into the main orchestrator, which is the explicit goal of Task 1.7 and the foundational first stage of the overall system.",
              "sequence_critique": "The sequence of actions within the step (open file, import, instantiate, execute, log) is logical and correct. Assuming prior steps in this task have prepared the `PlanningStage` class for integration, this step fits perfectly as the final integration action.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific file paths, class names (`PlanningStage`), method names (`execute`), expected inputs (user's goal), and the expected output artifact (`reasoning_tree.json`), leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 7": "Review all the new files you've created for Stage 0 (`models.py`, `planner.py`, `main.py`). Identify all new dependencies (e.g., `pydantic`, `openai`) and add them to the project's dependency management file (`pyproject.toml` or `requirements.txt`).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "models.py",
                "planner.py",
                "main.py",
                "pyproject.toml",
                "requirements.txt"
              ],
              "technology_hints": [
                "pydantic",
                "openai",
                "pyproject.toml",
                "requirements.txt"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Integrating a new component (the planner) necessitates declaring its dependencies in the project's dependency file to ensure the overall application can be built and run. This is a crucial and non-negotiable part of the integration task.",
              "sequence_critique": "The sequence is logical. This step correctly occurs after the relevant code files have been created or moved into the project, but before any subsequent steps that would try to install dependencies or run the code.",
              "clarity_critique": "The step is clear and actionable. It specifies exactly which files to review, what to look for (dependencies, with examples), and what action to take (add them to a specific type of file). An AI agent can execute this without ambiguity."
            }
          }
        },
        {
          "step 8": "Finally, create an integration test to verify that Stage 0 works as expected within the orchestrator. Create a test file, for example `tests/test_stage_0.py`. The test should: \n1. Define a sample user goal (e.g., 'build a simple CLI calculator').\n2. Call the main orchestrator's run method with this goal.\n3. Assert that a `reasoning_tree.json` file is created in the expected output directory.\n4. Optionally, load the JSON file and assert that its basic structure is not empty and contains the top-level goal. Use mocks for the LLM calls in `PlannerAgent` to ensure the test is fast and deterministic.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/test_stage_0.py",
                "main orchestrator's run method",
                "reasoning_tree.json",
                "PlannerAgent"
              ],
              "technology_hints": [
                "Python",
                "JSON",
                "mocks"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating an integration test is an essential part of verifying that the 'Hierarchical Planner' has been successfully integrated as Stage 0, which directly supports the task's goal.",
              "sequence_critique": "The sequence is logical. As a final step for the integration task, writing a verification test after the implementation work is the correct order of operations.",
              "clarity_critique": "The instructions are very clear and actionable, especially the specific guidance on mocking LLM calls. However, the word 'Optionally' in sub-step 4 introduces ambiguity for an AI agent; this check should be mandatory to ensure a more thorough and consistent test."
            }
          }
        }
      ],
      "Task 1.8: Implement the 'Interface Architect' agent (Stage 1) to generate the contract document from the planner's output.": [
        {
          "step 1": "First, we need to define the data structures that govern Stage 1. Create a new file at `src/schemas/contract.schema.ts`. Using the `zod` library, define a schema for a single `ModuleContract` and an all-encompassing `CONTRACT_DOCUMENT_SCHEMA` which will be an array of `ModuleContract` schemas. The `ModuleContract` schema should include fields like `name` (string), `purpose` (string), `dependencies` (array of strings), `constructorParams` (array of objects with name and type), `publicAPI` (array of objects representing functions), `promptInstructions` (string), and `acceptanceTests` (array of strings). Ensure all fields are strictly typed.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/contract.schema.ts",
                "ModuleContract",
                "CONTRACT_DOCUMENT_SCHEMA"
              ],
              "technology_hints": [
                "zod"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the contract schema is a foundational and necessary first step for implementing the 'Interface Architect' agent, directly supporting the 'Schema-Enforced Communication' and 'Contract-First Design' principles of the overall system.",
              "sequence_critique": "The sequence is logical. The instruction correctly identifies this as the 'First' step. Defining the output data structure before implementing the agent that generates it is the correct and standard approach. No prerequisite steps are missing.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the file path, library, schema names, and most field types. For maximum clarity, the structure of the objects within the `publicAPI` and `constructorParams` arrays could be more explicitly defined (e.g., specifying the exact keys and types for the objects, like `{ name: z.string(), type: z.string() }`), but the current level of detail is likely sufficient for an AI agent to infer the correct structure."
            }
          }
        },
        {
          "step 2": "Now, create the agent responsible for generating the contract. Create a new file at `src/agents/architect.agent.ts`. Define a class `InterfaceArchitectAgent`. This class should have a constructor that accepts an LLM client (e.g., an instance of `OpenAI`). It will also need a primary public method: `generateContract(reasoningTree: object): Promise<any>`. For now, leave the method implementation empty. Import the schemas you defined in the previous step.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Create a new file at `src/agents/architect.agent.ts`"
              ],
              "key_entities_dependencies": [
                "src/agents/architect.agent.ts",
                "InterfaceArchitectAgent",
                "OpenAI",
                "generateContract(reasoningTree: object): Promise<any>",
                "schemas"
              ],
              "technology_hints": [
                "TypeScript",
                "OpenAI"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the class structure for the `InterfaceArchitectAgent` is the foundational action required to implement the agent described in the task and overall system architecture.",
              "sequence_critique": "The sequence is logical. This step correctly establishes the agent's file and class shell, which is a necessary prerequisite before implementing its internal logic in subsequent steps. The mention of importing schemas from a previous step confirms the logical flow.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They specify the exact file path, class name, constructor signature, and primary method signature, leaving no room for ambiguity. The directive to leave the method empty for now is also a clear instruction for this stage of development."
            }
          }
        },
        {
          "step 3": "The core of the architect agent is the detailed system prompt that guides the LLM. Inside `src/agents/architect.agent.ts`, create a comprehensive `const SYSTEM_PROMPT`. This prompt must instruct the LLM to act as an expert 'Interface Architect'. It should explain that its input is a detailed procedural plan (`reasoning_tree.json`) and its output must be a JSON array of `ModuleContract` objects. Clearly instruct it on how to: 1. Analyze the plan to identify distinct, independent modules. 2. Determine dependencies between modules. 3. Translate procedural steps into declarative `promptInstructions` for a future coding agent. 4. Formulate plain-English `acceptanceTests` from the plan's requirements. 5. Strictly adhere to the JSON output format.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/architect.agent.ts",
                "SYSTEM_PROMPT",
                "reasoning_tree.json",
                "ModuleContract",
                "promptInstructions",
                "acceptanceTests"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of implementing the 'Interface Architect' agent. Creating the system prompt is the core of defining the agent's behavior, and the instructions within the step directly correspond to the agent's responsibilities outlined in the overall system architecture (Stage 1).",
              "sequence_critique": "The sequence is logical. Defining the agent's core system prompt is a foundational and appropriate step in the implementation of an LLM-based agent. It establishes the agent's core logic before the code that calls it is written.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the persona for the LLM, the input and output formats, and provides a precise, numbered list of requirements for the prompt's content. This level of detail is excellent for guiding development."
            }
          }
        },
        {
          "step 4": "Implement the `generateContract` method in `InterfaceArchitectAgent`. This method should: 1. Take the `reasoningTree` object as input. 2. Construct the user prompt by stringifying the `reasoningTree`. 3. Make a call to the LLM using the `SYSTEM_PROMPT` and the user prompt. Configure the LLM call to use its JSON output mode. 4. Receive the response, parse the JSON string into an object, and handle any potential JSON parsing errors. For now, return the parsed object directly.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Make a call to the LLM"
              ],
              "key_entities_dependencies": [
                "generateContract",
                "InterfaceArchitectAgent",
                "reasoningTree",
                "SYSTEM_PROMPT"
              ],
              "technology_hints": [
                "LLM",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing the `generateContract` method is the central action required to create the 'Interface Architect' agent. It directly uses the output of the previous stage (`reasoningTree`) to produce the input for the next, which is the core function of Stage 1 in the overall architecture.",
              "sequence_critique": "The sequence of actions within the step (input -> prompt construction -> LLM call -> parsing) is logical and correct. The instruction to return the parsed object directly for now is a sensible approach for iterative development, correctly deferring the more complex validation checks described in the Stage 1 overview to a subsequent step.",
              "clarity_critique": "The step is exceptionally clear and actionable. It breaks the method's implementation into four distinct, unambiguous instructions. Key details like using the LLM's JSON mode and the explicit scoping ('For now, return the parsed object directly') remove ambiguity and provide precise guidance for implementation."
            }
          }
        },
        {
          "step 5": "Create the validation logic as described in the system architecture. Create a new file `src/validation/contract.validator.ts`. Implement a function `validateContractDocument(contractData: unknown): { success: boolean; data?: any; error?: any }`. This function should first use `CONTRACT_DOCUMENT_SCHEMA.safeParse(contractData)` for schema validation. If that succeeds, it must then perform the 'Architectural Integrity' check: create a Set of all module names and iterate through each module's dependencies, ensuring every dependency string corresponds to a name in the Set. Return a structured result indicating success or failure with detailed errors.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/validation/contract.validator.ts",
                "validateContractDocument",
                "contractData",
                "CONTRACT_DOCUMENT_SCHEMA",
                "CONTRACT_DOCUMENT_SCHEMA.safeParse"
              ],
              "technology_hints": [
                "TypeScript",
                "Set"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. It directly implements the 'Post-Generation Validation' and 'Architectural Integrity' checks described in the Stage 1 architecture, which is a critical part of the system's core philosophy of enforcing strict contracts and verification at every stage.",
              "sequence_critique": "The logical sequence is sound. This validation step is a necessary component of the 'Interface Architect' agent's responsibilities, and creating it as a distinct function is a good design choice. No prerequisite steps appear to be missing.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, a precise function signature, and a detailed, step-by-step algorithm for the validation logic, including the use of a Set for efficient dependency checking. An AI agent can execute this with a high degree of confidence."
            }
          }
        },
        {
          "step 6": "Integrate the validator into the `InterfaceArchitectAgent`. Modify the `generateContract` method in `architect.agent.ts`. After parsing the JSON response from the LLM, pass the resulting object to your new `validateContractDocument` function. If the validation fails, throw a specific, informative error that includes the validation issues. If it succeeds, return the validated contract document. This ensures the agent's output is always guaranteed to be valid.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "InterfaceArchitectAgent",
                "generateContract",
                "architect.agent.ts",
                "validateContractDocument"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. It directly implements the 'Post-Generation Validation' described in Stage 1 and upholds the core philosophy of enforcing strict contracts and schema-based communication, which is crucial for the reliability of the entire system.",
              "sequence_critique": "The logical sequence is correct. Placing the validation check immediately after parsing the LLM's response and before returning the final contract is the ideal point to enforce data integrity. This ensures that any downstream consumer of this agent's output receives a guaranteed-valid contract, preventing errors from propagating.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the exact file (`architect.agent.ts`), method (`generateContract`), and function to call (`validateContractDocument`). The instructions for handling both success (return) and failure (throw an informative error) are explicit and unambiguous, leaving no room for misinterpretation."
            }
          }
        },
        {
          "step 7": "Now, let's wire the new agent into the main orchestrator. In your primary orchestration file (e.g., `src/main.ts` or `src/orchestrator.ts`), add the logic for 'Stage 1'. After successfully generating the `reasoning_tree.json` from Stage 0: 1. Instantiate the `InterfaceArchitectAgent`. 2. Load the `reasoning_tree.json` file. 3. Call the `architectAgent.generateContract()` method with the reasoning tree data. 4. Use a try/catch block to handle potential errors from the agent. 5. Upon success, save the validated contract document to the project's output directory as `contract.json`. Log the progress clearly to the console.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Load the `reasoning_tree.json` file",
                "save the validated contract document to the project's output directory as `contract.json`",
                "Log the progress clearly to the console"
              ],
              "key_entities_dependencies": [
                "src/main.ts",
                "src/orchestrator.ts",
                "reasoning_tree.json",
                "InterfaceArchitectAgent",
                "architectAgent",
                "generateContract()",
                "contract.json"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly addresses the task of implementing the 'Interface Architect' by integrating the newly created agent into the main orchestration flow, which is a critical part of building the foundational framework.",
              "sequence_critique": "The sequence is logical and correct. It correctly positions Stage 1 execution immediately after the successful completion of Stage 0 (generation of `reasoning_tree.json`) and outlines the necessary sub-steps (instantiate, load, call, save) in a coherent order.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They specify the files to modify, the exact sequence of operations, the method to call, the requirement for error handling, and the name and location for the output artifact. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 8": "Finally, write unit tests to ensure the robustness of your new components. Create a test file `src/validation/contract.validator.test.ts`. Write tests for `validateContractDocument` covering a valid contract, a schema-invalid contract, and a contract with a dangling dependency (an architectural integrity failure). Then, create `src/agents/architect.agent.test.ts`. Mock the LLM client and test the `InterfaceArchitectAgent`, ensuring it correctly calls the LLM, parses the response, and invokes the validator, throwing an error when the validator fails.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/validation/contract.validator.test.ts",
                "validateContractDocument",
                "src/agents/architect.agent.test.ts",
                "LLM client",
                "InterfaceArchitectAgent"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Writing unit tests for the validator and the agent is a crucial part of robustly implementing the 'Interface Architect'. It directly supports the overall goal's principles of 'Contract-First Design' and 'Schema-Enforced Communication' by ensuring the contract generation and validation process is reliable.",
              "sequence_critique": "The sequence is logical. As a final step for the task, testing the newly created components is the correct concluding action. Testing the lower-level validator before the higher-level agent that uses it is a standard and sound approach.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies exact file paths, outlines the specific test cases required for the validator (valid, schema-invalid, dangling dependency), and clearly defines the testing strategy for the agent (mocking the LLM, verifying calls, and checking error handling)."
            }
          }
        }
      ],
      "Task 1.9: Implement the automated contract validation logic (Schema, Internal Consistency, Graph Validation).": [
        {
          "step 1": "Create two new files for the contract validation logic: `src/validation/contractValidator.ts` for the implementation and `src/validation/contractValidator.test.ts` for the unit tests. Also, ensure the `ajv` library is installed as a project dependency by running `npm install ajv`. This library will be used for JSON Schema validation.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "run `npm install ajv`"
              ],
              "key_entities_dependencies": [
                "src/validation/contractValidator.ts",
                "src/validation/contractValidator.test.ts",
                "ajv"
              ],
              "technology_hints": [
                "ajv",
                "npm",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the necessary files and installing the `ajv` dependency are foundational actions required to begin implementing the contract validation logic, which is the core of the specified task.",
              "sequence_critique": "The sequence is logical. Setting up the file structure and installing dependencies is the correct prerequisite step before writing the implementation and test code for the validator.",
              "clarity_critique": "The instructions are clear, specific, and highly actionable. It provides exact file paths and the precise command for installing the required dependency, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "In `src/validation/contractValidator.ts`, begin by implementing the schema validation logic. Import the `CONTRACT_DOCUMENT_SCHEMA` from `src/schemas/contractSchema.ts` and the `ModuleContract` type. Create an exported function `validateSchema(data: unknown): { valid: boolean; errors: string[] | null }`. This function should use `ajv` to validate the input data against the `CONTRACT_DOCUMENT_SCHEMA` and return a structured result indicating success or failure with detailed error messages.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/validation/contractValidator.ts",
                "CONTRACT_DOCUMENT_SCHEMA",
                "src/schemas/contractSchema.ts",
                "ModuleContract",
                "validateSchema",
                "data"
              ],
              "technology_hints": [
                "ajv"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly implements the 'Schema Adherence' check described in Stage 1 of the overall goal. It is the first and most fundamental part of the parent Task 1.9, making it perfectly aligned.",
              "sequence_critique": "The sequence is logical. Validating the data's structure against a schema is the necessary first step before performing more complex content-based validations like internal consistency or graph integrity.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file, function signature, input/output types, and the library to be used (`ajv`), leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 3": "Implement the internal consistency validation logic. Create an exported function `validateInternalConsistency(contract: ModuleContract): string[]`. This function will take a single, schema-validated `ModuleContract` object and return an array of error strings. The validation should check for the following: for every parameter listed in `constructorParams`, ensure a corresponding module is listed in the `dependencies` array. If a constructor parameter's type does not match a dependency's `moduleName`, it should be flagged as an error. For example, if a constructor param is `{ name: 'logger', type: 'Logger' }`, there must be a dependency `{ moduleName: 'Logger', ... }`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "validateInternalConsistency",
                "ModuleContract",
                "constructorParams",
                "dependencies",
                "moduleName"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly implements the 'Internal Consistency' validation, a key requirement of the task. It aligns perfectly with the contract-first design and schema-enforced communication principles of the overall system.",
              "sequence_critique": "The step is logically sequenced. It correctly operates on a single, schema-validated contract, which is a necessary prerequisite before performing the subsequent 'Graph Validation' step that will analyze relationships between multiple contracts.",
              "clarity_critique": "The step is clear, but the validation logic is incomplete for a robust dependency-injection framework. It correctly checks that every constructor parameter has a matching dependency. However, it should also perform the reverse check: ensure every item in the `dependencies` array has a corresponding entry in `constructorParams`. This would prevent contracts from declaring 'dead' dependencies that are never injected, making the contract a more precise blueprint for the code generator."
            }
          }
        },
        {
          "step 4": "Implement the architectural integrity (graph) validation logic. Create an exported function `validateArchitecturalIntegrity(contracts: ModuleContract[]): string[]`. This function will take the entire array of module contracts and return an array of error strings. First, create a `Set` of all module names defined in the document for efficient lookups. Then, iterate through each contract and its list of `dependencies`. For each dependency, verify that its `moduleName` exists in the set of defined module names. If a dependency points to a module that is not defined in the contract document, add a descriptive error message to the results.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "validateArchitecturalIntegrity",
                "ModuleContract",
                "contracts",
                "dependencies",
                "moduleName"
              ],
              "technology_hints": [
                "Set"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task's goal of implementing contract validation, specifically addressing the 'Architectural Integrity (Graph Validation)' requirement mentioned in the overall system architecture.",
              "sequence_critique": "The step is incomplete. While it correctly validates that all dependencies exist, it omits a critical part of the 'Architectural Integrity' check defined in the Stage 1 description: 'It also performs a basic cross-module signature check based on the promptInstructions.' This check should be added to the function to fully satisfy the project's definition of architectural integrity.",
              "clarity_critique": "The instructions are highly clear and actionable for the logic that is described. The function signature, data structures, and algorithmic approach for checking dependency existence are specific and easy for an AI agent to implement."
            }
          }
        },
        {
          "step 5": "Create the main orchestrator function for validation. Define an exported function `validateContractDocument(document: unknown): { isValid: boolean; errors: string[] }`. This function will orchestrate the entire validation process by calling the previously created functions in sequence: 1. Call `validateSchema`. If it fails, return immediately with the schema validation errors. 2. If the schema is valid, cast the document to `ModuleContract[]`. 3. Aggregate errors from `validateInternalConsistency` (run for each module) and `validateArchitecturalIntegrity` (run on the whole document). 4. Return a final result object where `isValid` is true only if no errors were found in any stage.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "validateContractDocument",
                "validateSchema",
                "ModuleContract[]",
                "validateInternalConsistency",
                "validateArchitecturalIntegrity"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It creates the main orchestrator function for validation, which is the central objective of the task. This directly supports the overall goal's core principles of 'Contract-First Design' and 'Schema-Enforced Communication' by ensuring the contract is valid before it's used for code generation.",
              "sequence_critique": "The described internal sequence is logical and correct. It correctly prioritizes the fail-fast approach of checking for schema adherence before proceeding to more complex internal consistency and architectural checks. This is an efficient and robust validation strategy.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise function signature, a clear sequence of operations, and specific logic for handling errors and determining the final return value. The level of detail is ideal for an AI coding agent to execute without ambiguity."
            }
          }
        },
        {
          "step 6": "Now, implement comprehensive unit tests in `src/validation/contractValidator.test.ts`. Use a testing framework like Jest. Create mock contract documents for your tests. Your test suite should cover: \n- **Schema Validation:** Test with valid data, data missing required fields, and data with incorrect types. \n- **Internal Consistency:** Test a valid module, and a module where a `constructorParam` has no matching `dependency`. \n- **Architectural Integrity:** Test a valid document with interconnected modules, and a document where a module has a dependency that does not correspond to any other module in the document. \n- **Orchestrator Function:** Test the main `validateContractDocument` to ensure it correctly aggregates errors from all validation stages and returns the expected `isValid` status.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/validation/contractValidator.test.ts",
                "validateContractDocument"
              ],
              "technology_hints": [
                "Jest"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing comprehensive unit tests for the validation logic is a critical part of ensuring the 'Contract-First' and 'Schema-Enforced' principles are robust, which directly supports the overall goal of creating a reliable, production-ready framework.",
              "sequence_critique": "The sequence is logical. This step correctly follows the implied implementation of the validation functions, serving as the quality assurance part of the task. Writing tests after the core logic is a standard and valid development workflow.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the target file, suggests a framework, and provides a detailed, bulleted list of test categories and specific scenarios (both positive and negative cases) to cover. This level of detail is ideal for an AI agent, minimizing ambiguity and ensuring all required validation aspects are tested."
            }
          }
        },
        {
          "step 7": "Finally, review and refactor the code in `src/validation/contractValidator.ts`. Add TSDoc comments to all exported functions, explaining their purpose, parameters, and return values. Ensure that all error messages generated by the validators are clear, specific, and provide enough context to help a user (or another AI agent) understand what needs to be fixed in the contract document.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/validation/contractValidator.ts",
                "exported functions",
                "validators"
              ],
              "technology_hints": [
                "TSDoc"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Ensuring clear, specific, and context-rich error messages is critical for a system designed for autonomous correction loops, as it provides the necessary feedback for a 'corrector' agent to function effectively. Adding TSDoc comments and refactoring supports the creation of a robust and maintainable 'Foundational Framework'.",
              "sequence_critique": "The sequence is logical. This step is explicitly labeled as a final review and refactoring action, which should correctly occur after the initial implementation of the validation logic in preceding steps.",
              "clarity_critique": "The step is clear and actionable. It specifies the exact file to work on (`src/validation/contractValidator.ts`), the type of documentation required (TSDoc), and the specific qualities the error messages must possess. The rationale provided (helping a user or another AI) gives excellent context for the agent performing the task."
            }
          }
        }
      ],
      "Task 1.10: Implement the 'Module Builder' agent (Stage 2) to generate code and tests from a single contract.": [
        {
          "step 1": "Create a new directory `src/agents/module_builder` to house all components related to the Module Builder agent. Also, create an empty `src/agents/module_builder/__init__.py` file to mark it as a Python package.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/module_builder",
                "src/agents/module_builder/__init__.py"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a dedicated directory and package initializer is the standard, necessary first action for organizing the code of a new software component, directly contributing to the task of implementing the 'Module Builder' agent.",
              "sequence_critique": "The sequence is logical. Establishing the file structure is the correct prerequisite before any code for the agent itself is written. This is the foundational action for this task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise directory path (`src/agents/module_builder`) and a specific file to create (`__init__.py`), leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "In the `src/agents/module_builder` directory, create a new file named `schemas.py`. Define a Pydantic model `ModuleGenerationOutput` in this file. This model will enforce the structure of the LLM's response. It must contain two fields: `implementationCode: str` and `testCode: str`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/module_builder",
                "schemas.py",
                "ModuleGenerationOutput",
                "implementationCode",
                "testCode"
              ],
              "technology_hints": [
                "Pydantic",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the core philosophy of 'Schema-Enforced Communication' for the 'Module Builder' agent, which is the focus of the current task. Defining the output structure is a crucial part of creating a reliable agent.",
              "sequence_critique": "The sequence is logical. Defining the data schema for an agent's output is a standard and sound first step before implementing the agent's core logic that will produce or parse that output.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact directory, filename, model name, and field names with their types, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 3": "Create the main agent file at `src/agents/module_builder/agent.py`. Define a class named `ModuleBuilderAgent`. This class should be initialized with an LLM client instance (e.g., `def __init__(self, llm_client)`), which will be used to communicate with the language model.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/module_builder/agent.py",
                "ModuleBuilderAgent",
                "llm_client"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the `ModuleBuilderAgent` class and equipping it with an LLM client is a fundamental and necessary action for implementing the agent described in the task, which is a core component of the Stage 2 workflow.",
              "sequence_critique": "The step is logically sound. Establishing the agent's main file and class structure, including its essential dependency (the LLM client) via the constructor, is the correct foundational step for its implementation.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, and constructor signature, including the purpose of the injected dependency. An AI or human developer would have no ambiguity in executing this instruction."
            }
          }
        },
        {
          "step 4": "Inside the `ModuleBuilderAgent` class, define a constant or a private method to generate the system prompt. This prompt is critical. It must instruct the LLM to act as an expert software engineer on a team, specializing in writing production-quality, dependency-injected TypeScript code. Emphasize that it must only use information from the provided contract and that its output must be a JSON object conforming to the `ModuleGenerationOutput` schema. Include the 'CRITICAL RULES' about not making assumptions and adhering strictly to the contract.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ModuleBuilderAgent",
                "ModuleGenerationOutput",
                "CRITICAL RULES",
                "contract"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. It directly translates the system's core principles\u2014specifically 'Contract-First Design', 'Schema-Enforced Communication', and the rejection of naive generation\u2014into the specific instructions for the 'Module Builder' agent. This is a critical step for ensuring the agent's output adheres to the framework's strict process controls.",
              "sequence_critique": "The step is logically sound. Within the task of implementing the `ModuleBuilderAgent` class, defining the core system prompt is a foundational action that dictates the agent's behavior. It is a necessary prerequisite before implementing the method that actually calls the LLM API.",
              "clarity_critique": "The step is exceptionally clear and actionable. It precisely defines the required persona, technical specifications (dependency injection, TypeScript), constraints (use only the contract), and output format (JSON schema adherence) for the prompt, providing all necessary detail for implementation."
            }
          }
        },
        {
          "step 5": "Implement the main public method `generate_module(self, contract: ModuleContract) -> ModuleGenerationOutput` within the `ModuleBuilderAgent` class. This method will orchestrate the code generation process for a single module.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generate_module",
                "ModuleContract",
                "ModuleGenerationOutput",
                "ModuleBuilderAgent"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing the `generate_module` method is the central and most critical part of fulfilling the task's objective, which is to create an agent that generates code from a contract.",
              "sequence_critique": "The step's placement is logical. In object-oriented programming, defining the main public method that encapsulates the core logic is a standard step that follows the initial class definition and constructor setup. No prerequisite steps appear to be missing for this specific action.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides the exact class name, method name, and a complete, type-hinted function signature (`generate_module(self, contract: ModuleContract) -> ModuleGenerationOutput`), leaving no ambiguity for the developer or AI agent."
            }
          }
        },
        {
          "step 6": "Inside the `generate_module` method, construct the user prompt. This prompt should clearly state the goal: to generate the implementation and test code for the module defined in the provided contract. It should then include the full JSON representation of the `contract` object. Use f-strings or a template engine for clarity. Hint: `contract.model_dump_json(indent=2)` is a good way to serialize the Pydantic model.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generate_module",
                "contract",
                "model_dump_json"
              ],
              "technology_hints": [
                "f-strings",
                "template engine",
                "JSON",
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Constructing a detailed prompt that includes the module's contract is the central mechanism for the 'Module Builder' agent. This directly implements the 'Contract-First Design' and 'Parallel, Isolated Execution' principles outlined in the overall goal.",
              "sequence_critique": "The step is in a logical sequence. Before the system can call an LLM to generate code, it must first construct the prompt that contains all the necessary instructions and data (the contract). This step correctly precedes any API call.",
              "clarity_critique": "The step is clear and actionable, but it could be improved by being more comprehensive. The 'Stage 2' overview mentions the prompt should also contain 'System Context' and 'CRITICAL RULES'. This step should be updated to explicitly mention the inclusion of these elements alongside the contract to ensure the generated prompt fully aligns with the system's architectural design."
            }
          }
        },
        {
          "step 7": "Still within `generate_module`, make the call to the LLM client. Pass the system prompt, the user prompt, and specify that the response format should be a JSON object conforming to the `ModuleGenerationOutput` Pydantic schema. Assume your LLM client has a feature for enforcing JSON output based on a Pydantic model.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generate_module",
                "LLM client",
                "system prompt",
                "user prompt",
                "ModuleGenerationOutput"
              ],
              "technology_hints": [
                "JSON",
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It describes the core action of the 'Module Builder' agent\u2014calling the LLM to generate code\u2014which directly contributes to the task of implementing that agent and aligns with the overall system's goal of generating modules from contracts.",
              "sequence_critique": "The logical sequence is correct. This step naturally follows the preparation of the system and user prompts and precedes the handling of the LLM's response. The phrase 'Still within `generate_module`' correctly places it within the function being implemented.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the inputs (prompts), the expected output format (a Pydantic-enforced JSON), and a critical assumption about the LLM client's capabilities, leaving no room for ambiguity for the implementing agent."
            }
          }
        },
        {
          "step 8": "Add robust error handling to the `generate_module` method. If the LLM response fails to parse as JSON or does not validate against the `ModuleGenerationOutput` schema, raise a custom exception (e.g., `ModuleGenerationError`) that includes the reason for the failure. This is crucial for the orchestrator to handle retries.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generate_module",
                "ModuleGenerationOutput",
                "ModuleGenerationError"
              ],
              "technology_hints": [
                "JSON",
                "LLM"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the core philosophy of 'Schema-Enforced Communication' and provides the necessary failure signaling for the orchestrator to manage the process, which is central to the system's design.",
              "sequence_critique": "The step is logically sequenced. Error handling is a critical refinement that should be added to any function interacting with an external, non-deterministic service like an LLM. Placing it within the implementation task for the `generate_module` method is appropriate.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the location (`generate_module` method), the trigger conditions (JSON parsing/schema validation failure), the exact action (raise a custom exception), a suggested name (`ModuleGenerationError`), and the rationale (enabling retries). This leaves no room for ambiguity."
            }
          }
        },
        {
          "step 9": "Create a unit test file `tests/agents/test_module_builder_agent.py`. Write a test case to verify the `ModuleBuilderAgent`'s behavior. Use `unittest.mock` to mock the LLM client. Create a sample `ModuleContract` instance to use as input for your tests.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/agents/test_module_builder_agent.py",
                "ModuleBuilderAgent",
                "LLM client",
                "ModuleContract"
              ],
              "technology_hints": [
                "unittest.mock"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Writing unit tests is a fundamental and critical part of implementing a robust software component like the 'Module Builder' agent. Mocking the LLM client is a key best practice that ensures the test focuses on the agent's logic (e.g., prompt construction, output parsing) rather than the non-deterministic and external LLM service, which aligns with the overall philosophy of enforcing strict process controls.",
              "sequence_critique": "The step is logically sound. In a typical development workflow, creating unit tests is an integral part of the implementation task. Assuming the basic class structure for `ModuleBuilderAgent` was defined in a preceding step, writing its test is the next logical action.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to be created, the testing methodology (unit tests with a mocked client using `unittest.mock`), and the required test fixtures (a sample `ModuleContract`). This level of detail is ideal for an AI agent to execute without ambiguity."
            }
          }
        },
        {
          "step 10": "In your test file, write a specific test to ensure `generate_module` calls the mocked LLM client with the correctly formatted system and user prompts. Assert that the user prompt contains the JSON representation of the sample contract.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generate_module",
                "mocked LLM client",
                "system and user prompts",
                "sample contract"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Testing that the Module Builder agent correctly formats its prompt to the LLM is a fundamental and critical part of implementing this agent, directly contributing to the task and the overall system's reliability.",
              "sequence_critique": "The sequence is logical. This step represents a core unit test for the agent's primary function (prompt construction). It correctly focuses on verifying the input to the LLM before dealing with the output, which is a standard and robust testing practice.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the function to test (`generate_module`), the interaction to verify (calling the mocked LLM), and the precise assertion to make (the user prompt contains the contract's JSON). This is unambiguous for an AI agent."
            }
          }
        },
        {
          "step 11": "Write another test case where you configure the mocked LLM client to return a valid JSON string that matches the `ModuleGenerationOutput` schema. Call `generate_module` and assert that it returns a correctly parsed `ModuleGenerationOutput` object with the expected code and test strings.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "mocked LLM client",
                "ModuleGenerationOutput",
                "generate_module"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. The task is to implement the 'Module Builder' agent, which must parse a response from an LLM. This step tests the primary success case\u2014that the agent can correctly parse a valid, schema-compliant response. This directly supports the overall goal's principle of 'Schema-Enforced Communication'.",
              "sequence_critique": "The step represents a logical and necessary unit test (the 'happy path'). Assuming prior steps set up the testing framework and the function signature, this step fits correctly within the development sequence for the task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It precisely describes the test setup (mocking the LLM client with valid JSON), the action to perform (calling the function), and the specific assertions to make (verifying the returned object's type and content). It follows the standard Arrange-Act-Assert pattern, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 12": "Finally, write a test case for failure. Configure the mocked LLM client to return malformed JSON or a JSON object with missing fields. Assert that a call to `generate_module` raises the expected custom exception (e.g., `ModuleGenerationError`).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "mocked LLM client",
                "generate_module",
                "ModuleGenerationError"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "This step is perfectly aligned. It directly supports the core philosophy of 'Schema-Enforced Communication' by ensuring the system robustly handles non-compliant LLM outputs, which is a critical aspect of building a reliable agent-based framework.",
              "sequence_critique": "The sequence is logical. The use of the word 'Finally' correctly implies that this error-handling test should be written after the primary 'happy path' functionality has been tested and verified.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact failure conditions to simulate (malformed JSON, missing fields) and the expected outcome (raising a specific custom exception), leaving no room for ambiguity."
            }
          }
        }
      ],
      "Task 1.11: Add parallel execution logic to the orchestrator to invoke multiple Module Builder agents concurrently.": [
        {
          "step 1": "First, analyze the existing orchestrator codebase. Locate the specific function or method responsible for executing 'Stage 2: Module Implementation'. This method likely iterates through an array of `ModuleContract` objects and calls a `ModuleBuilder` agent for each one sequentially using `await` inside a loop. Identify the file and the function signature that will be refactored.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "orchestrator codebase",
                "Stage 2: Module Implementation",
                "ModuleContract",
                "ModuleBuilder"
              ],
              "technology_hints": [
                "await"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Identifying the specific code block responsible for sequential execution is the necessary first action before refactoring it for parallel execution as described in Stage 2 of the overall goal.",
              "sequence_critique": "The sequence is logical. This is the correct and essential first step in any refactoring task: locating and understanding the target code.",
              "clarity_critique": "The step is exceptionally clear and actionable. It not only directs the agent to locate the relevant function but also provides a highly specific hint about the implementation pattern to look for ('await inside a loop'), which significantly reduces ambiguity and increases the likelihood of success."
            }
          }
        },
        {
          "step 2": "Refactor the identified method to enable parallel execution. Modify the logic from a sequential `for...of` loop to a parallel approach using `Promise.allSettled`. Use the `Array.prototype.map` function on the input `ModuleContract[]` array to create an array of promises, where each promise represents the asynchronous call to the `ModuleBuilder` agent for one contract. Then, use `await Promise.allSettled(...)` to wait for all agent calls to complete.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ModuleContract[]",
                "ModuleBuilder"
              ],
              "technology_hints": [
                "Promise.allSettled",
                "Array.prototype.map"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. The choice of `Promise.allSettled` directly implements the 'Parallel, Isolated Execution' core principle and provides the necessary resilience for the subsequent 'Verification' stage, where individual module failures must be handled without halting the entire batch.",
              "sequence_critique": "The sequence is logical. The described pattern of using `map` to create an array of promises and `Promise.allSettled` to await their completion is a correct and standard implementation for this task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact JavaScript methods (`Promise.allSettled`, `Array.prototype.map`) and the required refactoring from a `for...of` loop, leaving no room for misinterpretation by an AI agent."
            }
          }
        },
        {
          "step 3": "After awaiting `Promise.allSettled`, process the results. The result will be an array of settlement objects. Create logic to iterate through this array. Separate the results into two new collections: one for successfully generated modules (where `status` is 'fulfilled') and one for build failures (where `status` is 'rejected'). For failures, make sure to capture the error `reason` and associate it with the contract that failed.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Promise.allSettled",
                "settlement objects",
                "status",
                "reason",
                "contract"
              ],
              "technology_hints": [
                "JavaScript",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Processing the results of parallel execution is a fundamental part of the task. Robustly handling both successes and failures is critical for the overall system's 'factory assembly line' philosophy, setting the stage for the subsequent verification and correction loops.",
              "sequence_critique": "The sequence is logical. This step correctly follows the dispatch and awaiting of parallel promises (`Promise.allSettled`) and is a necessary prerequisite for any subsequent stage, such as verification or integration, which needs to know which modules were successfully generated.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact function to use (`Promise.allSettled`), describes the expected data structure of the results, and provides explicit instructions for processing both success (`fulfilled`) and failure (`rejected`) cases, including the critical detail of associating errors with the failed contract."
            }
          }
        },
        {
          "step 4": "Update the data structures and logging within the orchestrator. Ensure that the collections of successful and failed modules are stored appropriately in the orchestrator's state to be used by 'Stage 3: Verification, Correction, and Integration'. Add clear logging to indicate the start of the parallel build process, the total number of modules to be built, and a summary of the results (e.g., 'Build complete: 5 modules succeeded, 1 module failed.').",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "orchestrator",
                "collections of successful and failed modules",
                "orchestrator's state",
                "Stage 3: Verification, Correction, and Integration"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Managing the results of the parallel execution (storing successful/failed modules) is a critical part of the task. It also directly supports the input requirements for the subsequent 'Stage 3', demonstrating strong alignment with the overall system workflow.",
              "sequence_critique": "The step is logically sequenced. After implementing the parallel invocation of agents (presumably in prior steps), the next logical action is to collect, categorize, and log the results of those parallel operations. This step correctly handles that state management.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies exactly what needs to be stored (collections of successful/failed modules), where (orchestrator's state), and provides a concrete example of the required logging output, which removes ambiguity for the implementing agent."
            }
          }
        },
        {
          "step 5": "Create or update unit tests to validate the new parallel execution logic. Use a mocking framework (like Jest) to mock the `ModuleBuilder` agent. The test should: \n1. Provide a list of mock contracts (e.g., three contracts).\n2. Configure the mock to simulate both successful resolutions and at least one rejection.\n3. Assert that the `ModuleBuilder` agent was called for every contract.\n4. Verify that the orchestrator correctly processes the results from `Promise.allSettled`, correctly populating the 'successful' and 'failed' module collections.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ModuleBuilder",
                "Promise.allSettled",
                "successful module collection",
                "failed module collection"
              ],
              "technology_hints": [
                "Jest"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating robust unit tests that specifically validate the handling of concurrent successes and failures is essential for implementing the 'Parallel, Isolated Execution' principle mentioned in the overall goal. It directly supports the task of adding reliable parallel execution logic.",
              "sequence_critique": "The step's placement is logical. It serves as the validation for the implementation steps that would precede it. Writing tests after implementing the core logic is a standard and sound development sequence.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the testing framework (Jest), the exact component to mock (`ModuleBuilder`), and provides a precise, numbered list of test case requirements, including setup (mock contracts), behavior simulation (success/rejection), and specific assertions (call count, correct result categorization). This level of detail is ideal for an AI agent."
            }
          }
        }
      ],
      "Task 1.12: Implement the 'Integrator' agent (Stage 3) to perform topological sort and generate the main entry point file.": [
        {
          "step 1": "Create a new file at `src/agents/integrator.ts`. In this file, define a class named `IntegratorAgent`. This class will be responsible for assembling the final project. Import the `ModuleContract` and `VerifiedModule` types from `src/types/contract.ts` (you may need to create a `VerifiedModule` type which is essentially a `ModuleContract` plus the `implementationCode` and `testCode` strings). The `IntegratorAgent` should have a constructor that accepts an array of `VerifiedModule` objects.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/integrator.ts",
                "IntegratorAgent",
                "ModuleContract",
                "src/types/contract.ts",
                "VerifiedModule",
                "implementationCode",
                "testCode"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the `IntegratorAgent` class and defining its constructor to accept `VerifiedModule` objects is the correct foundational action for implementing the agent described in Stage 3.",
              "sequence_critique": "The sequence is logical. Establishing the class structure and its data dependencies (`VerifiedModule`) is the necessary prerequisite before implementing the agent's core logic, such as the topological sort.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the exact file path, class name, and constructor signature. The instruction to create a `VerifiedModule` type, including its composition, is explicit and removes ambiguity."
            }
          }
        },
        {
          "step 2": "Inside the `IntegratorAgent` class, implement a private method `_buildDependencyGraph(modules: VerifiedModule[]): Map<string, string[]>`. This method should create an adjacency list representation of the module dependency graph. The keys of the map should be the module names, and the values should be an array of their dependency names, extracted from the `dependencies` field of each module's contract.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "IntegratorAgent",
                "_buildDependencyGraph",
                "VerifiedModule",
                "dependencies",
                "contract"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dependency graph is the foundational data structure required to perform a topological sort, which is the central responsibility of the 'Integrator' agent.",
              "sequence_critique": "The sequence is logical. Building the graph representation of dependencies is the necessary first action before any sorting algorithm can be applied. This step correctly precedes the implementation of the sort itself.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method signature, including input and output types, and provides unambiguous instructions on how to construct the adjacency list from the input modules' contracts."
            }
          }
        },
        {
          "step 3": "Implement a private method `_topologicalSort(graph: Map<string, string[]>): string[]`. This method will perform a topological sort on the dependency graph built in the previous step. You can use Kahn's algorithm or a DFS-based approach. The method should return an array of module names in the correct instantiation order. Crucially, it must detect cyclic dependencies and throw an `Error` if a cycle is found, as this indicates an unresolvable architectural flaw.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_topologicalSort",
                "graph",
                "Error"
              ],
              "technology_hints": [
                "Map"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing a topological sort is a fundamental and necessary requirement for the 'Integrator' agent, which must assemble modules in the correct dependency order. Detecting cycles is a critical part of ensuring architectural integrity, which directly supports the system's core philosophy of enforcing strict controls.",
              "sequence_critique": "The logical sequence appears correct. The step explicitly refers to a dependency graph 'built in the previous step,' correctly positioning this sorting logic after data preparation and before the final code generation that will use the sorted output.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise method signature, suggests valid algorithms (Kahn's, DFS), defines the expected output format, and includes the critical requirement to handle cyclic dependencies by throwing an error. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 4": "Implement a method `generateMainEntryPoint(sortedModules: string[], allModules: VerifiedModule[]): string`. This method will generate the content for the main entry point file (e.g., `src/main.ts`). It should iterate through the `sortedModules` array. For each module name, it must: 1. Generate an import statement like `import { ${moduleName} } from './${moduleName}';`. 2. Generate an instantiation statement like `const ${moduleName.toLowerCase()} = new ${moduleName}(...dependencies);`. The dependencies to be injected into the constructor must be determined from the `constructorParams` field in the module's contract.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generateMainEntryPoint",
                "sortedModules",
                "allModules",
                "VerifiedModule",
                "constructorParams",
                "src/main.ts"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task's goal of generating a main entry point file. It directly implements the core 'Final Assembly' logic described in Stage 3 of the overall system architecture, which is to instantiate all verified modules in the correct dependency order.",
              "sequence_critique": "The sequence is logical. The step correctly assumes a prerequisite action (topological sort) has been completed, as it takes a `sortedModules` array as input. The internal logic of generating imports before instantiating classes is also correct for a valid source file.",
              "clarity_critique": "The step is highly clear and actionable. It provides a precise method signature, specifies the iteration process, and includes concrete examples for code generation. Crucially, it directs the agent to the exact data source (`constructorParams` in the module's contract) needed to resolve constructor dependencies, leaving little room for ambiguity."
            }
          }
        },
        {
          "step 5": "Implement a method `generatePackageJson(projectName: string, modules: VerifiedModule[]): string`. This method will generate the content for the `package.json` file. It should create a basic structure including `name`, `version`, `main`, and `scripts` (e.g., a 'start' script: 'ts-node src/main.ts'). For now, include `typescript`, `ts-node`, and `@types/node` as default devDependencies. In the future, this could be expanded to parse dependencies from module code.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generatePackageJson",
                "projectName",
                "modules",
                "VerifiedModule",
                "package.json",
                "main.ts"
              ],
              "technology_hints": [
                "package.json",
                "ts-node",
                "typescript",
                "@types/node"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Generating the `package.json` is explicitly mentioned as a core responsibility of the 'Integrator' agent in the Stage 3 description, contributing directly to the task of creating a complete, runnable project.",
              "sequence_critique": "The step is logically sound and self-contained. As a method implementation, its exact order relative to other file-generation methods (like for README or tsconfig) within the 'Integrator' task is not critical. No prerequisite steps are missing for this specific function.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method signature, the required JSON keys (`name`, `version`, `main`, `scripts`), provides a concrete example for the 'start' script, and lists the exact `devDependencies` to include. This leaves very little room for ambiguity."
            }
          }
        },
        {
          "step 6": "Implement a method `generateTsConfig(): string`. This method will generate a standard `tsconfig.json` file content as a string. Configure it with reasonable defaults for a modern Node.js project, including `\"target\": \"ES2020\"`, `\"module\": \"commonjs\"`, `\"rootDir\": \"./src\"`, `\"outDir\": \"./dist\"`, and `\"strict\": true`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "generateTsConfig",
                "tsconfig.json"
              ],
              "technology_hints": [
                "Node.js",
                "tsconfig.json",
                "ES2020",
                "commonjs"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. The overall system description for Stage 3 explicitly states that the 'Integrator' agent is responsible for generating supporting files, including 'tsconfig.json'. This directly contributes to the task of implementing the Integrator and the overall goal of producing a complete, production-ready project.",
              "sequence_critique": "The step is a self-contained method implementation within the larger 'Integrator' agent. Its sequence is logical, as it does not depend on other parts of the Integrator (like the topological sort) to be implemented first.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific method name (`generateTsConfig`), return type (`string`), and the exact key-value pairs (`\"target\": \"ES2020\"`, `\"module\": \"commonjs\"`, etc.) to include, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 7": "Implement a public method `assembleProject(projectName: string, userGoal: string): Map<string, string>`. This method will orchestrate the entire integration process. It should: 1. Call `_buildDependencyGraph` and `_topologicalSort`. 2. Call the generation methods for `main.ts`, `package.json`, and `tsconfig.json`. 3. Create a map where keys are file paths (e.g., `src/main.ts`, `package.json`, `src/moduleA.ts`, `src/moduleA.test.ts`) and values are the string contents of those files. Include all the verified module implementation and test files in this map. This map represents the complete project file system.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "assembleProject",
                "_buildDependencyGraph",
                "_topologicalSort",
                "main.ts",
                "package.json",
                "tsconfig.json"
              ],
              "technology_hints": [
                "ts",
                "json"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned with the task. It describes the main orchestration method for the 'Integrator' agent, which correctly encapsulates the final assembly process of building the dependency graph, generating key files, and packaging all source code into a virtual file system. This directly contributes to the Stage 3 goal of producing a complete project.",
              "sequence_critique": "The internal sequence of operations is logical. Building and sorting the dependency graph is a necessary prerequisite for generating the `main.ts` file, and assembling the final file map is correctly positioned as the last action. No issues found.",
              "clarity_critique": "The step is mostly clear but has a critical omission in its proposed method signature. The `assembleProject` method needs the collection of verified module implementation and test files as an input to include them in the final file map. The current signature `(projectName: string, userGoal: string)` does not account for this. The signature should be updated to accept the verified modules as a parameter, for example: `assembleProject(projectName: string, userGoal: string, verifiedModules: VerifiedModule[])`."
            }
          }
        },
        {
          "step 8": "Create a new test file at `src/agents/integrator.test.ts`. Write comprehensive unit tests for the `IntegratorAgent` class using a testing framework like Jest. Your tests should cover the following scenarios: 1. A valid set of modules is topologically sorted correctly. 2. An error is thrown for a direct cyclic dependency (A -> B, B -> A). 3. An error is thrown for a transitive cyclic dependency (A -> B, B -> C, C -> A). 4. `generateMainEntryPoint` produces a correctly formatted string with proper imports and dependency-injected instantiations. 5. The `assembleProject` method returns a map containing all expected file paths and non-empty content.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/integrator.test.ts",
                "IntegratorAgent",
                "generateMainEntryPoint",
                "assembleProject"
              ],
              "technology_hints": [
                "Jest"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Writing comprehensive unit tests for the `IntegratorAgent` directly supports the task of implementing it and aligns with the overall system's core philosophy of verification and reliability.",
              "sequence_critique": "The sequence is logical. Placing unit testing after the initial implementation (presumably in prior steps of this task) is a standard and correct software development practice.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the file path, a suggested framework, and a detailed, numbered list of required test scenarios covering core functionality and critical edge cases (like cyclic dependencies). This provides excellent guidance."
            }
          }
        }
      ],
      "Task 1.13: Implement the final file assembler to create the complete project directory structure with all generated files.": [
        {
          "step 1": "Create a new file `src/core/models/file_system_models.py`. In this file, define the Pydantic models that will represent the inputs for the file assembler. Create two models: `VerifiedModule` with fields `module_name: str`, `implementation_code: str`, and `test_code: str`; and `IntegratorOutput` with fields `main_ts: str`, `package_json: str`, `tsconfig_json: str`, and `readme_md: str`. These models will ensure type-safe data handling.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/core/models/file_system_models.py",
                "VerifiedModule",
                "IntegratorOutput"
              ],
              "technology_hints": [
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Defining the input data models (`VerifiedModule`, `IntegratorOutput`) is a foundational and necessary prerequisite for building the 'final file assembler' and aligns with the system's principle of schema-enforced communication.",
              "sequence_critique": "The sequence is logical. Defining data models before implementing the logic that operates on them is a standard and correct practice. This is an appropriate first step for the task.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The prompt specifies the exact file path, technology (Pydantic), model names, and field definitions with their types, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "Create a new file `src/core/file_assembler.py`. Define a class `FileAssembler`. This class will be responsible for creating the final project directory structure. Import the models from `file_system_models.py`. The class should be initialized with a base output directory path (e.g., `output_dir: Path`).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/core/file_assembler.py",
                "FileAssembler",
                "file_system_models.py",
                "output_dir",
                "Path"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a dedicated `FileAssembler` class is the foundational action required to implement the 'Final Assembly' process described in the overall goal's Stage 3.",
              "sequence_critique": "The step is logically sound. Creating the class definition and its constructor is the correct initial action for this implementation task, establishing the component's structure before its methods are defined.",
              "clarity_critique": "The instructions are highly clear and actionable. The prompt specifies the exact file, class name, and constructor signature (including the parameter and type hint), leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 3": "In the `FileAssembler` class, create a primary public method: `assemble_project(self, modules: List[VerifiedModule], integrator_output: IntegratorOutput) -> Path`. This method will orchestrate the entire file assembly process. As the first step within this method, implement the logic to create the necessary directory structure: the root project directory, a `src` subdirectory, and a `src/__tests__` subdirectory. Use the `pathlib` library for all path operations and ensure directories are created with `exist_ok=True`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "FileAssembler",
                "assemble_project",
                "modules",
                "VerifiedModule",
                "integrator_output",
                "IntegratorOutput",
                "Path",
                "src",
                "src/__tests__"
              ],
              "technology_hints": [
                "pathlib"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the primary method for the `FileAssembler` and then implementing the initial directory creation logic is a direct and essential contribution to assembling the final project directory.",
              "sequence_critique": "The sequence is logical. Establishing the primary method and then implementing its first required action (creating the directory structure before files can be written) is the correct and necessary order of operations.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the class, method signature with type hints, exact directories to create, and technical implementation details (use `pathlib`, set `exist_ok=True`), which removes ambiguity for the AI agent."
            }
          }
        },
        {
          "step 4": "Within the `assemble_project` method, implement the logic to write the module files. Iterate through the `modules` list. For each `VerifiedModule`, write the `implementation_code` to `src/{module.module_name}.ts` and the `test_code` to `src/__tests__/{module.module_name}.test.ts`. Ensure you handle file paths correctly using `pathlib`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "write the `implementation_code` to `src/{module.module_name}.ts`",
                "write the `test_code` to `src/__tests__/{module.module_name}.test.ts`"
              ],
              "key_entities_dependencies": [
                "assemble_project",
                "modules",
                "VerifiedModule",
                "implementation_code",
                "test_code",
                "module.module_name"
              ],
              "technology_hints": [
                "pathlib",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly addresses the core requirement of the task, which is to place the generated source and test files into the correct directory structure as part of the final project assembly.",
              "sequence_critique": "The step's placement appears logical. It correctly assumes that a list of verified modules is available and focuses on writing their contents to disk. This would naturally follow steps that create the root project directory and necessary subdirectories like `src/` and `src/__tests__/`.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method, the data structure to iterate over (`VerifiedModule`), the properties to use (`implementation_code`, `test_code`, `module_name`), the precise file naming and path conventions, and even recommends a specific library (`pathlib`) for implementation. There is no ambiguity."
            }
          }
        },
        {
          "step 5": "Next, still within the `assemble_project` method, implement the logic to write the files generated by the integrator. Use the `integrator_output` object to write `package.json`, `tsconfig.json`, and `readme.md` to the root of the project directory. Write the `main_ts` content to `src/main.ts`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "assemble_project",
                "integrator_output",
                "package.json",
                "tsconfig.json",
                "readme.md",
                "main_ts",
                "src/main.ts"
              ],
              "technology_hints": [
                "package.json",
                "tsconfig.json",
                "Markdown (.md)",
                "TypeScript (.ts)"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly supports the task of assembling the final project by writing the key configuration and entry-point files. It is perfectly aligned with the task and the overall system goal.",
              "sequence_critique": "The sequence is logical. It correctly assumes that the necessary output directories (e.g., the project root and `src/`) have been created in a prior step. It handles a discrete, logical part of the file assembly process.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the input data object (`integrator_output`), the content to be written (e.g., `main_ts`), and the exact destination file paths, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 6": "Add a new public method to the `FileAssembler` class: `create_archive(self, source_dir: Path, archive_name: str) -> Path`. This method should take the path to the assembled project directory and create a `.zip` archive of it. Use the `shutil.make_archive` function for this. The `assemble_project` method should call this new method at the end and return the path to the generated zip file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "FileAssembler",
                "create_archive",
                "Path",
                "shutil.make_archive",
                "assemble_project"
              ],
              "technology_hints": [
                "shutil",
                ".zip"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly supports the overall goal of producing a 'complete, downloadable project archive (.zip)' and is a logical final action for the 'File Assembler' task.",
              "sequence_critique": "The step is logically placed at the end of the assembly process. It correctly assumes the project directory has already been created before attempting to archive it.",
              "clarity_critique": "The instructions are highly clear and actionable. They specify the exact class, method signature, implementation library (`shutil.make_archive`), and integration point within the existing `assemble_project` method."
            }
          }
        },
        {
          "step 7": "Create a new test file `tests/core/test_file_assembler.py`. Write comprehensive unit tests for the `FileAssembler` class using `pytest`. Use the `tmp_path` fixture to create a temporary directory for testing. Your tests should: \n1. Instantiate `FileAssembler`.\n2. Create mock `VerifiedModule` and `IntegratorOutput` objects.\n3. Call `assemble_project`.\n4. Verify that the expected directory structure (`src`, `src/__tests__`) was created.\n5. Verify that all files (`module.ts`, `module.test.ts`, `main.ts`, `package.json`, etc.) exist in the correct locations.\n6. Verify that the content of at least one of each type of file matches the mock input data.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/core/test_file_assembler.py",
                "FileAssembler",
                "tmp_path",
                "VerifiedModule",
                "IntegratorOutput",
                "assemble_project",
                "src",
                "src/__tests__",
                "module.ts",
                "module.test.ts",
                "main.ts",
                "package.json"
              ],
              "technology_hints": [
                "pytest",
                "Python",
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Writing comprehensive unit tests for the `FileAssembler` is a critical part of implementing it, ensuring it correctly performs the final assembly described in Stage 3 of the overall goal.",
              "sequence_critique": "The sequence is logical. The sub-steps for writing the test (instantiate, mock, call, verify) are in a correct and standard order. This step logically follows the initial implementation of the `FileAssembler` class, which is presumed to have occurred in a prior step of this task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact test file, the testing framework (`pytest`), the appropriate fixture (`tmp_path`), and provides a detailed, numbered checklist of assertions to implement, covering directory structure, file existence, and file content. This leaves very little room for ambiguity."
            }
          }
        },
        {
          "step 8": "Refactor the `FileAssembler` and its tests for clarity and robustness. Add comprehensive docstrings to all classes and methods, explaining their purpose, arguments, and return values. Ensure logging is added to the `assemble_project` method to provide visibility into the assembly process (e.g., 'Creating directory structure...', 'Writing module file: logger.ts...', 'Project assembly complete.').",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "FileAssembler",
                "assemble_project",
                "logger.ts"
              ],
              "technology_hints": [
                "logging",
                "docstrings",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Refactoring, documenting, and adding logging are crucial activities for making the `FileAssembler` a robust and maintainable component, which directly supports the task of implementing it and the overall goal of creating a production-ready framework.",
              "sequence_critique": "The sequence is logical. This step acts as a final polishing and hardening phase for the `FileAssembler`, which should correctly occur after the initial implementation and basic tests are in place from previous steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact actions to take (refactor, add docstrings, add logging), where to perform them (the `FileAssembler` class, its tests, the `assemble_project` method), and provides concrete examples for the logging output, leaving no room for ambiguity."
            }
          }
        }
      ]
    },
    "Phase 2: Implementation of Planning and Contract Generation (Stages 0 & 1)": {
      "1.1: Set up the main project structure and the high-level orchestrator to manage the pipeline stages.": [
        {
          "step 1": "Initialize a new Node.js project using TypeScript. Install necessary dependencies for the project foundation and for schema validation.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Initialize a new Node.js project using TypeScript",
                "Install necessary dependencies for the project foundation and for schema validation"
              ],
              "key_entities_dependencies": [],
              "technology_hints": [
                "Node.js",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Initializing a Node.js/TypeScript project is the essential first action for the task of setting up the project structure. The specific mention of installing dependencies for schema validation directly supports the system's core principles of 'Schema-Enforced Communication' and 'Contract-First Design'.",
              "sequence_critique": "The sequence is logical. This is the correct foundational step that must precede any other development activity within the task, such as creating directories or writing the orchestrator code.",
              "clarity_critique": "The step is clear and actionable. It specifies the technology stack (Node.js, TypeScript) and a key functional requirement (schema validation), which is specific enough for an AI agent to execute by running standard initialization commands and selecting a suitable schema validation library (e.g., zod, ajv)."
            }
          }
        },
        {
          "step 2": "Create the core directory structure to organize the project. This structure will house schemas, core logic like the orchestrator, individual pipeline stages, and generated output artifacts.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "schemas",
                "orchestrator",
                "pipeline stages",
                "generated output artifacts"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a core directory structure is a fundamental and necessary action for 'setting up the main project structure'.",
              "sequence_critique": "The sequence is logical. Establishing the directory structure is a prerequisite for subsequent steps where files for the orchestrator, schemas, and pipeline stages will be created.",
              "clarity_critique": "The step clearly states the purpose of the directories. However, it lacks specificity regarding the exact names of the directories to be created (e.g., 'src', 'schemas', 'output'). For an AI agent, providing a concrete list of directory names would make the instruction more deterministic and actionable, ensuring a consistent project layout."
            }
          }
        },
        {
          "step 3": "Define the JSON schemas that enforce the structure of data passed between stages. Start by creating the schemas for the `reasoning_tree.json` (output of Stage 0) and the `ModuleContract[]` (output of Stage 1) using the 'zod' library. Place these in the `src/schemas/` directory.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "reasoning_tree.json",
                "ModuleContract[]",
                "src/schemas/"
              ],
              "technology_hints": [
                "JSON",
                "zod"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the foundational principle of \"Schema-Enforced Communication\" mentioned in the overall goal. Defining the data contracts (`reasoning_tree.json`, `ModuleContract[]`) is a critical prerequisite for building the orchestrator and the individual pipeline stages (Stages 0 & 1) as described in the current task and phase.",
              "sequence_critique": "The sequence is logical. Defining the data schemas before implementing the logic that produces or consumes them is a sound software engineering practice. It establishes the 'contracts' for data flow early in the development process, which is essential for building a robust orchestrator.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies what to create (schemas for `reasoning_tree.json` and `ModuleContract[]`), the technology to use ('zod' library), and the exact location for the output (`src/schemas/` directory), leaving no room for ambiguity."
            }
          }
        },
        {
          "step 4": "Define a generic TypeScript interface for a pipeline stage. This will ensure that all stages (Planning, Contract Generation, etc.) have a consistent `execute` method, making them interchangeable and easy to manage within the orchestrator. Create this in a new `src/core/` directory.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "execute method",
                "orchestrator",
                "src/core/ directory"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a generic interface for a pipeline stage is a foundational and crucial step for building a \"high-level orchestrator to manage the pipeline stages.\" This abstraction is essential for the plug-and-play nature of the described system architecture.",
              "sequence_critique": "The sequence is logical. Defining a core interface that other components will depend on is a sound software engineering practice. This step correctly precedes or runs concurrently with the implementation of the orchestrator itself.",
              "clarity_critique": "The step is clear and actionable. It specifies what to create (a generic TypeScript interface), why it's needed (consistency, interchangeability), what it should contain (an `execute` method), and where it should be located (`src/core/`). This is sufficient detail for an AI agent to proceed effectively."
            }
          }
        },
        {
          "step 5": "Create the main `Orchestrator` class. This class will be responsible for managing the entire pipeline, executing each stage in the correct order, and passing data between them. For now, create a skeleton class with a `run` method in `src/core/Orchestrator.ts`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Orchestrator",
                "run",
                "src/core/Orchestrator.ts"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the `Orchestrator` class is the central action required to 'set up the high-level orchestrator to manage the pipeline stages.'",
              "sequence_critique": "The step is logically sound. Creating the main orchestrator class is a foundational action for this task, and it's reasonable to assume that preceding steps have set up the basic project and directory structure.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the class name (`Orchestrator`), its purpose, the file path (`src/core/Orchestrator.ts`), and the required initial structure (a skeleton class with a `run` method)."
            }
          }
        },
        {
          "step 6": "Create a placeholder implementation for Stage 0, the `PlanningStage`. This class should implement the `IStage` interface. For now, its `execute` method will not call an LLM but will instead return a hardcoded, mock `reasoning_tree` object that conforms to the schema you created. It should also save this mock object to `artifacts/reasoning_tree.json`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "save this mock object to `artifacts/reasoning_tree.json`"
              ],
              "key_entities_dependencies": [
                "PlanningStage",
                "IStage",
                "execute",
                "reasoning_tree",
                "artifacts/reasoning_tree.json"
              ],
              "technology_hints": [
                "LLM",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "Excellent. Creating a mock for Stage 0 is a pragmatic and essential step. It allows the high-level orchestrator to be built and tested without a dependency on a fully functional, LLM-driven planning stage, directly contributing to the task of setting up the pipeline structure.",
              "sequence_critique": "The step is logically sequenced. Assuming prior steps have defined the project structure, the `IStage` interface, and the necessary data schemas, creating a concrete (mock) implementation for the first stage is the correct next action. It provides the necessary output for developing and testing the subsequent `Contract Generation` stage.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the class name (`PlanningStage`), the interface to implement (`IStage`), the exact behavior of the `execute` method (use a hardcoded mock, conform to a schema), and the required side-effect (save the artifact to a specific file path). There is no ambiguity."
            }
          }
        },
        {
          "step 7": "Create a placeholder implementation for Stage 1, the `ContractStage`. This class will also implement the `IStage` interface. Its `execute` method will take the reasoning tree data as input and return a hardcoded array of mock `ModuleContract` objects conforming to your contract schema. Save the output to `artifacts/contracts.json`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ContractStage",
                "IStage",
                "execute",
                "reasoning tree data",
                "ModuleContract",
                "contract schema",
                "artifacts/contracts.json"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned. Creating a placeholder for the `ContractStage` is a crucial and pragmatic step towards building the high-level orchestrator. It allows the pipeline's flow to be developed and tested by providing a predictable, schema-compliant output for the next stage, without needing the full complexity of the actual contract generation logic yet.",
              "sequence_critique": "The step's position in the plan is logical. It correctly follows the presumed setup of the project and orchestrator shell. Building placeholder stages sequentially allows for the incremental construction and testing of the overall pipeline from one stage to the next.",
              "clarity_critique": "The step is exceptionally clear and actionable. It precisely defines the class name (`ContractStage`), the interface to implement (`IStage`), the input for the `execute` method, the nature of the output (hardcoded mock objects), the required schema for that output, and the final action of saving the result to a specific file."
            }
          }
        },
        {
          "step 8": "Integrate the placeholder stages into the `Orchestrator`. In the `run` method of the orchestrator, instantiate and execute the `PlanningStage` and `ContractStage` sequentially. Ensure the output of the planning stage is passed as the input to the contract stage. Log the final output to the console.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Orchestrator",
                "run",
                "PlanningStage",
                "ContractStage"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step directly contributes to the task of setting up the orchestrator by implementing its core sequential logic for the first two stages. It aligns perfectly with the phase goal and the overall system architecture.",
              "sequence_critique": "The sequence is logical. It correctly specifies that the Planning Stage must execute before the Contract Stage, and that the output of the former becomes the input for the latter, which matches the overall system workflow.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method (`run`), the classes to instantiate (`PlanningStage`, `ContractStage`), the execution order, the data flow between them, and the final action (logging), making it unambiguous for an AI agent."
            }
          }
        },
        {
          "step 9": "Create the main application entry point file, `src/index.ts`. This file will instantiate the `Orchestrator` and invoke its `run` method with a sample high-level user goal. This will make the project runnable.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/index.ts",
                "Orchestrator",
                "run"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a runnable entry point that instantiates and executes the `Orchestrator` is a critical and direct contribution to the task of setting up the project and the high-level orchestrator.",
              "sequence_critique": "The step is logically sequenced. It serves as the final action in the setup task, tying together the previously defined components (like the Orchestrator class) to make the entire application executable for the first time.",
              "clarity_critique": "The instruction is exceptionally clear and actionable. It specifies the exact file to create (`src/index.ts`), the precise actions to perform (instantiate `Orchestrator`, call `run`), and the necessary input (a sample goal), leaving no room for ambiguity."
            }
          }
        },
        {
          "step 10": "Finalize the project setup by adding essential configuration files. Create a `.gitignore` file to exclude `node_modules` and `dist`. Also, create a basic `README.md` file explaining what the project is, how to install dependencies (`npm install`), and how to run the orchestrator (`npx ts-node src/index.ts`).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                ".gitignore",
                "node_modules",
                "dist",
                "README.md",
                "src/index.ts"
              ],
              "technology_hints": [
                ".gitignore",
                "npm",
                "npx",
                "ts-node"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a `.gitignore` and a `README.md` are essential final actions for the task of 'Set up the main project structure'. The README's content, specifically how to run the orchestrator, directly contributes to the task's goal.",
              "sequence_critique": "The step is logically placed as a finalization action for the initial project setup task. It makes sense to create these files after the core directory structure and entry point (`src/index.ts`) have been established by previous steps.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The prompt specifies the exact files to create (`.gitignore`, `README.md`), the specific content for the gitignore (`node_modules`, `dist`), and the precise commands to include in the README, making it unambiguous for an AI agent."
            }
          }
        }
      ],
      "1.2: Integrate the existing 'Hierarchical Planner' project as the engine for Stage 0.": [
        {
          "step 1": "First, let's establish a clean directory structure for the planning stage within the new project. Create a new top-level directory `src/stage-0-planning`. Inside this new directory, create three subdirectories: `services`, `schemas`, and `utils`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stage-0-planning",
                "services",
                "schemas",
                "utils"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a dedicated and structured directory for Stage 0 is a logical and necessary prerequisite for the task of integrating the existing 'Hierarchical Planner' project.",
              "sequence_critique": "The sequence is correct. Establishing the directory structure is the ideal first action to take before any code is moved, adapted, or written for the integration.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides precise, unambiguous paths and directory names, making it easy for an AI agent to execute without misinterpretation."
            }
          }
        },
        {
          "step 2": "Now, copy the core logic files from the existing 'Hierarchical Planner' project. Locate the source files responsible for the planning logic (e.g., `Planner.ts`, `PhasePlanner.ts`, `TaskPlanner.ts`, `StepPlanner.ts`) and copy them into the newly created `src/stage-0-planning/services` directory. Copy any associated helper/utility functions into `src/stage-0-planning/utils`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Copy the core logic files from the existing 'Hierarchical Planner' project"
              ],
              "key_entities_dependencies": [
                "'Hierarchical Planner' project",
                "Planner.ts",
                "PhasePlanner.ts",
                "TaskPlanner.ts",
                "StepPlanner.ts",
                "src/stage-0-planning/services",
                "src/stage-0-planning/utils"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Copying the core logic files is a fundamental and necessary action to achieve the task of integrating the existing 'Hierarchical Planner' project into the new system for Stage 0.",
              "sequence_critique": "The sequence is logical, assuming a prior step created the target directories (`src/stage-0-planning/services`, `src/stage-0-planning/utils`). Copying files into a pre-existing structure is the correct order of operations.",
              "clarity_critique": "The step is mostly clear, providing examples of files to copy and specific destination directories. However, it is critically ambiguous about the source location. It states 'from the existing `Hierarchical Planner` project' without providing a relative or absolute path, which is not actionable for an automated agent."
            }
          }
        },
        {
          "step 3": "The planner's output is governed by strict schemas. Copy the TypeScript/Zod schema definition files for the `reasoning_tree` and its sub-components from the planner project into the `src/stage-0-planning/schemas` directory. Create an `index.ts` file within `src/stage-0-planning/schemas` to export all the schema types and definitions for easy importing elsewhere in the project.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Copy the TypeScript/Zod schema definition files for the `reasoning_tree` and its sub-components from the planner project"
              ],
              "key_entities_dependencies": [
                "reasoning_tree",
                "planner project",
                "src/stage-0-planning/schemas",
                "index.ts"
              ],
              "technology_hints": [
                "TypeScript",
                "Zod"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Integrating the planner requires handling its output, and the system's core philosophy mandates 'Schema-Enforced Communication'. This step directly implements that principle by bringing the planner's output schemas into the new system, ensuring robust, verifiable data transfer from Stage 0 to Stage 1.",
              "sequence_critique": "The step is in a logical sequence. Establishing the data contracts (schemas) for the planner's output is a foundational prerequisite before writing the orchestration code that will call the planner and parse its results. This step correctly prioritizes defining 'what' the data looks like before implementing 'how' to use it.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact source content (`reasoning_tree` schemas), the precise destination directory (`src/stage-0-planning/schemas`), and the required action (copying files and creating a barrel `index.ts` for exports). The instructions are specific enough for an AI agent to execute without ambiguity."
            }
          }
        },
        {
          "step 4": "To integrate the planner into the main application, we need a clean interface. Create a new file named `planning.facade.ts` inside `src/stage-0-planning`. In this file, define a class named `PlanningFacade`. This class will serve as the single entry point for the orchestrator to interact with the entire planning stage.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "planning.facade.ts",
                "src/stage-0-planning",
                "PlanningFacade",
                "orchestrator",
                "planner"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "Excellent alignment. Creating a facade is a key software engineering pattern for cleanly integrating a complex subsystem, which is the core of this task. This directly contributes to the overall goal of a robust, modular system.",
              "sequence_critique": "The sequence is logical. Defining the interface (the facade) is a proper first step before implementing the orchestrator code that will use it.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific instructions on the file name, location, and class name, along with crucial context on its architectural purpose as a 'single entry point'."
            }
          }
        },
        {
          "step 5": "Implement the `PlanningFacade` class. It should have a constructor that accepts any necessary configuration, such as an LLM client instance (e.g., an OpenAI client), to facilitate dependency injection. Create a single public async method: `generatePlan(userGoal: string): Promise<ReasoningTree>`. The type `ReasoningTree` should be imported from your schemas. Inside this method, adapt the logic from the original planner's main execution script. You will need to instantiate the various planner classes you copied in step 2, pass them the LLM client from the constructor, and chain them together to perform the full Goal -> Phases -> Tasks -> Steps decomposition. The method must return the final plan, validated against its Zod schema.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "PlanningFacade",
                "LLM client instance",
                "generatePlan",
                "ReasoningTree",
                "original planner's main execution script",
                "various planner classes you copied in step 2",
                "Zod schema"
              ],
              "technology_hints": [
                "OpenAI",
                "Zod"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task of integrating the existing planner. Creating a `PlanningFacade` is an excellent design pattern for this purpose, and the specified method signature and return type directly correspond to the functional requirements of Stage 0.",
              "sequence_critique": "The step's placement seems logical. It correctly assumes that prerequisite steps (like copying the necessary planner classes, as referenced) have already been completed, and it focuses on creating the 'glue code' to integrate those classes into the new system.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific names, method signatures, and design patterns (dependency injection, Facade). The instruction to validate the output against a Zod schema is a precise and testable requirement, aligning with the project's core principles."
            }
          }
        },
        {
          "step 6": "Merge the dependencies from the 'Hierarchical Planner' project. Open the `package.json` from the original planner project, identify all its `dependencies` and `devDependencies` (e.g., `zod`, LLM SDKs), and add them to the `package.json` of this new project. After updating the file, run `npm install` to fetch and install the new packages.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "run `npm install` to fetch and install the new packages"
              ],
              "key_entities_dependencies": [
                "package.json",
                "dependencies",
                "devDependencies"
              ],
              "technology_hints": [
                "npm",
                "zod",
                "LLM SDKs"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Making the planner's dependencies available is a core requirement for integrating it as an engine for Stage 0.",
              "sequence_critique": "The sequence is logical. The project's dependencies must be declared and installed before the integrated code can be successfully run or tested.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The step specifies the source file (`package.json` from the original project), the exact data to extract (`dependencies` and `devDependencies`), the action (add to the new project's `package.json`), and the final command to execute (`npm install`)."
            }
          }
        },
        {
          "step 7": "Refactor the copied planner services for better modularity. Go through the files in `src/stage-0-planning/services` and remove any direct instantiation of LLM clients or hardcoded access to environment variables for API keys or model names. Modify the constructors of these classes to accept the LLM client as a parameter, which will be passed down from the `PlanningFacade`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stage-0-planning/services",
                "LLM clients",
                "PlanningFacade"
              ],
              "technology_hints": [
                "LLM"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Refactoring the services to accept an LLM client via dependency injection is a crucial and standard practice for integrating a standalone component into a larger, modular framework. This directly supports the task of integration and upholds the overall system's core philosophy of creating decoupled, controllable components.",
              "sequence_critique": "The step's position is logical. This refactoring must happen after the planner's source code has been copied into the new project structure and before the `PlanningFacade` attempts to instantiate and use these services. It is a necessary prerequisite for the facade to manage dependencies correctly.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the target directory (`src/stage-0-planning/services`), the exact anti-patterns to remove (direct instantiation, hardcoded environment variables), and the precise pattern to implement (modifying constructors to accept the client). This level of detail is ideal for an AI agent or human developer."
            }
          }
        },
        {
          "step 8": "To verify the integration, create a test script. Create a new file at `src/scripts/run-planning-stage.ts`. In this script, import the `PlanningFacade`. Instantiate your LLM client (you can use a library like `dotenv` to load API keys from a `.env` file for this script). Then, instantiate `PlanningFacade` with the client. Define a sample `userGoal` (e.g., 'Build a real-time chat application with a React frontend'). Call the `generatePlan` method and log the resulting JSON plan to the console. Also, save the output to a file named `reasoning_tree.json` in the project's root directory to inspect the artifact.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "load API keys from a `.env` file",
                "save the output to a file named `reasoning_tree.json`"
              ],
              "key_entities_dependencies": [
                "src/scripts/run-planning-stage.ts",
                "PlanningFacade",
                "LLM client",
                ".env",
                "userGoal",
                "generatePlan",
                "reasoning_tree.json"
              ],
              "technology_hints": [
                "dotenv",
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a verification script that runs the integrated component and produces its designated artifact (`reasoning_tree.json`) is a direct and essential action to confirm the successful completion of the task ('Integrate the existing... planner'). This directly contributes to the overall goal by completing a key part of Stage 0.",
              "sequence_critique": "The sequence is logical. This step serves as a validation test, which should naturally occur after the initial integration work (e.g., file copying, dependency installation) is presumed to be complete. The internal sequence of actions within the script (instantiate client, instantiate facade, call method, save output) is also correct.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class names (`PlanningFacade`), method names (`generatePlan`), and output artifacts (`reasoning_tree.json`). It also provides helpful, concrete suggestions like using `dotenv` for API key management, making it unambiguous for an AI agent to execute."
            }
          }
        },
        {
          "step 9": "Finalize the integration by performing a cleanup and review. Add comprehensive JSDoc comments to the `PlanningFacade` class and its public `generatePlan` method, clearly documenting its purpose, parameters, and return value. Double-check that all file imports across the new `stage-0-planning` module use correct relative paths. Finally, delete any extraneous files that were copied from the old project but are no longer needed (e.g., its old `README.md`, `package.json`, `.gitignore`, or CLI entry point).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Delete any extraneous files that were copied from the old project but are no longer needed (e.g., its old `README.md`, `package.json`, `.gitignore`, or CLI entry point)."
              ],
              "key_entities_dependencies": [
                "PlanningFacade",
                "generatePlan",
                "stage-0-planning",
                "README.md",
                "package.json",
                ".gitignore"
              ],
              "technology_hints": [
                "JSDoc"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step's actions\u2014adding documentation, verifying import paths, and cleaning up unneeded files\u2014are all crucial for successfully and cleanly finalizing the integration of an external project. The step is perfectly aligned with the task of integration and the overall goal of building a robust system.",
              "sequence_critique": "As a finalization and cleanup step, its position at the end of the integration task is logical. The internal sequence of documenting, checking, and then deleting is also sound.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. It specifies the exact class (`PlanningFacade`) for documentation, the scope of the path check (`stage-0-planning` module), and provides concrete examples of extraneous files to delete, making the requirements unambiguous for an execution agent."
            }
          }
        }
      ],
      "1.3: Implement the Stage 0 orchestrator logic, including the sequence of prompts for Goal-to-Phases, Phase-to-Tasks, and Task-to-Steps decomposition.": [
        {
          "step 1": "First, set up the directory structure and define the data schemas for Stage 0. Create a new directory `src/stages/stage_0_planning`. Inside this directory, create a file named `schemas.py`. In `schemas.py`, use the Pydantic library to define the data models for the hierarchical plan. You will need four classes: `Step`, `Task`, `Phase`, and `PlanningTree`. The structure should be hierarchical: `PlanningTree` contains a list of `Phase` objects, each `Phase` contains a list of `Task` objects, and each `Task` contains a list of `Step` objects. Each class should have an `id` and a `description` field. For example, `Step(id: str, description: str)`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning",
                "schemas.py",
                "Step",
                "Task",
                "Phase",
                "PlanningTree"
              ],
              "technology_hints": [
                "Pydantic",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing the Stage 0 orchestrator requires a defined data structure for its output (the planning tree). This step creates those exact Pydantic schemas, which directly supports the task and the overall system's core principle of 'Schema-Enforced Communication'.",
              "sequence_critique": "The sequence is logical. Defining the data models is the correct and necessary first step before writing any logic that would populate or manipulate them. It establishes the foundation for the rest of the task's implementation.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific instructions on directory structure, file names, technology to use (Pydantic), class names, hierarchical relationships, and the exact fields required for each class, including an example. An AI agent would have no trouble executing this."
            }
          }
        },
        {
          "step 2": "Now, create the prompt templates that will be used to guide the LLM at each decomposition stage. In the `src/stages/stage_0_planning` directory, create a new file named `prompts.py`. Define three string constants in this file: `GOAL_TO_PHASES_PROMPT`, `PHASE_TO_TASKS_PROMPT`, and `TASK_TO_STEPS_PROMPT`. Each prompt must explicitly instruct the LLM to return a JSON object with a specific key (e.g., `phases`, `tasks`, `steps`) containing a list of objects, each with `id` and `description` fields. This is critical for enforcing the schema.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning",
                "prompts.py",
                "GOAL_TO_PHASES_PROMPT",
                "PHASE_TO_TASKS_PROMPT",
                "TASK_TO_STEPS_PROMPT",
                "phases",
                "tasks",
                "steps",
                "id",
                "description"
              ],
              "technology_hints": [
                "Python",
                "LLM",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating prompt templates for decomposition is a direct and essential action for implementing the Stage 0 orchestrator logic, which in turn serves the overall goal of hierarchical planning and schema-enforced communication.",
              "sequence_critique": "The sequence is logical. Defining the prompts is a natural prerequisite before writing the orchestrator code that will use them. This step fits correctly within the task of implementing the Stage 0 logic.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the exact directory, filename, constant names, and, most importantly, the required JSON output structure for the LLM. This level of detail is excellent for ensuring the 'Schema-Enforced Communication' principle is met."
            }
          }
        },
        {
          "step 3": "To ensure modularity, create a simple abstraction for interacting with the LLM. Create a new directory `src/llm`. Inside it, create `llm_adapter.py`. Define an abstract base class `LLMAdapter` with an abstract method `generate_json(prompt: str) -> dict`. Then, create a concrete implementation, for instance, `MockLLMAdapter`, that inherits from `LLMAdapter`. For now, this mock adapter can return pre-defined, structured JSON responses that match the expected output for each prompt type. This will allow you to build and test the orchestrator logic without making real LLM calls.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/llm",
                "llm_adapter.py",
                "LLMAdapter",
                "generate_json(prompt: str) -> dict",
                "MockLLMAdapter"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing the orchestrator logic requires interacting with an LLM. Creating an abstraction (`LLMAdapter`) and a mock version (`MockLLMAdapter`) is a critical and standard practice that decouples the core logic from a specific LLM implementation. This allows the orchestrator's flow to be developed and tested reliably and efficiently, directly contributing to the task's goal.",
              "sequence_critique": "The sequence is logical. It is standard practice to define and build a dependency (the LLM adapter) before implementing the component that will use it (the main orchestrator logic). This allows the orchestrator to be built against a stable, predictable interface from the start.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact directory and file names (`src/llm/llm_adapter.py`), class names (`LLMAdapter`, `MockLLMAdapter`), the abstract method signature (`generate_json(prompt: str) -> dict`), and the purpose of the mock. The instructions are unambiguous and can be executed directly."
            }
          }
        },
        {
          "step 4": "Create the main orchestrator for Stage 0. In `src/stages/stage_0_planning`, create a file named `planner.py`. Define a class `Stage0Planner`. The constructor should accept an instance of `LLMAdapter`. The class should have a main public method `execute(user_goal: str) -> PlanningTree` and private helper methods for each decomposition stage: `_generate_phases`, `_generate_tasks_for_phase`, and `_generate_steps_for_task`. Initialize an empty `PlanningTree` object in the `execute` method.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage_0_planning",
                "planner.py",
                "Stage0Planner",
                "LLMAdapter",
                "execute",
                "PlanningTree",
                "_generate_phases",
                "_generate_tasks_for_phase",
                "_generate_steps_for_task"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It establishes the primary class structure (`Stage0Planner`) that will orchestrate the hierarchical decomposition process described in Stage 0, directly contributing to the task's goal of implementing the orchestrator logic.",
              "sequence_critique": "The step is in a logical sequence. Creating the skeleton class structure with its main public method and private helpers is a necessary prerequisite before implementing the detailed LLM-calling logic within those helpers. This assumes that dependent types like `LLMAdapter` and `PlanningTree` have been defined in previous steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, constructor dependencies, and method signatures (including visibility, parameter names, and type hints), leaving no ambiguity for an AI coding agent."
            }
          }
        },
        {
          "step 5": "Implement the `_generate_phases(self, user_goal: str) -> list[Phase]` method in the `Stage0Planner` class. This method should: 1. Format the `GOAL_TO_PHASES_PROMPT` with the `user_goal`. 2. Call the `generate_json` method of the `llm_adapter`. 3. Parse the returned dictionary, access the `phases` key, and use Pydantic's `parse_obj_as` to validate and convert the list of dictionaries into a list of `Phase` model instances. Include robust error handling for JSON parsing and Pydantic validation errors.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_generate_phases",
                "user_goal",
                "Phase",
                "Stage0Planner",
                "GOAL_TO_PHASES_PROMPT",
                "generate_json",
                "llm_adapter",
                "phases",
                "parse_obj_as"
              ],
              "technology_hints": [
                "Pydantic",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the first part of the Goal-to-Phases-to-Tasks-to-Steps decomposition, which is the core responsibility of the current task (1.3) and the foundational action of Stage 0.",
              "sequence_critique": "The sequence is logical. Implementing the `_generate_phases` method is the correct first step in building the hierarchical planner's orchestration logic. The internal sequence (format prompt, call LLM, parse/validate) is also correct and standard practice.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the class, method signature, exact functions to call (`generate_json`, `parse_obj_as`), data models to use (`Phase`), and explicit error handling requirements, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 6": "Implement the `_generate_tasks_for_phase(self, phase: Phase) -> list[Task]` method. This method will be called within a loop in the main `execute` method. It should: 1. Format the `PHASE_TO_TASKS_PROMPT` with the `phase.description`. 2. Call the `llm_adapter.generate_json` method. 3. Parse and validate the response to produce a list of `Task` objects, similar to the previous step. Handle potential errors gracefully.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_generate_tasks_for_phase",
                "phase",
                "Phase",
                "Task",
                "execute",
                "PHASE_TO_TASKS_PROMPT",
                "phase.description",
                "llm_adapter",
                "llm_adapter.generate_json"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing the `_generate_tasks_for_phase` method is a crucial and direct component of the task, which is to build the Stage 0 orchestrator for hierarchical decomposition (Phase-to-Tasks).",
              "sequence_critique": "The logical sequence is correct. This step naturally follows the generation of Phases and precedes the generation of Steps, fitting perfectly into the top-down decomposition workflow outlined in the Stage 0 description.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method signature, input/output types, the prompt to use, the function to call, and the need for validation and error handling, leaving no ambiguity for the implementer."
            }
          }
        },
        {
          "step 7": "Implement the `_generate_steps_for_task(self, task: Task) -> list[Step]` method. This will be called in a nested loop for each task. It should: 1. Format the `TASK_TO_STEPS_PROMPT` with the `task.description`. 2. Call the `llm_adapter.generate_json` method. 3. Parse and validate the response to produce a list of `Step` objects. Ensure error handling is in place.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_generate_steps_for_task",
                "task",
                "Task",
                "Step",
                "TASK_TO_STEPS_PROMPT",
                "task.description",
                "llm_adapter.generate_json"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing the `_generate_steps_for_task` method is the final and most granular part of the 'Task-to-Steps decomposition' process, which is a core requirement of the current task (1.3) and the overall Stage 0 planning architecture.",
              "sequence_critique": "The step is logically sequenced. It correctly follows the hierarchical decomposition pattern (Goal -> Phases -> Tasks -> Steps), and its placement within a nested loop that iterates over tasks is the correct implementation approach for the orchestrator.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact method signature, the prompt to use, the adapter method to call, the expected output type (`list[Step]`), and the necessity of validation and error handling. The instructions are unambiguous."
            }
          }
        },
        {
          "step 8": "Complete the implementation of the main `execute(self, user_goal: str) -> PlanningTree` method in `Stage0Planner`. This method orchestrates the entire process. It should: 1. Call `_generate_phases` to get the initial list of phases. 2. Iterate through each generated `Phase`, call `_generate_tasks_for_phase` for it, and assign the resulting list of `Task` objects to the phase. 3. Perform a nested iteration through each `Task` within each `Phase`, call `_generate_steps_for_task`, and assign the resulting `Step` objects to the task. 4. Return the fully populated `PlanningTree` object.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "execute",
                "user_goal",
                "PlanningTree",
                "Stage0Planner",
                "_generate_phases",
                "Phase",
                "_generate_tasks_for_phase",
                "Task",
                "_generate_steps_for_task",
                "Step"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It directly describes the core orchestration logic for the hierarchical decomposition (Goal -> Phases -> Tasks -> Steps) that defines Stage 0, which is the explicit goal of the current task.",
              "sequence_critique": "The sequence is logical and correct. It follows the required top-down decomposition approach: phases are generated first, then tasks are generated for each phase, and finally steps are generated for each task. This order is essential for building the planning tree correctly.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the method signature, the class, and provides a precise, numbered list of operations including iteration logic and data assignment. An AI agent or human developer could implement this method directly from the description with no ambiguity."
            }
          }
        },
        {
          "step 9": "Create a main entry point to run the Stage 0 planner and generate the `reasoning_tree.json` artifact. Create a `main.py` file in the root directory of the project. This script should: 1. Instantiate the `MockLLMAdapter` and the `Stage0Planner`. 2. Define a sample `user_goal` string (e.g., 'Build a real-time chat application with a React frontend'). 3. Call the `planner.execute()` method with the goal. 4. Serialize the returned `PlanningTree` object to a JSON file named `reasoning_tree.json` in a new `./artifacts` directory, using the `.model_dump_json(indent=2)` method from Pydantic for pretty-printing.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "main.py",
                "MockLLMAdapter",
                "Stage0Planner",
                "user_goal",
                "planner.execute()",
                "PlanningTree",
                "reasoning_tree.json",
                "./artifacts",
                ".model_dump_json(indent=2)"
              ],
              "technology_hints": [
                "Python",
                "Pydantic",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a main entry point to execute the planner and generate its key artifact (`reasoning_tree.json`) is the logical conclusion for a task focused on implementing the Stage 0 orchestrator logic. It directly contributes to the overall goal by producing the necessary input for Stage 1.",
              "sequence_critique": "The sequence is logical. The step correctly assumes that the `Stage0Planner` and its dependencies have been implemented in prior steps. The internal flow (instantiate, define input, execute, save output) is standard and correct for a main script.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact filename (`main.py`), location (root), classes to instantiate, methods to call (`planner.execute`, `.model_dump_json`), output artifact name (`reasoning_tree.json`), output directory (`./artifacts`), and even formatting details (`indent=2`). This level of specificity is ideal for an AI agent."
            }
          }
        },
        {
          "step 10": "Write unit tests to ensure the `Stage0Planner` works correctly. Create a `tests/` directory at the project root, and inside it, a `test_stage_0_planning.py` file. Use the `pytest` framework and `unittest.mock`. Your tests should: 1. Mock the `LLMAdapter`. 2. Configure the mock to return specific JSON payloads for each type of prompt. 3. Call the `planner.execute()` method. 4. Assert that the resulting `PlanningTree` object is structured correctly and contains the expected data based on the mock responses. This validates your parsing, validation, and tree-building logic independently of the LLM.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "Stage0Planner",
                "tests/",
                "test_stage_0_planning.py",
                "LLMAdapter",
                "planner.execute()",
                "PlanningTree"
              ],
              "technology_hints": [
                "pytest",
                "unittest.mock",
                "JSON",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Writing unit tests for the `Stage0Planner` is a crucial part of implementing the orchestrator logic, ensuring its parsing and tree-building capabilities are robust and correct, which directly supports the overall goal of a verifiable, reliable system.",
              "sequence_critique": "The sequence is logical. Unit testing is a standard and necessary step that should occur after the initial implementation of the code being tested. Placing this after the core logic is written is the correct order of operations.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the testing framework (`pytest`), the mocking library (`unittest.mock`), the file structure, and the precise testing strategy (mocking the LLM adapter, providing sample payloads, and asserting the output). This leaves very little room for ambiguity."
            }
          }
        }
      ],
      "1.4: Define the final JSON schema for the `reasoning_tree.json` artifact and implement the logic to assemble and save it.": [
        {
          "step 1": "Create a new file at `src/schemas/planning_schemas.py`. In this file, define the Pydantic models that will represent the structure of the `reasoning_tree.json` artifact. This ensures all planning output conforms to a strict, verifiable schema. The hierarchy should be `ReasoningTree` -> `Phase` -> `Task` -> `Step`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/planning_schemas.py",
                "reasoning_tree.json",
                "ReasoningTree",
                "Phase",
                "Task",
                "Step"
              ],
              "technology_hints": [
                "Pydantic",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining Pydantic models is a standard and effective method for creating a verifiable JSON schema, which directly addresses the task of defining the `reasoning_tree.json` structure. This aligns with the project's core principle of \"Schema-Enforced Communication.\"",
              "sequence_critique": "The logical sequence is correct. Defining the data structure (the schema) is the necessary prerequisite before implementing the logic to assemble and save data conforming to that structure. This is the correct first step for the given task.",
              "clarity_critique": "The step is clear and highly actionable. It specifies the exact file to create, the technology to use (Pydantic), the purpose of the models, and the required hierarchical structure (`ReasoningTree` -> `Phase` -> `Task` -> `Step`), providing sufficient detail for an AI agent to execute successfully."
            }
          }
        },
        {
          "step 2": "Implement the Pydantic models in `src/schemas/planning_schemas.py`. Use the `pydantic.BaseModel` and `pydantic.Field` for clear definitions. The models should be as follows:\n\n- `Step`: Contains `step_number: int` and `description: str`.\n- `Task`: Contains `task_number: str` (e.g., '1.1', '2.3'), `description: str`, and `steps: list[Step]`.\n- `Phase`: Contains `phase_number: int`, `description: str`, and `tasks: list[Task]`.\n- `ReasoningTree`: This is the root model. It should contain `goal: str` and `phases: list[Phase]`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/planning_schemas.py",
                "pydantic.BaseModel",
                "pydantic.Field",
                "Step",
                "Task",
                "Phase",
                "ReasoningTree"
              ],
              "technology_hints": [
                "Pydantic",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly contributes to the task's primary goal of defining the JSON schema for the `reasoning_tree.json` artifact. The specified Pydantic models (`ReasoningTree`, `Phase`, `Task`, `Step`) perfectly mirror the hierarchical decomposition structure outlined in 'Stage 0: Hierarchical Planning', ensuring strong alignment with the overall system architecture.",
              "sequence_critique": "The step is logically sequenced. Defining the data structure (the Pydantic models) is a necessary prerequisite before implementing any logic to assemble or save an instance of that structure. This step correctly establishes the foundation for the rest of the task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, the required library (Pydantic), the base classes to use, and a precise definition for each model, including field names and data types. This level of detail minimizes ambiguity and is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 3": "Create a new file at `src/planning/tree_assembler.py`. Define a class named `TreeAssembler` that will be responsible for progressively building the reasoning tree object in memory during the planning stage.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/planning/tree_assembler.py",
                "TreeAssembler",
                "reasoning tree object"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a `TreeAssembler` class is a direct and necessary action to fulfill the task's requirement of implementing logic to assemble the `reasoning_tree.json` artifact.",
              "sequence_critique": "The step is logically sequenced. Establishing the primary class responsible for assembly is a foundational action for implementing the broader assembly logic.",
              "clarity_critique": "The step is clear and actionable. It specifies the file path, class name, and the class's core responsibility, providing sufficient detail for an AI agent to execute the task correctly."
            }
          }
        },
        {
          "step 4": "Implement the `TreeAssembler` class in `src/planning/tree_assembler.py`. It should manage the state of the planning process.\n\n- **Imports:** Import the Pydantic models from `src/schemas/planning_schemas.py`.\n- **`__init__`:** The constructor should accept the high-level `goal: str` and initialize empty lists to hold the plan's components (e.g., `self.phases = []`).\n- **State Management:** Implement methods to add components to the tree. These methods will be called by the planner as it generates each part of the plan:\n  - `add_phase(self, description: str)`: Appends a new `Phase` to `self.phases`. It should automatically assign the correct `phase_number`.\n  - `add_task(self, description: str)`: Appends a new `Task` to the *current* phase. It should automatically assign the correct `task_number` (e.g., '1.1', '1.2').\n  - `add_step(self, description: str)`: Appends a new `Step` to the *current* task. It should automatically assign the correct `step_number`.\n- **Hint:** You will need to maintain internal counters to track the current phase, task, and step numbers to ensure they are assigned sequentially.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "TreeAssembler",
                "src/planning/tree_assembler.py",
                "src/schemas/planning_schemas.py",
                "Phase",
                "Task",
                "Step",
                "add_phase",
                "add_task",
                "add_step"
              ],
              "technology_hints": [
                "Pydantic"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a `TreeAssembler` class is a direct and necessary implementation for programmatically building the `reasoning_tree.json` artifact, which is the core objective of the task.",
              "sequence_critique": "The step's position seems logical, assuming the Pydantic schemas it depends on were defined in a preceding step, as is implied by the instructions.",
              "clarity_critique": "The instructions are clear, specific, and highly actionable for an AI agent. The description of methods, their responsibilities (like auto-numbering), and the hint about internal counters are excellent. The prompt could be made microscopically more explicit by stating *how* to access the 'current' phase/task (e.g., 'append to the tasks list of the last phase in `self.phases`'), but a capable agent can reliably infer this from the current wording."
            }
          }
        },
        {
          "step 5": "Implement the final assembly and serialization method in the `TreeAssembler` class. \n\n- **Method:** Create a method `build_and_save(self, output_path: str = 'reasoning_tree.json')`.\n- **Logic:** This method should:\n  1. Construct the final `ReasoningTree` Pydantic object using the `goal` and the `self.phases` list that have been built up.\n  2. Serialize the `ReasoningTree` object to a nicely formatted JSON string. Hint: Use the `.model_dump_json(indent=2)` method from Pydantic.\n  3. Write the resulting JSON string to the specified `output_path`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "TreeAssembler",
                "build_and_save",
                "reasoning_tree.json",
                "ReasoningTree",
                "goal",
                "self.phases",
                ".model_dump_json(indent=2)"
              ],
              "technology_hints": [
                "Pydantic",
                "JSON",
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Implementing a `build_and_save` method is the logical conclusion to the task of \"implement the logic to assemble and save\" the `reasoning_tree.json`. This artifact is the critical output of Stage 0, making this step essential for the overall system workflow.",
              "sequence_critique": "The step is logically sequenced. It correctly assumes that previous steps would have defined the `TreeAssembler` class and implemented the logic to populate its internal state (`self.phases`). This step serves as the final, culminating action for the class, making its position as the last step in the implementation logical.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific method signature, breaks the logic into three unambiguous sub-steps, and even includes a helpful hint on which Pydantic method to use (`.model_dump_json(indent=2)`), which removes ambiguity and ensures the output is well-formatted. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 6": "Refactor the main planning orchestrator logic (likely in a file such as `src/planning/planner.py` or `src/orchestrator.py`) to use the new `TreeAssembler`.\n\n1. At the start of the planning process, instantiate `TreeAssembler` with the user's goal.\n2. In the loop where you generate phases, replace the existing logic with a call to `assembler.add_phase()`.\n3. Similarly, in the nested loops for tasks and steps, call `assembler.add_task()` and `assembler.add_step()` respectively.\n4. At the very end of the planning stage, after all loops are complete, make a single call to `assembler.build_and_save()` to generate the `reasoning_tree.json` file.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/planning/planner.py",
                "src/orchestrator.py",
                "TreeAssembler",
                "assembler.add_phase()",
                "assembler.add_task()",
                "assembler.add_step()",
                "assembler.build_and_save()",
                "reasoning_tree.json"
              ],
              "technology_hints": [
                "Python",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The steps are perfectly aligned with the task of implementing the assembly and saving logic for `reasoning_tree.json`. This refactoring directly contributes to producing the key artifact of Stage 0, which is essential for the overall system workflow.",
              "sequence_critique": "The sequence is logical. It correctly follows the process of instantiating an assembler, populating it hierarchically within the existing loops (phase, task, step), and then building the final output at the very end. No issues found.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They specify the target files, the class and methods to use, and the exact points in the existing logic where the new calls should be integrated, making the refactoring task unambiguous."
            }
          }
        },
        {
          "step 7": "Create a new test file at `tests/planning/test_tree_assembler.py`. Write comprehensive unit tests for the `TreeAssembler` class to ensure its correctness.\n\n- **Setup:** Use `pytest`.\n- **Test Cases:**\n  1. Test the constructor initializes the `goal` and `phases` list correctly.\n  2. Write a test to add a phase, a task, and a step, then verify the internal state of the assembler object is as expected.\n  3. Write a more complex test that adds multiple phases, tasks, and steps to ensure the numbering logic (`phase_number`, `task_number`, `step_number`) is correct.\n  4. Test the `build_and_save` method. Use `pytest`'s `tmp_path` fixture to create a temporary directory. Call the method, then read the generated file and parse it as JSON. Assert that the resulting data structure matches the expected tree structure and content.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "tests/planning/test_tree_assembler.py",
                "TreeAssembler",
                "goal",
                "phases",
                "phase_number",
                "task_number",
                "step_number",
                "build_and_save",
                "tmp_path"
              ],
              "technology_hints": [
                "pytest",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Writing comprehensive unit tests for the `TreeAssembler` is a critical part of 'implementing the logic to assemble and save' the `reasoning_tree.json` artifact. This ensures the output of Stage 0 is reliable, which is fundamental to the system's core philosophy of verification at every stage.",
              "sequence_critique": "The sequence is logical. This step, which focuses on testing, correctly assumes that the `TreeAssembler` class has been implemented in a prior step within the same task. Testing the implementation is the natural and necessary next action.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, names the testing framework (`pytest`), and outlines four distinct, well-defined test cases. The guidance, such as using `pytest`'s `tmp_path` fixture for file I/O testing, demonstrates best practices and leaves no ambiguity for the executing agent."
            }
          }
        }
      ],
      "1.5: Define the detailed `ModuleContract` and `CONTRACT_DOCUMENT_SCHEMA` JSON schemas for Stage 1.": [
        {
          "step 1": "Create a new directory `src/schemas` to house all JSON schema definitions for the project. Inside this new directory, create a file named `contract.schema.ts`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas",
                "contract.schema.ts"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating the file structure (`src/schemas/contract.schema.ts`) is a direct and necessary prerequisite for defining the schemas, which is the core objective of the current task and fundamental to the 'Schema-Enforced Communication' principle of the overall system.",
              "sequence_critique": "The sequence is logical. A file must be created before its content can be defined in subsequent steps. No prerequisite steps appear to be missing.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact directory path and filename, leaving no room for ambiguity for an AI or human developer."
            }
          }
        },
        {
          "step 2": "In `contract.schema.ts`, begin defining the JSON schema for an individual `ModuleContract`. This will be the most detailed part of our schema definitions. Create a constant named `moduleContractSchemaDefinition`. For now, define it as a plain TypeScript object. Use the JSON Schema specification format. Start by defining the basic properties: `name` (a unique non-empty string), `purpose` (a non-empty string describing the module's goal), and `dependencies` (an array of unique strings, where each string is the `name` of another module).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "contract.schema.ts",
                "ModuleContract",
                "moduleContractSchemaDefinition"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON Schema"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned. It directly begins the implementation of the `ModuleContract` schema, which is a critical component of the 'Contract-First Design' principle and Stage 1 of the overall architecture.",
              "sequence_critique": "The sequence is logical. Starting with the foundational properties (`name`, `purpose`, `dependencies`) of an individual module is a sound, incremental approach to building the more complex schema required by the task.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. They specify the file, constant name, format (JSON Schema as a TypeScript object), and the precise properties and their constraints, leaving little room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 3": "Expand the `moduleContractSchemaDefinition` by defining the schemas for the module's interface: `dataStructures`, `functionSignatures`, and `publicAPI`. \n- `dataStructures`: An array of objects, where each object has a required `name` (string) and a required `definition` (string, intended to hold a full TypeScript type or interface definition).\n- `functionSignatures`: An array of objects, where each object must have a required `name` (string), a `params` array (of objects with `name` and `type` string properties), and a `returnType` (string).\n- `publicAPI`: An array of strings, where each string must correspond to a `name` in the `functionSignatures` array. This explicitly defines the module's public surface.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "moduleContractSchemaDefinition",
                "dataStructures",
                "functionSignatures",
                "publicAPI"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Defining `dataStructures`, `functionSignatures`, and `publicAPI` is fundamental to creating a detailed `ModuleContract` schema. This directly supports the overall system's 'Contract-First Design' principle by establishing a formal, machine-readable interface for each module before implementation begins.",
              "sequence_critique": "The logical sequence is sound. Defining the structural components of a module's interface is a necessary and self-contained part of the larger task of defining the complete contract schema. There are no missing prerequisites or ordering issues within this step.",
              "clarity_critique": "The step is exceptionally clear and actionable. The requirements for each field (`dataStructures`, `functionSignatures`, `publicAPI`) are specified with precise data types and nested structures. The constraint that `publicAPI` entries must correspond to names in `functionSignatures` is a crucial detail that adds significant value and clarity for implementation and future validation."
            }
          }
        },
        {
          "step 4": "Complete the `moduleContractSchemaDefinition` by adding the properties that guide the implementation and verification stages: `constructorParams`, `promptInstructions`, and `acceptanceTests`.\n- `constructorParams`: An array of objects, each with a required `name` (string, the parameter name) and `type` (string, the name of the dependency module to be injected).\n- `promptInstructions`: An array of non-empty strings containing detailed, step-by-step instructions for the code generation agent.\n- `acceptanceTests`: An array of non-empty strings, each describing a specific acceptance criterion or a high-level test case that the generated code must pass.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "moduleContractSchemaDefinition",
                "constructorParams",
                "promptInstructions",
                "acceptanceTests",
                "ModuleContract",
                "CONTRACT_DOCUMENT_SCHEMA"
              ],
              "technology_hints": [
                "JSON",
                "JSON Schema"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. The properties `constructorParams`, `promptInstructions`, and `acceptanceTests` are direct, concrete implementations of the system's core principles (Contract-First Design, Test-Driven Correction, and Parallel Execution), providing the necessary blueprint for the implementation and verification stages.",
              "sequence_critique": "The step's position within the task of defining the schema is logical. It correctly focuses on adding the more complex, derived properties that guide implementation, which would naturally follow the definition of the module's basic identity and public interface.",
              "clarity_critique": "The step is exceptionally clear and actionable. The descriptions for each property are specific about their data structure, content, and purpose, providing an unambiguous guide for creating the JSON schema. The distinction between `promptInstructions` (how to build) and `acceptanceTests` (what to verify) is well-defined."
            }
          }
        },
        {
          "step 5": "Now, create the main schema for the entire contract document. In the same file, define a new constant named `contractDocumentSchema`. This schema will define the root object. It should use the `$defs` keyword to contain the `moduleContractSchemaDefinition` you just created under the key `moduleContract`. The main schema object should have a `type` of `object` and define two required properties: `schemaVersion` (a string) and `modules` (an array). The `modules` array's `items` should use a `$ref` to point to `#/$defs/moduleContract`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "contractDocumentSchema",
                "moduleContractSchemaDefinition",
                "moduleContract"
              ],
              "technology_hints": [
                "JSON Schema"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Defining the top-level `contractDocumentSchema` is the logical conclusion to defining the individual `moduleContractSchema`. This directly supports the 'Contract-First Design' and 'Schema-Enforced Communication' principles of the overall system.",
              "sequence_critique": "The sequence is logical. It correctly builds upon the presumed prior creation of the `moduleContractSchemaDefinition`, using it as a reusable component within the main document schema. The approach is standard and correct.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides precise instructions on naming (`contractDocumentSchema`), structure (using `$defs` and `$ref`), and content (properties like `schemaVersion` and `modules`), leaving no room for ambiguity for an AI coding agent."
            }
          }
        },
        {
          "step 6": "Thoroughly review both schema definitions (`moduleContractSchemaDefinition` and `contractDocumentSchema`). Add a descriptive `description` property to every single field and sub-field. These descriptions are critical context for other developers and for the AI agents that will interact with these schemas. Explain the purpose of each field, its expected format, and its role in the overall system architecture.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "moduleContractSchemaDefinition",
                "contractDocumentSchema"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Adding detailed descriptions to the schema is critical for the 'Schema-Enforced Communication' principle, as it provides the necessary context for AI agents to correctly generate the contract documents. It is a foundational requirement, not just a documentation task.",
              "sequence_critique": "The step is logically sequenced. It acts as a final review and enrichment step for the schema definitions, which correctly assumes that the basic structure of the schemas has already been drafted in previous steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It precisely defines the required action (add a `description` property to every field), the target artifacts (`moduleContractSchemaDefinition`, `contractDocumentSchema`), and provides specific guidelines on the content of the descriptions. This level of detail is ideal for an AI agent."
            }
          }
        },
        {
          "step 7": "To finalize the file and make it easily usable within the TypeScript project, export both the `contractDocumentSchema` and the `moduleContractSchemaDefinition` constants. Apply a TypeScript `as const` assertion to both schema objects. This will provide strong, static type inference for any part of the orchestrator that imports and uses these schemas, preventing typos and improving overall code quality.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "contractDocumentSchema",
                "moduleContractSchemaDefinition"
              ],
              "technology_hints": [
                "TypeScript",
                "as const"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Applying `as const` is a best practice in TypeScript for defining schema-like objects, ensuring that the schema definition itself is type-safe and immutable within the orchestrator's codebase. This directly supports the overall goal's principle of 'Schema-Enforced Communication' by leveraging the type system to enforce the schema's structure at compile time.",
              "sequence_critique": "This step is logically placed as a final action for the schema definition file. It assumes the constants have already been defined in previous steps, which is the correct order. Exporting the constants is the last thing one would do in a module file.",
              "clarity_critique": "The step is exceptionally clear and actionable. It explicitly names the constants to export and the precise TypeScript feature (`as const`) to apply. It also provides the technical justification, which helps an AI agent understand the intent and execute the instruction correctly."
            }
          }
        }
      ],
      "1.6: Implement the 'Interface Architect' agent, including the core prompt that transforms the `reasoning_tree.json` into the contract document.": [
        {
          "step 1": "Create a new file at `src/schemas/contract.schema.ts`. In this file, use the `zod` library to define the schemas for the contract generation stage. Define a `ModuleContractSchema` that includes fields for `name`, `purpose`, `dependencies` (an array of strings), `constructorParams` (an array of objects with `name` and `type`), `publicAPI` (an array of objects with `name` and `signature`), `dataStructures` (an array of objects with `name` and `schema`), `promptInstructions` (a string), and `acceptanceTests` (a string). Then, define a `ContractDocumentSchema` as an array of `ModuleContractSchema`. Export both schemas.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/contract.schema.ts",
                "ModuleContractSchema",
                "ContractDocumentSchema"
              ],
              "technology_hints": [
                "zod",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and overall goal. Defining the `ModuleContractSchema` is a foundational and necessary prerequisite for implementing the 'Interface Architect' agent, directly supporting the core principles of 'Contract-First Design' and 'Schema-Enforced Communication'.",
              "sequence_critique": "The sequence is logical. Defining the data structure (the schema) is the correct first action to take before implementing any logic that generates or validates data conforming to that structure.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, library, schema names, and a detailed breakdown of the required fields and their types, leaving little room for ambiguity."
            }
          }
        },
        {
          "step 2": "Create the main agent file at `src/agents/architect.agent.ts`. Define a class named `InterfaceArchitectAgent`. This class will be responsible for orchestrating the transformation of the reasoning tree into a contract document. It should have a constructor and a primary public method `generateContract(reasoningTree: object): Promise<object>`. For now, leave the method implementation empty.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/architect.agent.ts",
                "InterfaceArchitectAgent",
                "generateContract",
                "reasoningTree"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the class structure for the `InterfaceArchitectAgent` is a foundational and necessary action to implement the agent's functionality as described in the task and overall goal.",
              "sequence_critique": "The step is logically sound. Creating the file and class skeleton is a standard prerequisite before implementing the internal logic of the `generateContract` method. It establishes the necessary structure for subsequent implementation steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, class name, method signature (including parameter and return types), and explicitly states that the method body should be left empty for now. This leaves no room for ambiguity."
            }
          }
        },
        {
          "step 3": "Inside the `InterfaceArchitectAgent` class, create a private constant named `SYSTEM_PROMPT`. This multi-line string will be the core instruction for the LLM. It must clearly explain the goal: to act as an 'Interface Architect' and convert a detailed procedural plan (`reasoning_tree.json`) into a formal, declarative `ContractDocument`. The prompt should instruct the LLM to: \n1. Analyze the entire plan to identify logical, independent software modules. \n2. For each module, populate all fields of the `ModuleContractSchema`. \n3. Pay close attention to inferring dependencies between modules. \n4. Translate the low-level steps from the reasoning tree into high-level `promptInstructions` and `acceptanceTests` for each module. \n5. Emphasize that the final output MUST be a JSON object that strictly conforms to the `ContractDocumentSchema`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "InterfaceArchitectAgent",
                "SYSTEM_PROMPT",
                "reasoning_tree.json",
                "ContractDocument",
                "ModuleContractSchema",
                "promptInstructions",
                "acceptanceTests",
                "ContractDocumentSchema"
              ],
              "technology_hints": [
                "LLM",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the core `SYSTEM_PROMPT` is the central action required to implement the 'Interface Architect' agent, whose function is a critical part of Stage 1 in the overall system architecture.",
              "sequence_critique": "The step is logically sequenced. It correctly assumes that the `InterfaceArchitectAgent` class has been created and now requires its core logic (the prompt) to be defined. It is a necessary and well-placed step within the broader task of implementing the agent.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides five specific, well-defined requirements for the prompt's content, directly referencing key concepts from the overall goal like schema enforcement, dependency inference, and the translation from procedural steps to declarative instructions. This leaves little room for ambiguity."
            }
          }
        },
        {
          "step 4": "Implement a private validation method `_validateContractDocument(document: any): object` within the `InterfaceArchitectAgent` class. This method will perform the post-generation checks. First, implement the 'Schema Adherence' check by using `ContractDocumentSchema.parse(document)`. If parsing fails, throw a detailed error. If it succeeds, return the parsed document.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_validateContractDocument",
                "InterfaceArchitectAgent",
                "ContractDocumentSchema",
                "ContractDocumentSchema.parse"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Implementing a schema validation method is a direct and crucial part of the 'Contract Generation' stage's 'Post-Generation Validation' process, which enforces the system's core principle of 'Schema-Enforced Communication'.",
              "sequence_critique": "The sequence is logical. Performing schema adherence validation is the necessary first step in the validation process, as subsequent checks like 'Internal Consistency' and 'Architectural Integrity' rely on the document having a valid structure.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the class, method name, visibility, signature, the exact library function to use (`ContractDocumentSchema.parse`), and the precise behavior for both success and failure cases."
            }
          }
        },
        {
          "step 5": "Enhance the `_validateContractDocument` method to perform 'Architectural Integrity' validation. After the initial schema check passes, add logic to verify the dependency graph. Create a `Set` of all module names defined in the document. Then, iterate through each module and its `dependencies` array. For each dependency listed, ensure it exists in the module name `Set`. If a dependency is not found, throw an error indicating an invalid architectural reference.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "_validateContractDocument",
                "dependencies"
              ],
              "technology_hints": [
                "Set"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step directly implements the 'Architectural Integrity (Graph Validation)' check, a core requirement of Stage 1 outlined in the system architecture. This validation is crucial for ensuring the contract document is a reliable blueprint for the parallel build stage, perfectly aligning with the task and overall goal.",
              "sequence_critique": "The step is logically sequenced to occur after the initial schema validation, which is the correct and efficient order of operations. The internal logic described for the validation itself is also sound.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the method to enhance, the exact algorithm to implement (including the use of a `Set` for efficiency), and the precise error-handling behavior, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 6": "Now, implement the main `generateContract` method. This method should: \n1. Take the `reasoningTree` object as input. \n2. Create the user prompt by stringifying the `reasoningTree` object. \n3. Make a call to a hypothetical LLM service (e.g., `llm.generateJson(this.SYSTEM_PROMPT, userPrompt)`), which you can mock for now. \n4. Pass the JSON response from the LLM to your `_validateContractDocument` method. \n5. If validation is successful, return the validated contract document. If any part fails, catch the error and log it appropriately before re-throwing or handling it.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "Make a call to a hypothetical LLM service"
              ],
              "key_entities_dependencies": [
                "generateContract",
                "reasoningTree",
                "llm.generateJson",
                "this.SYSTEM_PROMPT",
                "userPrompt",
                "_validateContractDocument"
              ],
              "technology_hints": [
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The steps are well-aligned. They describe the implementation of the core `generateContract` method, which is the central responsibility of the 'Interface Architect' agent defined in the task and the overall architecture.",
              "sequence_critique": "The sequence of operations is logical and correct: take input, prepare the prompt, call the LLM, validate the response, and then handle the success or failure case. This is a standard and robust workflow.",
              "clarity_critique": "The instructions are clear and actionable. However, sub-step 2, which suggests the user prompt is created by simply 'stringifying the `reasoningTree` object', may be an oversimplification. While clear, this approach might be too naive for the sophisticated task of contract generation, potentially leading to lower-quality LLM outputs. A more structured prompt that guides the LLM through the analysis of the tree might be more effective in the long run."
            }
          }
        },
        {
          "step 7": "Create a new test file at `src/agents/architect.agent.test.ts`. In this file, create a mock `reasoning_tree.json` object that describes a simple two-module project (e.g., a 'Database' module and a 'UserService' module that depends on the 'Database'). This mock data will serve as the input for your tests.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/architect.agent.test.ts",
                "reasoning_tree.json",
                "'Database' module",
                "'UserService' module"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating mock input data (`reasoning_tree.json`) is a fundamental and necessary prerequisite for testing the 'Interface Architect' agent, whose primary function is to process this exact type of input.",
              "sequence_critique": "The step is logically sequenced. In a test-driven approach, defining the test inputs is one of the first things to do after creating the test file itself. This step correctly precedes the implementation of the test logic that will use this mock data.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to create, the nature of the mock data required, and provides a concrete, relevant example ('Database' and 'UserService' with a dependency) that effectively guides the creation of a meaningful test case."
            }
          }
        },
        {
          "step 8": "In `src/agents/architect.agent.test.ts`, write unit tests for the `InterfaceArchitectAgent`. Your tests should mock the LLM call. \n1. Test the successful path: provide the mock reasoning tree, have the mocked LLM return a valid contract document, and assert that the `generateContract` method returns it without errors. \n2. Test schema validation failure: have the mocked LLM return a malformed JSON object (e.g., with a missing `name` field in a module) and assert that `generateContract` throws a `ZodError`. \n3. Test architectural validation failure: have the mocked LLM return a contract document where one module depends on a module name that is not defined. Assert that `generateContract` throws your custom architectural error.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/agents/architect.agent.test.ts",
                "InterfaceArchitectAgent",
                "LLM",
                "reasoning tree",
                "contract document",
                "generateContract",
                "ZodError",
                "custom architectural error"
              ],
              "technology_hints": [
                "TypeScript",
                "JSON",
                "Zod"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and overall goal. Testing the success, schema failure, and architectural failure paths directly verifies the core responsibilities of the 'Interface Architect' agent as defined in the 'Stage 1: Contract Generation' process, ensuring it adheres to the system's principles of contract-first design and schema-enforced communication.",
              "sequence_critique": "The sequence is logical. It follows a standard testing pattern: verify the happy path first, then test specific, critical failure modes. The order of testing schema validation before architectural validation is also logical, as it mirrors the likely order of operations in the agent's implementation.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file, the testing methodology (mocking the LLM), and provides three distinct, well-defined test cases with concrete examples of inputs (e.g., 'missing `name` field', 'depends on a module name that is not defined') and expected outputs (e.g., 'throws a `ZodError`', 'throws your custom architectural error')."
            }
          }
        }
      ],
      "1.7: Implement the Stage 1 post-generation validation module, including checks for schema adherence, internal consistency, and architectural integrity (dependency graph validation).": [
        {
          "step 1": "Create the necessary files and define the main validation function structure. Create a new file at `src/stages/1_contract_generation/validation/contractValidator.ts`. Inside this file, import the necessary types, specifically `ModuleContract` and the Zod schema `CONTRACT_DOCUMENT_SCHEMA` from `src/llm/schemas.ts`. Then, define an exported function `validateContractDocument(document: unknown): ModuleContract[]`. This function will serve as the entry point for all validation logic. For now, leave the implementation empty but add a JSDoc comment outlining its purpose: to perform full validation of a module contract document, including schema adherence, architectural integrity, and internal consistency.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/1_contract_generation/validation/contractValidator.ts",
                "ModuleContract",
                "CONTRACT_DOCUMENT_SCHEMA",
                "src/llm/schemas.ts",
                "validateContractDocument"
              ],
              "technology_hints": [
                "Zod",
                "JSDoc"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating the main validation file and function signature is the foundational action required to implement the Stage 1 post-generation validation module, as described in the task description.",
              "sequence_critique": "The sequence is logical. This step correctly establishes the necessary file structure and function entry point before any specific validation logic is implemented. It is the correct first step for this task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides the exact file path, required imports, function signature, and JSDoc content, leaving no room for ambiguity for an AI coding agent."
            }
          }
        },
        {
          "step 2": "Implement the complete validation logic within the `validateContractDocument` function. The implementation should follow these sequential checks: 1. **Schema Validation**: Use the `CONTRACT_DOCUMENT_SCHEMA.safeParse(document)` method from Zod to validate the input against the schema. If parsing fails, throw a detailed error including the Zod error issues. If it succeeds, use the parsed data for the subsequent checks. 2. **Architectural Integrity (Dependency Graph)**: Create a `Set<string>` of all module names from the parsed document for efficient lookups. Then, iterate through each module in the document. For each module, iterate through its `dependencies` array. For each dependency name, check if it exists in the module name `Set`. If a dependency is not found, throw a specific `Error` stating which module has an undefined dependency. 3. **Internal Consistency (Constructor vs. Dependencies)**: Inside the same loop, for each module, compare its `dependencies` array with its `constructorParams` array. The set of names in `dependencies` must be identical to the set of names in `constructorParams`. If they do not match (either a missing param for a dependency or an extra param), throw a specific `Error` indicating the mismatch for that module.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "validateContractDocument",
                "CONTRACT_DOCUMENT_SCHEMA",
                "safeParse",
                "document",
                "dependencies",
                "constructorParams",
                "Set",
                "Error"
              ],
              "technology_hints": [
                "Zod",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It directly implements the three required validation checks (schema, architectural, internal), which are fundamental to the 'Contract-First Design' and 'Schema-Enforced Communication' principles of the overall system.",
              "sequence_critique": "The specified sequence of checks (1. Schema, 2. Architectural Integrity, 3. Internal Consistency) is logical and efficient. It correctly prioritizes validating the basic structure with the schema before checking inter-module and then intra-module consistency, following a robust 'fail-fast' strategy.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The step provides a precise, unambiguous algorithm, specifying the exact methods (e.g., `Zod.safeParse`), data structures (e.g., `Set<string>`), and error-handling logic required, making it ideal for an AI coding agent to execute."
            }
          }
        },
        {
          "step 3": "Create a corresponding test file `src/stages/1_contract_generation/validation/contractValidator.test.ts`. Write a comprehensive suite of unit tests for the `validateContractDocument` function using your preferred testing framework (e.g., Jest). Your tests must cover the following scenarios: 1. **Valid Contract**: A test case with a valid, multi-module contract document that should pass validation successfully. 2. **Invalid Schema**: A test case with a document that does not conform to the `CONTRACT_DOCUMENT_SCHEMA` (e.g., missing a required field), and assert that it throws an error. 3. **Missing Dependency**: A test case where a module lists a dependency that is not defined as another module in the document, and assert that it throws the correct architectural integrity error. 4. **Inconsistent Constructor Params**: A test case where a module's `constructorParams` do not perfectly match its `dependencies` list, and assert that it throws the correct internal consistency error.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/1_contract_generation/validation/contractValidator.test.ts",
                "validateContractDocument",
                "CONTRACT_DOCUMENT_SCHEMA",
                "constructorParams",
                "dependencies"
              ],
              "technology_hints": [
                "Jest",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. It directly addresses the need to verify the implementation of the validation module by creating a test suite that covers the three core validation requirements specified in the task: schema adherence, internal consistency, and architectural integrity.",
              "sequence_critique": "The step's placement is logical, assuming it follows the initial implementation of the `validateContractDocument` function. The internal sequence of required test cases is also logical, starting with the valid 'happy path' and then systematically testing each specified failure mode.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, the function to target, and a precise, enumerated list of test scenarios. Each scenario is described with enough detail (e.g., 'missing a dependency that is not defined') for an AI agent to create a concrete and meaningful test case."
            }
          }
        },
        {
          "step 4": "Review and refine the implementation in `contractValidator.ts`. Ensure all functions and type definitions have clear JSDoc comments explaining their purpose, parameters, and return values or thrown errors. Focus on the clarity and specificity of the error messages. For example, instead of 'Invalid dependency', use 'Validation Error in module \"MyApi\": Dependency \"MyDatabase\" is not defined in the contract document.' Refactor the code for readability and maintainability, ensuring the validation logic is easy to follow.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "contractValidator.ts"
              ],
              "technology_hints": [
                "JSDoc",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. The focus on specific, detailed error messages and code maintainability directly supports the core philosophy of creating a robust, verifiable, and production-ready framework. It moves beyond simple implementation to ensure the validation module is a high-quality, durable component.",
              "sequence_critique": "The step's position is logical. A 'review and refine' step naturally follows the initial implementation of the validation logic, serving as a quality assurance pass to harden the code before the task is considered complete.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides specific, concrete instructions (add JSDoc, refactor) and, crucially, includes a high-quality example of the desired output ('Validation Error in module...'). This example transforms a potentially vague instruction into a precise, testable requirement for an AI agent."
            }
          }
        }
      ],
      "1.8: Implement the end-to-end flow connecting Stage 0 and Stage 1, where the `reasoning_tree.json` is passed to the Interface Architect and the validated contract document is saved as the final output of the phase.": [
        {
          "step 1": "Create a new file `src/main_orchestrator.py` which will serve as the primary entry point for running the end-to-end flow from user goal to a validated contract document.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/main_orchestrator.py"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a primary entry point script (`main_orchestrator.py`) is the logical first action for implementing an end-to-end flow that connects the planning and contract generation stages.",
              "sequence_critique": "The sequence is logical. Before writing the orchestration logic, creating the file to house it is the correct initial step.",
              "clarity_critique": "The step is clear and actionable. It specifies the exact file path and name, and clearly states its purpose, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 2": "In `src/main_orchestrator.py`, import the necessary components: `HierarchicalPlanner` from `src.planning.planner`, `InterfaceArchitect` from `src.architect.architect`, and any required schema definitions. Sketch out a main function that defines the high-level sequence: 1. Get user goal, 2. Run Planner (Stage 0), 3. Run Architect (Stage 1 Generation), 4. Run Validator (Stage 1 Validation), 5. Save output. Use placeholder function calls for now.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/main_orchestrator.py",
                "HierarchicalPlanner",
                "src.planning.planner",
                "InterfaceArchitect",
                "src.architect.architect",
                "schema definitions",
                "main function",
                "Validator"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a main orchestrator file that sketches the sequence of Stage 0 (Planner) and Stage 1 (Architect + Validator) is the core of implementing the end-to-end flow between these stages.",
              "sequence_critique": "The sequence of operations outlined within the step (Get Goal -> Planner -> Architect -> Validator -> Save) is logical and correctly reflects the data flow described in the overall system architecture, where the output of one stage becomes the input for the next.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the exact file, the necessary imports, the sequence of placeholder functions, and the scope of the task (sketching, not full implementation). This provides precise guidance for an AI agent."
            }
          }
        },
        {
          "step 3": "Implement the Stage 0 integration. Create a function `run_planning_stage(goal: str) -> str` in `main_orchestrator.py`. This function should instantiate the `HierarchicalPlanner`, execute its planning process with the provided goal, and return the file path to the generated `reasoning_tree.json`. Ensure the planner's execution is encapsulated and doesn't terminate the script.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "run_planning_stage",
                "main_orchestrator.py",
                "HierarchicalPlanner",
                "reasoning_tree.json"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating an encapsulated function to run Stage 0 and return its artifact path is the necessary first half of the end-to-end flow that connects Stage 0 to Stage 1.",
              "sequence_critique": "The step is logically sequenced. Implementing the function for the first stage (Stage 0) is a necessary prerequisite before implementing the function for the second stage (Stage 1) and passing the data between them.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the function name, signature, file location, core logic (instantiate, execute), expected return value, and a critical non-functional requirement (encapsulation), leaving little room for ambiguity."
            }
          }
        },
        {
          "step 4": "Implement the Stage 1 generation integration. Create a function `run_architect_stage(reasoning_tree_path: str) -> list` in `main_orchestrator.py`. This function should read the content of `reasoning_tree.json`, instantiate the `InterfaceArchitect`, and call it to generate the contract document. It should parse the LLM's JSON output and return the raw, unvalidated contract document as a Python list of dictionaries.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "run_architect_stage",
                "main_orchestrator.py",
                "reasoning_tree.json",
                "InterfaceArchitect"
              ],
              "technology_hints": [
                "Python",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is misaligned with the task's ultimate goal. The task is to implement the end-to-end flow for Stage 1, which culminates in a *validated* contract document. This step explicitly instructs the function to return a 'raw, unvalidated' document, thereby omitting the critical 'Post-Generation Validation' checks (Schema Adherence, Internal Consistency, Architectural Integrity) that are a core part of the Stage 1 definition.",
              "sequence_critique": "The step is a logical part of the process but represents an incomplete sequence. To fulfill the task of implementing the 'end-to-end flow' for Stage 1, the generation described in this step must be immediately followed by the validation steps. A better design would be for the `run_architect_stage` function to orchestrate both generation and validation to truly represent the completion of the stage.",
              "clarity_critique": "The step is exceptionally clear and actionable. It precisely defines the function name, signature, location, and internal logic, leaving no ambiguity for an AI agent."
            }
          }
        },
        {
          "step 5": "Create a dedicated module for validation. Create a new file `src/architect/validator.py`. Inside this file, define a class named `ContractValidator`. The constructor `__init__` should accept the contract document (the list of module contracts) as an argument and store it.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/architect/validator.py",
                "ContractValidator",
                "__init__",
                "contract document"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Creating a dedicated `ContractValidator` class is a crucial and logical part of implementing the \"Post-Generation Validation\" checks described in Stage 1, which is a core requirement of the current task.",
              "sequence_critique": "The sequence is logical. This step correctly establishes the foundational structure (the class and its file) for the validation logic before subsequent steps would presumably add the specific validation methods to it.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a specific file path, class name, and a precise definition for the constructor's signature and purpose, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 6": "Implement schema validation within the `ContractValidator` class. Add a method `validate_schema()`. This method should import the `CONTRACT_DOCUMENT_SCHEMA` from `src.schemas.contract` and use the `jsonschema` library to validate the contract document stored in the instance. If validation fails, it should raise a `jsonschema.ValidationError`. Hint: You may need to install `jsonschema` (`pip install jsonschema`).",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "install `jsonschema` (`pip install jsonschema`)"
              ],
              "key_entities_dependencies": [
                "ContractValidator class",
                "validate_schema() method",
                "CONTRACT_DOCUMENT_SCHEMA",
                "src.schemas.contract",
                "jsonschema.ValidationError"
              ],
              "technology_hints": [
                "jsonschema library",
                "pip"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the 'Schema Adherence' validation described in Stage 1, which is a core principle ('Schema-Enforced Communication') of the overall system. This is essential for the task of producing a 'validated contract document'.",
              "sequence_critique": "The logical sequence is correct. Schema validation is the most fundamental check and should be performed before any deeper, more complex architectural or consistency checks. This step fits appropriately within the broader task of building a contract validator.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the target class (`ContractValidator`), method name (`validate_schema`), necessary imports, the library to use (`jsonschema`), the data to act upon ('contract document stored in the instance'), and the precise error handling mechanism (`raise a jsonschema.ValidationError`)."
            }
          }
        },
        {
          "step 7": "Implement architectural integrity validation in `ContractValidator`. Add a method `validate_dependencies()`. This method must perform a graph validation check: 1. Create a set of all `moduleName` values from the contract document. 2. Iterate through each module and its `dependencies` list. 3. For each dependency, verify that its `moduleName` exists in the set of defined module names. 4. If a dependency points to a non-existent module, raise a custom `ValueError` with a clear error message (e.g., \"Validation Error: Module 'X' has a dependency on 'Y', but module 'Y' is not defined in the contract.\").",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "ContractValidator",
                "validate_dependencies",
                "moduleName",
                "dependencies",
                "ValueError"
              ],
              "technology_hints": [
                "Python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It directly implements the 'Architectural Integrity (Graph Validation)' check, a critical validation requirement explicitly defined in the 'Stage 1: Contract Generation' process description. This ensures the contract is a reliable blueprint, which is central to the overall goal.",
              "sequence_critique": "The step is a logical and self-contained unit of work. Assuming the `ContractValidator` class itself is defined in a prior step, implementing this specific validation method within it is a sound sequential action.",
              "clarity_critique": "The step is exceptionally clear and actionable. It provides a precise, numbered algorithm for the validation logic, specifies the exact error type to raise, and even gives a template for the error message. This level of detail is ideal for an AI coding agent."
            }
          }
        },
        {
          "step 8": "Integrate the validation logic into the main orchestrator flow. In `main_orchestrator.py`, after generating the contract document, instantiate `ContractValidator` with it. Call the `validate_schema()` and `validate_dependencies()` methods. Use a try-except block to catch potential validation errors and print a user-friendly failure message before exiting.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "main_orchestrator.py",
                "ContractValidator",
                "validate_schema()",
                "validate_dependencies()"
              ],
              "technology_hints": []
            },
            "step_critique": {
              "alignment_critique": "The step is well-aligned. It directly implements the validation requirement of the task, which is a critical part of the 'Contract-First Design' and 'Schema-Enforced Communication' principles outlined in the overall goal.",
              "sequence_critique": "The sequence is logical, placing validation immediately after generation. However, the Stage 1 description details three validation checks (Schema Adherence, Internal Consistency, Architectural Integrity), while this step only explicitly calls methods for two (`validate_schema`, `validate_dependencies`). It should be clarified whether `validate_dependencies` is intended to also cover the 'Internal Consistency' check, or if a call to another validation method is missing.",
              "clarity_critique": "The step is very clear and actionable. It precisely identifies the file (`main_orchestrator.py`), the class (`ContractValidator`), the specific methods to call, and the required error handling (`try-except` block), leaving little room for misinterpretation by a coding agent."
            }
          }
        },
        {
          "step 9": "Finalize the orchestrator script by adding a command-line interface and file output. Use the `typer` library to make the main function runnable from the command line, accepting the user goal as an argument. Add `logging` to provide status updates for each stage (e.g., 'Running planner...', 'Generating contract...', 'Validating contract...'). If all steps succeed, save the validated contract document to `build/contract_document.json`. Ensure the `build` directory is created if it doesn't exist.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "orchestrator script",
                "main function",
                "user goal",
                "validated contract document",
                "build/contract_document.json",
                "build"
              ],
              "technology_hints": [
                "typer",
                "logging",
                "JSON"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. It represents the final, practical implementation needed to complete the task of creating a runnable end-to-end flow. Adding a CLI, logging, and file output transforms the preceding logical steps into a functional and verifiable tool, directly contributing to the task's goal.",
              "sequence_critique": "The sequence is logical. This step acts as a finalization or 'wrapping' of the core logic. It is appropriate to add user-facing features like a CLI and status logging after the internal data flow between Stage 0 and Stage 1 has been established in previous steps.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact libraries to use (`typer`, `logging`), the purpose of the CLI argument, provides concrete examples for log messages, and gives a precise path for the output file, including the necessary check for the output directory's existence."
            }
          }
        },
        {
          "step 10": "Update the project's `README.md` file. Add a new section titled 'Running the Full Pipeline (Stages 0 & 1)' that explains how to use the new `main_orchestrator.py` script. Include a clear example command, like `python -m src.main_orchestrator \"Build a simple real-time chat API\"`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "README.md",
                "main_orchestrator.py",
                "src.main_orchestrator"
              ],
              "technology_hints": [
                "python"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Documenting how to use the new end-to-end orchestrator script is a critical final part of completing the task to 'Implement the end-to-end flow'. It makes the newly implemented feature usable and discoverable.",
              "sequence_critique": "The sequence is logical. Updating documentation should occur after the feature it describes (the orchestrator script) has been implemented, making this an appropriate final step for the task.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file to modify (`README.md`), the new section title, the required content (how to use `main_orchestrator.py`), and provides a concrete example command. An AI agent would have no trouble executing this."
            }
          }
        }
      ]
    },
    "Phase 3: Parallel Module Code Generation (Stage 2)": {
      "Develop the Stage 2 orchestrator logic to load the validated `ModuleContract[]` document.": [
        {
          "step 1": "First, set up the necessary file structure for Stage 2. Create a new directory `src/stages/stage2_module_implementation`. Inside this directory, create two new files: `orchestrator.ts` and `orchestrator.test.ts`. Concurrently, create a directory `src/schemas` if it doesn't exist, and add a new file inside it named `contract.schema.ts`.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage2_module_implementation",
                "orchestrator.ts",
                "orchestrator.test.ts",
                "src/schemas",
                "contract.schema.ts"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The creation of the orchestrator files (`orchestrator.ts`, `orchestrator.test.ts`) is well-aligned with the task. However, the creation of `contract.schema.ts` is misaligned. According to the overall plan, Stage 1 (Contract Generation) is responsible for validating the output against a `CONTRACT_DOCUMENT_SCHEMA`. This implies the schema must exist before or during Stage 1. Stage 2 should consume this pre-existing schema for loading the contract, not create it.",
              "sequence_critique": "The creation of the schema file is out of sequence with the overall project workflow. This step should have occurred during the development of Stage 1, as the schema is a critical prerequisite for that stage's validation process.",
              "clarity_critique": "The instructions are clear, specific, and directly actionable."
            }
          }
        },
        {
          "step 2": "In `src/schemas/contract.schema.ts`, define the core data structure for our contracts. Create and export a TypeScript interface named `ModuleContract`. Based on the system architecture document, this interface must include the following properties: `name` (string), `purpose` (string), `functionSignatures` (string[]), `dataStructures` (string[]), `publicAPI` (string[]), `dependencies` (string[]), `constructorParams` (string[]), `promptInstructions` (string), and `acceptanceTests` (string). Add clear JSDoc comments to describe the purpose of the interface and each of its properties.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/schemas/contract.schema.ts",
                "ModuleContract"
              ],
              "technology_hints": [
                "TypeScript",
                "JSDoc"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned. Defining the `ModuleContract` interface is a fundamental prerequisite for the task of loading the contract document, directly supporting the system's 'Contract-First' and 'Schema-Enforced' principles.",
              "sequence_critique": "The sequence is logical. Defining a data structure before writing the code that uses it is the correct order of operations.",
              "clarity_critique": "The step is exceptionally clear and actionable. It specifies the exact file path, interface name, a complete list of properties with their types, and the requirement for JSDoc comments, leaving no room for ambiguity."
            }
          }
        },
        {
          "step 3": "Now, let's add robust, runtime schema validation using the `zod` library. If you haven't already, add `zod` as a project dependency. In `src/schemas/contract.schema.ts`, create and export a Zod schema constant named `ModuleContractSchema` that mirrors the structure of the `ModuleContract` interface. Then, create and export a `ContractDocumentSchema` constant defined as `z.array(ModuleContractSchema)` to validate the entire contract document.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [
                "add `zod` as a project dependency"
              ],
              "key_entities_dependencies": [
                "`zod` library",
                "`src/schemas/contract.schema.ts`",
                "`ModuleContractSchema`",
                "`ModuleContract` interface",
                "`ContractDocumentSchema`",
                "`z.array`"
              ],
              "technology_hints": [
                "zod",
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task and the overall goal. Creating a Zod schema is a direct and necessary action to 'load the validated ModuleContract[] document' robustly, which directly supports the core philosophy of 'Schema-Enforced Communication' and 'Contract-First Design'.",
              "sequence_critique": "The logical sequence is correct. Defining the validation schema is a mandatory prerequisite before it can be used to parse and validate the input file in a subsequent step. This step correctly places the schema's creation before its use.",
              "clarity_critique": "The step is highly clear and actionable. It specifies the library (`zod`), the file path, the exact names for the constants to be exported (`ModuleContractSchema`, `ContractDocumentSchema`), and the precise relationship between them (`z.array(ModuleContractSchema)`). This leaves very little room for ambiguity."
            }
          }
        },
        {
          "step 4": "In `src/stages/stage2_module_implementation/orchestrator.ts`, create the function for loading the contracts. Import the `ModuleContract` interface and the `ContractDocumentSchema` from `../schemas/contract.schema.ts`. Define and export an `async` function named `loadAndValidateContracts` that accepts a `filePath: string` and is typed to return a `Promise<ModuleContract[]>`. This function will be the entry point for Stage 2 processing.",
          "qa_info": {
            "resource_analysis": {
              "external_actions": [],
              "key_entities_dependencies": [
                "src/stages/stage2_module_implementation/orchestrator.ts",
                "ModuleContract",
                "ContractDocumentSchema",
                "../schemas/contract.schema.ts",
                "loadAndValidateContracts",
                "Promise<ModuleContract[]>"
              ],
              "technology_hints": [
                "TypeScript"
              ]
            },
            "step_critique": {
              "alignment_critique": "The step is perfectly aligned with the task. Creating a function to load and validate the contract document is the essential first action for the Stage 2 orchestrator, directly contributing to the overall goal of parallel module implementation.",
              "sequence_critique": "The step represents a logical starting point for the task. Defining the primary function signature and its location is the correct first action before implementing the file reading and validation logic within it.",
              "clarity_critique": "The instructions are exceptionally clear and actionable. The step provides the specific file path, function name, signature (including `async`, parameter types, and return type), and required imports, leaving no room for ambiguity for an AI agent."
            }
          }
        },
        {
          "step 5": "Implement the core logic for the `loadAndValidateContracts` function. Use the `fs/promises` module from Node.js to read the file content at the given `filePath`. Parse the resulting string as JSON. Then, use the `ContractDocumentSchema.parse()` method to validate the parsed data. If validation succeeds, return the data. This ensures that any data returned from this function is guaranteed to match the contract schema."
        },
        {
          "step 6": "Implement comprehensive error handling within `loadAndValidateContracts`. Wrap the entire file reading, parsing, and validation logic in a `try...catch` block. The `catch` block should handle different types of errors: file system errors (e.g., file not found), JSON parsing errors, and Zod validation errors. For each error type, log a specific, informative message and re-throw a new, user-friendly `Error` that clearly explains the failure (e.g., 'Failed to load contracts: File not found at path...' or 'Failed to validate contracts: Data does not conform to schema.')."
        },
        {
          "step 7": "Now, write unit tests to verify the 'happy path' for your loader. In `src/stages/stage2_module_implementation/orchestrator.test.ts`, use a testing framework like Jest. Create a mock `contracts.json` file in a temporary test directory. This file should contain a valid array of two or more module contract objects. Write a test case that calls `loadAndValidateContracts` with the path to this mock file and asserts that the returned value is an array that deeply equals the mock data."
        },
        {
          "step 8": "Finally, write unit tests to ensure your error handling is robust. In `orchestrator.test.ts`, add three more test cases: 1. Test that `loadAndValidateContracts` throws the expected error when given a path to a non-existent file. 2. Test that it throws the expected error when the file contains malformed JSON. 3. Test that it throws the expected Zod-related error when the file contains valid JSON that fails schema validation (e.g., a contract object is missing the `name` property). Use `expect(...).rejects.toThrow()` to assert that the function correctly rejects the promise with an appropriate error for each case."
        }
      ],
      "Implement the parallel execution mechanism to spawn a 'Module Builder' agent for each contract concurrently.": [
        {
          "step 1": "Create a new file named `stage_2_module_implementation.py`. This file will contain all the logic for Stage 2: Parallel Module Implementation. Also, create a corresponding test file `test_stage_2_module_implementation.py`."
        },
        {
          "step 2": "In `stage_2_module_implementation.py`, define the necessary Pydantic models to represent the data structures for this stage. You will need: \n1. A `GeneratedModule` model with fields: `module_name: str`, `implementation_code: str`, and `test_code: str`. \n2. A `Stage2Output` model that holds a list of `GeneratedModule` objects: `modules: List[GeneratedModule]`. \nHint: You will be reading `ModuleContract` objects. Assume the Pydantic models for the contract (e.g., `ModuleContract`, `FunctionSignature`, etc.) are available to be imported from a `shared_types.py` file. If they are not, create them based on the Stage 1 description."
        },
        {
          "step 3": "Create a helper function `_build_module_builder_prompt(contract: ModuleContract) -> str`. This function will take a single module contract and construct the detailed, multi-part prompt for the LLM. The prompt should include:\n- A clear role for the AI (e.g., 'You are an expert software developer specializing in creating modular, production-ready TypeScript code.').\n- The full JSON representation of the `ModuleContract`.\n- The 'System Context' and 'CRITICAL RULES' mentioned in the system architecture, such as instructions to write dependency-injected code, not to call other modules directly, and to return only a specific JSON object.\n- A final instruction specifying the exact output format: a JSON object with two keys, `implementationCode` and `testCode`."
        },
        {
          "step 4": "Implement an asynchronous function `generate_module_code_async(contract: ModuleContract, llm_client: Any) -> GeneratedModule`. This function will be responsible for generating the code for a *single* module. Its logic should be:\n1. Call `_build_module_builder_prompt` to get the prompt for the given contract.\n2. Use the provided `llm_client` to make an asynchronous API call to the LLM with the generated prompt.\n3. Receive the response and parse it as JSON into a dictionary.\n4. Validate the dictionary contains the keys `implementationCode` and `testCode`.\n5. Instantiate and return a `GeneratedModule` object containing the `module_name` from the contract and the code from the response.\n6. Implement robust error handling for API failures and JSON parsing errors, raising a custom exception if a module cannot be generated."
        },
        {
          "step 5": "Implement the main orchestration function `run_stage_2_parallel(contracts: List[ModuleContract]) -> Stage2Output`. This function will manage the concurrent execution. \n1. It should be an `async` function.\n2. Initialize an LLM client (assume a client class like `LLMClient` is available to be instantiated).\n3. Create a list of awaitable tasks by calling `asyncio.create_task(generate_module_code_async(contract, llm_client))` for each contract in the input list.\n4. Use `asyncio.gather(*tasks, return_exceptions=True)` to execute all tasks concurrently and collect the results. Using `return_exceptions=True` is crucial for handling failures in individual generation tasks without stopping the entire process.\n5. Process the results from `gather`. Separate the successful `GeneratedModule` objects from any exceptions that were returned.\n6. Log any errors for failed modules.\n7. Return a `Stage2Output` object containing only the successfully generated modules."
        },
        {
          "step 6": "In `test_stage_2_module_implementation.py`, write unit tests for the `run_stage_2_parallel` function. Use `unittest.mock.AsyncMock` to mock the `llm_client` and the `generate_module_code_async` function. Your tests should cover:\n1. The happy path where all modules are generated successfully.\n2. A scenario where one of the module generation tasks fails (returns an exception). Verify that the orchestrator correctly handles the exception and returns the successfully generated modules.\n3. An edge case with an empty list of contracts as input."
        },
        {
          "step 7": "Finally, create a main execution block (`if __name__ == '__main__':`) in `stage_2_module_implementation.py`. This block should:\n1. Load the `ModuleContract[]` document from a file (e.g., `module_contracts.json`).\n2. Use `asyncio.run()` to execute the `run_stage_2_parallel` function with the loaded contracts.\n3. Serialize the resulting `Stage2Output` object to a new JSON file named `generated_modules.json`.\n4. Print a summary to the console, indicating how many modules were generated successfully and how many failed."
        }
      ],
      "Design and finalize the master prompt template for the 'Module Builder' agent, which will combine the system context, critical rules, and a specific module contract.": [
        {
          "step 1": "Create a new file named `prompt_components.ts`. In this file, define a TypeScript constant named `SYSTEM_CONTEXT` as a multi-line string. This string will serve as the introductory part of the prompt, establishing the agent's persona. It should clearly state that the agent is an expert TypeScript developer, part of a larger autonomous system, and its role is to implement a single, specific module based on a provided contract. Emphasize that it is a specialist on a team and should not act like a general-purpose assistant."
        },
        {
          "step 2": "In the same `prompt_components.ts` file, define another TypeScript constant named `CRITICAL_RULES` as a multi-line string. This section will list the non-negotiable rules for code generation. Include the following rules, formatted clearly (e.g., using markdown list syntax): 1. Strict Contract Adherence (implement only what's in the contract), 2. Dependency Injection (all external dependencies must be injected via the constructor), 3. Production-Ready Code (clean, typed, commented, and robust), 4. Comprehensive Test Generation (write Jest tests for all acceptance criteria in the contract), 5. No Hardcoded Values (use constructor parameters or constants), and 6. Isolated Implementation (write code as if it's the only module you know about, besides its direct dependencies)."
        },
        {
          "step 3": "In `prompt_components.ts`, define a third TypeScript constant named `IO_FORMAT_INSTRUCTIONS` as a multi-line string. This section will detail the input and output format. For the input, explain that the agent will receive a `ModuleContract` JSON object and briefly describe its key fields (`moduleName`, `purpose`, `functionSignatures`, `dependencies`, `promptInstructions`, `acceptanceTests`). For the output, specify that the response MUST be a single, raw JSON object conforming to the schema `{ \"implementationCode\": \"...\", \"testCode\": \"...\" }`. Explicitly forbid any explanatory text, greetings, or markdown formatting outside of the JSON object itself."
        },
        {
          "step 4": "Create a new file named `prompt_template_builder.ts`. In this file, import the constants from `prompt_components.ts`. Create a function `buildModuleBuilderPrompt(moduleContract: object): string`. This function should take a JavaScript object representing a single `ModuleContract` as input. It will construct the final, complete prompt string by combining `SYSTEM_CONTEXT`, `CRITICAL_RULES`, the stringified `moduleContract` (nicely formatted with `JSON.stringify(moduleContract, null, 2)`), and `IO_FORMAT_INSTRUCTIONS`. Use a clear structure with markdown headings like '## Your Role', '## Critical Rules', '## Your Task: Module Contract', and '## Required Output Format'."
        },
        {
          "step 5": "To test the template builder, create a mock `ModuleContract` object. Create a new file named `mock_contracts.ts`. In this file, define and export a constant named `mockLoggerContract`. This object should represent a contract for a simple `Logger` module. It should have no dependencies, a constructor that accepts a `logLevel` string, a single public method `log(level: string, message: string): void`, and at least two `acceptanceTests` describing scenarios like 'should log messages that meet the configured log level' and 'should not log messages below the configured log level'."
        },
        {
          "step 6": "Create a new file named `main.ts` to demonstrate the complete process. In this file, import `buildModuleBuilderPrompt` from `prompt_template_builder.ts` and `mockLoggerContract` from `mock_contracts.ts`. Call the `buildModuleBuilderPrompt` function with the `mockLoggerContract` as input. Finally, print the resulting complete prompt string to the console. This will serve as a final validation that the template is assembled correctly and is ready to be sent to an LLM."
        }
      ],
      "Implement the 'Module Builder' agent, responsible for taking a single contract, constructing the full prompt, and calling the LLM API.": [
        {
          "step 1": "Create a new file at `src/agents/module_builder_agent.ts`. In this file, define the necessary data structures for the agent's operation. First, define and export a Zod schema named `GeneratedModuleSchema` which validates an object with two string properties: `implementationCode` and `testCode`. Then, derive a TypeScript type `GeneratedModule` from this schema. You will also need the `ModuleContract` type, which you can import from `src/schemas/contract.schema.ts`."
        },
        {
          "step 2": "In `src/agents/module_builder_agent.ts`, define two string constants, `SYSTEM_CONTEXT` and `CRITICAL_RULES`. Populate these constants with the core instructions for the code generation LLM, based on the system's philosophy. The `SYSTEM_CONTEXT` should explain that the AI is a specialist developer on a team, receiving a formal contract to implement a single module. The `CRITICAL_RULES` should enforce key principles like writing production-ready, dependency-injected code, not making assumptions beyond the contract, including comprehensive comments, and strictly adhering to the JSON output format."
        },
        {
          "step 3": "Define and export the `ModuleBuilderAgent` class in `src/agents/module_builder_agent.ts`. It should have a constructor that accepts an instance of the OpenAI client as a dependency. Create a public async method `generateModule(contract: ModuleContract): Promise<GeneratedModule>`. Also, add a private method signature for `_constructPrompt(contract: ModuleContract): string` which will be implemented next."
        },
        {
          "step 4": "Implement the private `_constructPrompt` method within the `ModuleBuilderAgent` class. This method should take a `ModuleContract` object and return a single, formatted string. It must assemble the final prompt by concatenating the `SYSTEM_CONTEXT`, `CRITICAL_RULES`, a clear instruction to implement the provided contract, the `ModuleContract` object itself (stringified as a JSON block), and a final instruction specifying the required JSON output format (`{ \"implementationCode\": \"...\", \"testCode\": \"...\" }`)."
        },
        {
          "step 5": "Implement the core logic of the `generateModule` method. This method should: 1. Call `_constructPrompt` to get the full prompt string. 2. Use the injected OpenAI client to make a chat completion request. Ensure you enable the client's JSON mode to guarantee a JSON response. 3. Retrieve the JSON string content from the LLM's response. 4. Use a try-catch block to parse the JSON string. If parsing fails, throw a custom error. 5. Use the `GeneratedModuleSchema.parse()` method to validate the parsed object. This will throw an error if the object doesn't match the schema. 6. If validation is successful, return the parsed and validated object."
        },
        {
          "step 6": "Create a new test file `src/agents/module_builder_agent.test.ts`. Set up the necessary imports, including the `ModuleBuilderAgent`, a mock `ModuleContract` object for testing, and your testing framework (e.g., Jest/Vitest). Mock the OpenAI client using `jest.mock('openai')` or an equivalent for your test runner. This will allow you to control the LLM's responses in your tests."
        },
        {
          "step 7": "In `module_builder_agent.test.ts`, write a unit test specifically for the prompt construction logic. Instantiate the `ModuleBuilderAgent` (you can pass a `null` or mock client for this test). Call the `_constructPrompt` method (you may need to temporarily make it public or use `// @ts-ignore` for testing). Assert that the returned prompt string contains the system context, critical rules, and the stringified JSON of the mock contract you provided."
        },
        {
          "step 8": "Write a comprehensive suite of tests for the `generateModule` method. Create at least three test cases: 1. **Success Case:** Mock the OpenAI client to return a valid JSON string that conforms to the `GeneratedModuleSchema`. Assert that the method returns the correctly parsed object. 2. **Invalid JSON Case:** Mock the client to return a malformed JSON string (e.g., `{\"code\": ...`). Assert that the method throws a specific `JSON.parse` error. 3. **Schema Mismatch Case:** Mock the client to return a valid JSON string that does *not* conform to the schema (e.g., `{\"implementationCode\": \"...\"}` but missing `testCode`). Assert that the method throws a Zod validation error."
        },
        {
          "step 9": "Perform a final review of the `ModuleBuilderAgent` and its tests. Ensure all type imports are correct, add JSDoc comments to the class and its public methods explaining their purpose, parameters, and return values. Refactor any complex logic for clarity and ensure consistent error handling. Make the `_constructPrompt` method private again if you made it public for testing."
        }
      ],
      "Define the JSON schema for the 'Module Builder' agent's output (`{implementationCode, testCode}`) and implement validation for the LLM response.": [
        {
          "step 1": "Create a new file named `module_code_schema.py` inside a new directory `src/schemas`. This file will store the JSON schema for the output of the 'Module Builder' agent."
        },
        {
          "step 2": "In `src/schemas/module_code_schema.py`, define the JSON schema as a Python dictionary named `MODULE_CODE_SCHEMA`. This schema must enforce that the root is an object with two required string properties: `implementationCode` and `testCode`. Ensure no additional properties are allowed."
        },
        {
          "step 3": "Create a new file named `llm_response_validator.py` inside a new directory `src/validators`. This module will contain the logic to validate LLM responses against our defined schemas."
        },
        {
          "step 4": "In `src/validators/llm_response_validator.py`, implement a function `validate_llm_response(json_string: str, schema: dict) -> tuple[bool, dict | None, str | None]`. This function should parse the input string, validate it against the provided schema, and return a tuple containing: a boolean indicating success, the parsed data if successful (or None), and an error message if it fails (or None). Handle both `json.JSONDecodeError` and `jsonschema.ValidationError`."
        },
        {
          "step 5": "Ensure you have the `jsonschema` library installed. If not, add it to your `requirements.txt` file and install it. The `validate_llm_response` function should use this library for the validation logic."
        },
        {
          "step 6": "Create a new test file `tests/validators/test_llm_response_validator.py` to write unit tests for the validation logic."
        },
        {
          "step 7": "In `tests/validators/test_llm_response_validator.py`, write a comprehensive suite of unit tests for the `validate_llm_response` function using `pytest`. Import the `MODULE_CODE_SCHEMA` for testing. Your tests should cover the following cases: 1. A perfectly valid response. 2. A response that is not valid JSON. 3. A valid JSON response that is missing the required `implementationCode` key. 4. A valid JSON response where `testCode` has the wrong data type (e.g., a boolean instead of a string). 5. A valid JSON response that includes an extraneous, unallowed property."
        }
      ],
      "Implement the logic to collect the generated code and test pairs from all parallel agent runs.": [
        {
          "step 1": "First, let's define the data structures for handling the output from the `Module Builder` agents. In the `src/schemas.py` file, create two new Pydantic models: `ModuleGenerationOutput` which will represent the successful output from a single agent (containing `module_name`, `implementation_code`, and `test_code`), and `Stage2Output` which will be a dictionary mapping module names to either a `ModuleGenerationOutput` object or an `Exception` object for failed generations."
        },
        {
          "step 2": "Navigate to the file responsible for Stage 2 logic, which should be `src/stages/stage_2_code_generation.py`. Create a new asynchronous helper function named `_generate_module_code_async`. This function will take a single `ModuleContract` pydantic object and an `aiohttp.ClientSession` as input. Its purpose is to prepare the prompt for the `Module Builder` agent, make the API call, and parse the response. For now, you can mock the API call to return a sample JSON object like `{\"implementationCode\": \"...\", \"testCode\": \"...\"}`. The function should return an instance of the `ModuleGenerationOutput` model you created in the previous step."
        },
        {
          "step 3": "Now, create the main function for this stage, `run_stage_2_code_generation(contracts: list[ModuleContract]) -> Stage2Output`. This function will be the entry point for Stage 2. Inside this function, initialize an `aiohttp.ClientSession`."
        },
        {
          "step 4": "Inside `run_stage_2_code_generation`, create a list of awaitable tasks. Iterate through the input `contracts` list and for each `contract`, create a task by calling the `_generate_module_code_async` helper function. Store these tasks in a list."
        },
        {
          "step 5": "Use `asyncio.gather(*tasks, return_exceptions=True)` to execute all the module generation tasks concurrently. The `return_exceptions=True` flag is critical as it prevents the entire process from halting on a single agent failure and allows you to collect exceptions along with successful results."
        },
        {
          "step 6": "After `asyncio.gather` completes, process the list of results. Create an empty dictionary that will conform to the `Stage2Output` type. Iterate over the results list and the original `contracts` list simultaneously (e.g., using `zip`). For each result, check if it is an instance of `Exception`. If it is, log the failure and store the exception object in your output dictionary with the corresponding module name as the key. If it's a successful `ModuleGenerationOutput` object, store it in the dictionary."
        },
        {
          "step 7": "Return the final populated dictionary from the `run_stage_2_code_generation` function. Ensure the entire file has proper type hints, logging (e.g., 'Starting code generation for X modules...', 'Successfully generated module Y', 'Failed to generate module Z'), and follows asynchronous programming best practices."
        },
        {
          "step 8": "Finally, create a new test file `tests/stages/test_stage_2_code_generation.py`. Write unit tests for the `run_stage_2_code_generation` function using `pytest` and `pytest-asyncio`. You will need to use `unittest.mock.AsyncMock` to patch `_generate_module_code_async`. Create at least two test cases: one where all modules generate successfully, and another where one or more modules fail, ensuring the output dictionary correctly captures both the successful results and the exceptions."
        }
      ],
      "Structure the collected output into a data format suitable for input into Stage 3 (Verification & Correction).": [
        {
          "step 1": "Define the data structure that will encapsulate all information needed for the verification and correction stage. Create a new file `src/schemas/verification_schemas.py`. In this file, define a Pydantic model named `ModuleVerificationUnit`. This model will represent a single, self-contained package of work for Stage 3."
        },
        {
          "step 2": "Implement the `ModuleVerificationUnit` Pydantic model in `src/schemas/verification_schemas.py`. It must include the following fields: `module_name: str`, `contract: dict` (to hold the full JSON object for the module's contract), `implementation_code: str`, `test_code: str`, `status: str` (default to 'PENDING_VERIFICATION'), `verification_attempts: int` (default to 0), and `test_results: Optional[dict]` (default to None). Also, define a `VerificationStatus` Enum with values like `PENDING_VERIFICATION`, `VERIFICATION_SUCCESS`, `VERIFICATION_FAILURE`, `CORRECTION_ATTEMPT`, `CORRECTION_SUCCESS`, `CORRECTION_FAILURE`, `DEPENDENCY_FAILURE` and use it for the `status` field."
        },
        {
          "step 3": "Create a new script file `src/scripts/prepare_for_verification.py`. This script will be responsible for orchestrating the data transformation. Set up the basic file structure with necessary imports, including the `ModuleVerificationUnit` schema you just created, and a main function placeholder."
        },
        {
          "step 4": "In `src/scripts/prepare_for_verification.py`, implement the logic to load the necessary input data. This involves reading the main contract document from `output/1_contract_document.json` which contains the array of `ModuleContract` objects. Your function should parse this JSON file into a Python list of dictionaries."
        },
        {
          "step 5": "Implement the core transformation logic within the main function of `prepare_for_verification.py`. Iterate through each module contract loaded in the previous step. For each contract, extract the `moduleName` and dynamically construct the file path to its corresponding generated code, which is located at `temp/generated_code/{moduleName}.json`. Load the content of this JSON file, which contains the `implementationCode` and `testCode`."
        },
        {
          "step 6": "Inside the loop in `prepare_for_verification.py`, for each module, instantiate the `ModuleVerificationUnit` Pydantic model. Populate it with the `module_name` from the contract, the full `contract` object itself, the `implementation_code` and `test_code` loaded from the temporary file, and the default status and attempt count. Append each fully populated `ModuleVerificationUnit` object to a list."
        },
        {
          "step 7": "After the loop completes, implement the final step in `prepare_for_verification.py`: serialization. Convert the list of `ModuleVerificationUnit` Pydantic objects into a single JSON string. Ensure the output is pretty-printed for human readability. Write this final JSON string to a new file at `output/2_verification_units.json`. This file will serve as the definitive input for Stage 3."
        },
        {
          "step 8": "Refactor `src/scripts/prepare_for_verification.py` to be a robust, command-line executable script. Use the `typer` library to add command-line arguments for the input contract document path, the generated code directory path, and the output file path. This will make the script more flexible and easier to integrate into the main orchestrator pipeline."
        }
      ],
      "Add error handling and retry logic for individual module generation failures (e.g., LLM API errors, malformed JSON response).": [
        {
          "step 1": "First, locate the function responsible for generating the code for a single module. This function likely takes a `ModuleContract` as input and calls the LLM API. Let's assume this function is named `generateModuleCode` within a file like `src/stages/stage_2_generation.ts`. Isolate this function for modification."
        },
        {
          "step 2": "To handle failures more gracefully, create a new utility function that encapsulates retry logic with exponential backoff. Create a new file `src/utils/retry.ts` and define an async function `withRetry(fn, retries, initialDelay)`. This function should: accept an async function `fn` to execute, a `retries` count, and an `initialDelay` in ms. It should call `fn` and if it fails, wait for `initialDelay`, double the delay, and retry up to `retries` times. If all retries fail, it should re-throw the last error."
        },
        {
          "step 3": "Write comprehensive unit tests for the `withRetry` utility in `src/utils/retry.test.ts`. Use a mocking library like Jest (`jest.fn()`) to create mock async functions. Test the following scenarios: 1. The function succeeds on the first try. 2. The function fails once, then succeeds. 3. The function fails more times than the allowed retries and correctly throws an error. 4. Verify that the delay between retries is being applied correctly."
        },
        {
          "step 4": "Refactor the `generateModuleCode` function in `src/stages/stage_2_generation.ts`. Wrap the core logic (LLM API call and JSON parsing) into its own small, inner async function. Then, call this inner function using your new `withRetry` utility. Configure it with sensible defaults, for example, 3 retries and a 2000ms initial delay."
        },
        {
          "step 5": "Define a custom error class named `ModuleGenerationError` in a new file `src/errors.ts`. This error should accept a message and the original error as constructor arguments. In your `generateModuleCode` function, if the `withRetry` logic ultimately fails, catch the error and throw a new `ModuleGenerationError` that clearly states which module failed to generate and why."
        },
        {
          "step 6": "Now, modify the primary orchestrator function in `stage_2_generation.ts` that generates all modules in parallel. Previously, it might have used `Promise.all`. Change this to use `Promise.allSettled`. This ensures that the process continues even if some module generation promises are rejected."
        },
        {
          "step 7": "After `Promise.allSettled` completes, iterate over the results. Create two arrays: `successfulModules` and `failedModules`. Populate these arrays by checking the `status` of each result object ('fulfilled' or 'rejected'). For rejected promises, log the detailed error (the `reason` property, which should be your `ModuleGenerationError`) to provide clear feedback on which modules failed and why."
        },
        {
          "step 8": "Finally, update the unit tests for the main orchestrator function in `stage_2_generation.ts`. Mock the `generateModuleCode` function to simulate a mix of successful generations and failures (i.e., return a mix of resolved and rejected promises). Assert that the function correctly separates the results into `successfulModules` and `failedModules`."
        }
      ]
    },
    "Phase 4: Sandboxed Verification and Correction Loop Implementation": {
      "Task 4.1: Design and build the sandboxed execution environment (e.g., a Docker container with Node.js, Jest, and TypeScript pre-installed).": [
        {
          "step 1": "Create a new directory named `sandbox` which will contain all the files for our execution environment. All subsequent files in this task should be created within this directory unless specified otherwise."
        },
        {
          "step 2": "Inside the `sandbox` directory, create a `package.json` file. This file will define the necessary dependencies for our test execution environment. It should include `jest`, `typescript`, `ts-jest`, `@types/jest`, and `ts-node` as development dependencies. Define a `test` script with the command `jest --json --outputFile=test-results.json`."
        },
        {
          "step 3": "Inside the `sandbox` directory, create a `tsconfig.json` file. Configure it for a modern Node.js environment. Key settings should include `target: 'ES2020'`, `module: 'commonjs'`, `esModuleInterop: true`, `strict: true`, and `skipLibCheck: true`."
        },
        {
          "step 4": "Inside the `sandbox` directory, create a `jest.config.js` file. This file will configure Jest to work with TypeScript. Export a configuration object that sets the `preset` to `'ts-jest'` and the `testEnvironment` to `'node'`."
        },
        {
          "step 5": "Create a file named `Dockerfile` in the `sandbox` directory. This file will define the containerized sandboxed environment. The Dockerfile should: 1. Start with a `node:18-slim` base image. 2. Set the working directory to `/app`. 3. Copy `package.json`, `package-lock.json` (if it exists), `tsconfig.json`, and `jest.config.js` into the working directory. 4. Run `npm install --omit=dev` to install only production dependencies (as test dependencies will be part of the image layer). Then run `npm install` to get all dependencies for the test runner itself. 5. The container will receive code and tests via a mounted volume, so do not copy any application source code at build time. 6. The `CMD` should be set to execute a script that will run the tests, for example, `CMD [\"node\", \"/app/run_tests.js\"]`."
        },
        {
          "step 6": "Create a Node.js script named `run_tests.js` in the `sandbox` directory. This script will be the main entry point executed inside the Docker container. Its purpose is to run Jest and pipe the structured results to stdout for the orchestrator to capture. The script should: 1. Use Node.js's `child_process.exec` to run the `jest` command. Since the `package.json` test script is already configured, you can simply run `npm test`. 2. Capture `stdout`, `stderr` from the Jest process. 3. Use a `try...catch` or promise `.catch()` block to handle errors. If the Jest process fails (exits with a non-zero code), the script should still attempt to read the `test-results.json` file. 4. After the Jest process completes (successfully or not), read the `test-results.json` file. 5. Print the entire JSON content of the results file to `process.stdout`. 6. If `test-results.json` cannot be read, log the captured `stderr` from Jest to `process.stderr` and exit with a non-zero status code."
        },
        {
          "step 7": "In the project's root directory (outside of `sandbox`), create a shell script named `build_sandbox_image.sh`. This script should contain the Docker command to build the image from the `sandbox/Dockerfile`. Tag the image with a clear name, such as `autonomous-agent/execution-sandbox:latest`. Make the script executable."
        },
        {
          "step 8": "To test the entire setup, create a directory in the project root named `test_module_example`. Inside this directory, create two files: 1. `calculator.ts`: Implement a simple `Calculator` class with `add(a, b)` and `subtract(a, b)` methods. 2. `calculator.test.ts`: Write a Jest test suite for the `Calculator` class. Import the class, and write at least one test that passes and one test that is designed to fail (e.g., `expect(calculator.add(2, 2)).toBe(5);`) to verify the failure reporting mechanism."
        },
        {
          "step 9": "In the project's root directory, create a shell script named `run_sandbox_test.sh`. This script will simulate how the orchestrator uses the sandbox. It should: 1. Use the `docker run` command with the `--rm` flag. 2. Mount the `test_module_example/calculator.ts` file to `/app/implementation.ts` inside the container. 3. Mount the `test_module_example/calculator.test.ts` file to `/app/implementation.test.ts` inside the container. 4. Run the `autonomous-agent/execution-sandbox:latest` image. 5. The script should capture and print the standard output from the container, which should be the JSON test report."
        },
        {
          "step 10": "Finally, create a `README.md` file inside the `sandbox` directory. Document the purpose of this sandboxed environment and provide clear instructions on how to use the scripts you've created. Explain how to build the image with `build_sandbox_image.sh` and how to execute the example test with `run_sandbox_test.sh`. Describe the expected JSON output format from Jest."
        }
      ],
      "Task 4.2: Implement the 'Verification Runner' service that takes a module's code and tests, executes them in the sandbox, and captures the structured test results (e.g., Jest's JSON output).": [
        {
          "step 1": "Create a new directory for the service at `packages/verification-runner`. Inside this directory, initialize a new Node.js/TypeScript project by creating a `package.json` (e.g., `npm init -y`) and a `tsconfig.json` (e.g., `npx tsc --init`). Configure `tsconfig.json` with a `rootDir` of `./src`, an `outDir` of `./dist`, and set `module` to `CommonJS` and `target` to `ES2020` or newer. Install necessary dependencies: `typescript`, `ts-node`, `@types/node`, and `jest`, `ts-jest`, `@types/jest` as dev dependencies. Also install `uuid` and `@types/uuid` for generating unique directory names."
        },
        {
          "step 2": "Create a file `packages/verification-runner/src/types.ts`. Define the data structures for this service. Create a `VerificationInput` interface with `implementationCode: string` and `testCode: string`. Create a `VerificationResult` type which will be a union of a `SuccessResult` interface (containing `success: true` and `testResults: any`) and a `FailureResult` interface (containing `success: false`, `error: string`, and optionally `stdout: string`, `stderr: string`). The `testResults` field should be typed to match the structure of Jest's JSON output format."
        },
        {
          "step 3": "Create a `Dockerfile` in the root of the `packages/verification-runner` directory. This file will define the sandboxed test environment. It should use a `node` base image (e.g., `node:18-slim`), create a working directory (e.g., `/usr/src/app`), copy a placeholder `package.json` into it, run `npm install`, and then copy the rest of the test files. The `CMD` should be `[\"npm\", \"test\"]`. This Docker image will be used to run tests in isolation for each module."
        },
        {
          "step 4": "Create a `jest.config.js` file in `packages/verification-runner`. Configure it to use the `ts-jest` preset for running TypeScript tests. Crucially, add configuration to ensure Jest can output a JSON report. You will later invoke Jest with the `--json` and `--outputFile` flags to capture this structured output. Also, create a placeholder `package.json` file in a new `config` directory (e.g., `packages/verification-runner/config/package.json.template`). This template will be copied into each sandbox environment and should list `jest`, `ts-jest`, and `@types/jest` as dev dependencies."
        },
        {
          "step 5": "Create the main service file at `packages/verification-runner/src/runner.ts`. Begin implementing the primary function `runVerification(input: VerificationInput): Promise<VerificationResult>`. In this step, focus on the setup phase: use the `fs/promises` and `path` modules to create a unique temporary directory for each verification run (hint: use the `uuid` library). Inside this directory, write the `implementationCode` to a file (e.g., `module.ts`), the `testCode` to another file (e.g., `module.test.ts`), and copy the `jest.config.js` and the `package.json.template` (as `package.json`) into it."
        },
        {
          "step 6": "In `packages/verification-runner/src/runner.ts`, implement the sandbox execution logic within the `runVerification` function. Use the `child_process` module (specifically `exec` or `spawn`) to run Docker commands. The command sequence should be: 1. `npm install` inside the temporary directory via a Docker container. 2. `jest --json --outputFile results.json` also via a Docker container. The Docker run command must mount the temporary directory as a volume (e.g., `docker run --rm -v $(pwd)/temp-dir:/usr/src/app ...`). Capture `stdout` and `stderr` from these commands."
        },
        {
          "step 7": "Complete the `runVerification` function in `packages/verification-runner/src/runner.ts`. After the Docker command finishes, implement the results processing and cleanup. Check if `results.json` was created in the temporary directory. If it exists, read and parse it, and return a `SuccessResult`. If it does not exist, or if the Docker command failed, construct a `FailureResult` object containing the error message and any captured `stdout`/`stderr`. Finally, ensure the temporary directory and its contents are deleted in all cases (success or failure) using a `try...finally` block."
        },
        {
          "step 8": "Create an entry point file `packages/verification-runner/src/index.ts`. Expose the `runVerification` function. To facilitate testing, add a simple `main` async function that calls `runVerification` with hard-coded sample `implementationCode` and `testCode`. Include one example that should pass and one that should fail (e.g., a test that expects `2 + 2` to be `5`). Use `console.log` to print the structured `VerificationResult` for both cases. This will serve as a manual integration test for the service."
        }
      ],
      "Task 4.3: Develop the prompt and schema for the 'Corrector' agent, designed to accept the original contract, faulty code, and a formal test report.": [
        {
          "step 1": "Create a new file at `src/schemas/corrector_schemas.ts`. In this file, you will define the Zod schemas that govern the inputs and outputs for the Corrector agent. Start by importing `z` from `zod` and the `MODULE_CONTRACT_SCHEMA` from `./contract_schema.ts`."
        },
        {
          "step 2": "In `src/schemas/corrector_schemas.ts`, define and export a Zod schema named `TEST_REPORT_SCHEMA`. This schema will represent the structured output from a test runner. It should be an object with the following properties: `passed` (a boolean), `summary` (a string containing a high-level summary of the test run), and `failedTestDetails` (an array of objects, where each object contains `testName` (string), `errorMessage` (string), and an optional `stackTrace` (string))."
        },
        {
          "step 3": "In the same file, `src/schemas/corrector_schemas.ts`, define and export the main input schema named `CORRECTOR_AGENT_INPUT_SCHEMA`. This schema will represent the complete package of information sent to the Corrector agent. It must be a Zod object with three properties: `moduleContract` (which uses the imported `MODULE_CONTRACT_SCHEMA`), `faultyCode` (a non-empty string), and `testReport` (which uses the `TEST_REPORT_SCHEMA` you just created)."
        },
        {
          "step 4": "Now, define and export the output schema in `src/schemas/corrector_schemas.ts`. Name it `CORRECTOR_AGENT_OUTPUT_SCHEMA`. This schema ensures the Corrector agent's response is predictable. It should be a Zod object with two required string properties: `correctedCode` (the new, fixed version of the code) and `reasoning` (a detailed explanation of what was wrong and how the new code fixes it)."
        },
        {
          "step 5": "Create a new file at `src/prompts/corrector_prompt.ts`. This file will contain the system prompt template for the Corrector agent. Import the `CORRECTOR_AGENT_INPUT_SCHEMA` and `CORRECTOR_AGENT_OUTPUT_SCHEMA` types from `../schemas/corrector_schemas.ts` to ensure type safety."
        },
        {
          "step 6": "In `src/prompts/corrector_prompt.ts`, define and export a function `createCorrectorPrompt(input: z.infer<typeof CORRECTOR_AGENT_INPUT_SCHEMA>): string`. This function will take the structured input and generate the final, detailed prompt string to be sent to the LLM."
        },
        {
          "step 7": "Implement the body of the `createCorrectorPrompt` function. The returned string must be a meticulously crafted prompt that instructs the AI on its role and task. Structure the prompt with the following sections:\n\n1.  **ROLE AND GOAL**: State clearly: 'You are an expert software developer specializing in debugging. Your task is to analyze faulty code, a formal module contract, and a test report, and then produce a corrected version of the code that passes all tests and adheres to the contract.'\n\n2.  **CONTEXT**: Explain the three pieces of input they will receive: `moduleContract`, `faultyCode`, and `testReport`. Emphasize that the `moduleContract` (specifically its `promptInstructions` and `acceptanceTests` fields) is the ultimate source of truth for the required functionality.\n\n3.  **CRITICAL RULES**: Provide a list of non-negotiable rules:\n    *   'Methodically analyze the `testReport` to understand the exact error messages and stack traces.'\n    *   'Cross-reference the `faultyCode` with the `moduleContract` to identify where the implementation deviates from the specification.'\n    *   'Your primary goal is to fix the bugs. Rewrite the code to be correct, robust, and efficient.'\n    *   'You MUST NOT alter the public interface. The names and signatures of functions/classes defined in the contract's `publicAPI` are immutable.'\n    *   'In your `reasoning`, provide a clear, step-by-step explanation of your diagnosis and the rationale for your fix.'\n\n4.  **INPUT DATA**: Use template literals to inject the stringified JSON of the `moduleContract`, the `faultyCode` as a string, and the stringified JSON of the `testReport` into clearly marked sections within the prompt.\n\n5.  **OUTPUT INSTRUCTIONS**: Conclude with a strict instruction for the output format: 'You MUST reply with a single, valid JSON object that conforms to the `CORRECTOR_AGENT_OUTPUT_SCHEMA`. Do not include markdown formatting, comments, or any other text outside of the JSON object.'"
        }
      ],
      "Task 4.4: Implement the core 'Correction Loop' in the orchestrator, which invokes the Corrector agent on test failure and re-submits the code for verification, respecting a retry limit.": [
        {
          "step 1": "Create a new prompt template specifically for the Corrector Agent. In `src/agents/prompts.ts`, add a new exported constant `CORRECTOR_PROMPT_TEMPLATE`. This prompt should instruct the AI that it is a debugging expert. It will receive a module contract, the faulty implementation code, the original test code, and a detailed test failure report. Its goal is to analyze the error and fix ONLY the `implementationCode` while leaving the `testCode` unchanged. The output must be a JSON object with keys `implementationCode` and `testCode`."
        },
        {
          "step 2": "Create the `CorrectorAgent`. In the `src/agents/` directory, create a new file `CorrectorAgent.ts`. This agent will be responsible for invoking the LLM to fix code. Implement a function `invokeCorrectorAgent(contract: ModuleContract, faultyCode: { implementationCode: string; testCode: string }, testReport: string): Promise<{ implementationCode: string; testCode: string }>`. This function should format the `CORRECTOR_PROMPT_TEMPLATE` with the provided arguments, call the LLM service, parse the JSON response, and return the corrected code. Ensure robust error handling for LLM calls and JSON parsing."
        },
        {
          "step 3": "Introduce configuration for the correction loop. In your main configuration file (e.g., `src/config.ts` or a constants file), add a new constant `MAX_CORRECTION_RETRIES` and set its value to `3`. This will control how many times the system attempts to fix a failing module."
        },
        {
          "step 4": "Update the module status tracking to accommodate the correction loop. Locate the type or enum that defines the status of a module (likely in `src/types.ts` or `src/orchestrator.ts`). Add new statuses to represent the verification and correction lifecycle, such as `VERIFICATION_FAILED`, `CORRECTION_IN_PROGRESS`, and `VERIFIED_AFTER_CORRECTION`. This will provide more granular insight into the build process."
        },
        {
          "step 5": "Refactor the verification logic in the orchestrator to prepare for the loop. In the main orchestrator file (e.g., `src/orchestrator.ts`), locate the function responsible for Stage 3 (Verification). Isolate the logic that runs the tests for a single module into a separate, reusable function, for example `runVerification(module: Module): Promise<{ passed: boolean; report: string }>`. This function should execute the tests in the sandbox and return a structured result without modifying the module's state directly."
        },
        {
          "step 6": "Implement the core correction loop within the Stage 3 orchestration logic. For each module, replace the single verification call with a `for` or `while` loop that iterates up to `MAX_CORRECTION_RETRIES` times. Inside the loop, do the following:\n1. Call the `runVerification` function from the previous step.\n2. If `result.passed` is true, update the module's status to `VERIFIED` (or `VERIFIED_AFTER_CORRECTION` if it's not the first attempt), log the success, and break the loop.\n3. If `result.passed` is false, log the failure and the attempt number.\n4. If the retry limit has been reached, update the module's status to `VERIFICATION_FAILED`, log the final failure, and break the loop.\n5. If retries remain, update the module's status to `CORRECTION_IN_PROGRESS`, call the `invokeCorrectorAgent` with the module's contract, the failing code, and the test report.\n6. Replace the module's `implementationCode` with the newly corrected code from the agent and continue to the next iteration of the loop."
        },
        {
          "step 7": "Integrate the `Dependency Failure Propagation` logic. After the verification/correction loops for all modules have completed, iterate through the modules one last time. For each module, check its final status. If a module's status is `VERIFICATION_FAILED`, find all other modules that list it as a dependency. Mark each of these dependent modules as `FAILED_DEPENDENCY`, as they cannot be integrated correctly."
        },
        {
          "step 8": "Review and refine the logging within the orchestrator. Add detailed log statements at each key step of the correction loop: when verification fails, when a correction attempt is initiated, when corrected code is received, and the final outcome (success or failure) for each module. This is critical for debugging the autonomous system itself."
        }
      ],
      "Task 4.5: Implement the 'Dependency Failure Propagation' logic that marks modules as failed if any of their dependencies failed verification.": [
        {
          "step 1": "Create a new file at `src/verification/dependency-propagator.ts`. Inside this file, define the necessary types for the verification process. Specifically, create a `VerificationStatus` string literal type ('PASSED' | 'FAILED' | 'PENDING') and a `ModuleVerificationResult` interface with properties: `moduleName: string`, `dependencies: string[]`, and `status: VerificationStatus`."
        },
        {
          "step 2": "In `src/verification/dependency-propagator.ts`, implement an exported function `propagateDependencyFailures(results: ModuleVerificationResult[]): ModuleVerificationResult[]`. This function must not mutate the input array. It should perform the following logic:\n1. Create a deep copy of the input `results` array.\n2. Create a `Set<string>` containing the names of all modules that initially have a 'FAILED' status.\n3. Use a loop that continues as long as new failures are propagated in a pass (a `do-while` loop is a good choice here).\n4. In each pass, iterate through all modules in the copied array. For each module that is not already marked 'FAILED', check if any of its `dependencies` exist in the failed modules set.\n5. If a dependency has failed, update the current module's status to 'FAILED', add its name to the failed modules set, and signal that a change occurred in this pass.\n6. The loop terminates when a full pass over all modules results in no new failures being added.\n7. Return the updated array of results."
        },
        {
          "step 3": "Create a corresponding test file at `src/verification/dependency-propagator.test.ts`. Import the `propagateDependencyFailures` function and the `ModuleVerificationResult` type. Use a testing framework like Jest or Vitest to set up the test suite. Prepare mock data for the test cases."
        },
        {
          "step 4": "In `dependency-propagator.test.ts`, write unit tests for the following basic scenarios:\n1. **No Failures:** A test case where all modules have a 'PASSED' status. Assert that the output is identical to the input.\n2. **Direct Dependency Failure:** A test case with three modules (A, B, C). Module A depends on B. Module B's initial status is 'FAILED'. Assert that the final status of Module A is 'FAILED', while C's status remains unchanged."
        },
        {
          "step 5": "In `dependency-propagator.test.ts`, add more complex unit tests to ensure robustness:\n1. **Transitive Dependency Failure:** A test case where Module A depends on B, and B depends on C. C's initial status is 'FAILED'. Assert that both A and B are marked as 'FAILED' in the output.\n2. **Multiple Dependencies Failure:** A test case where Module A depends on B and C. C's initial status is 'FAILED'. Assert that A is marked as 'FAILED'.\n3. **Diamond Dependency Failure:** A test case where D depends on B and C; B and C both depend on A. A's initial status is 'FAILED'. Assert that B, C, and D are all marked as 'FAILED' in the output."
        },
        {
          "step 6": "Finally, integrate the new logic into the main system orchestrator. Locate the code responsible for managing 'Stage 3: Verification, Correction, and Integration'. After the initial parallel verification and correction loops are complete and you have a definitive list of each module's pass/fail status, call the `propagateDependencyFailures` function. Use the result from this function (the list with propagated failures) for all subsequent logic, such as determining which modules to pass to the 'Integrator' agent."
        }
      ],
      "Task 4.6: Implement the 'Integrator' agent, responsible for performing a topological sort on the dependency graph of successful modules.": [
        {
          "step 1": "Create a new file `src/agents/integrator.ts`. In this file, define a class named `Integrator`. This class will be responsible for orchestrating the final assembly of the project. For now, its constructor should accept an array of `ModuleContract` objects. Create a placeholder public method `generateInstantiationOrder()` that takes a list of successful module names (string array) and returns an array of strings."
        },
        {
          "step 2": "Inside the `Integrator` class, implement a private helper method `_buildDependencyGraph(successfulModuleNames: string[])`. This method should parse the `ModuleContract[]` stored in the class instance. It will construct two data structures: an adjacency list (e.g., `Map<string, string[]>`) representing the graph where a key is a module and the value is an array of its dependencies, and an in-degree map (e.g., `Map<string, number>`) tracking how many incoming edges each module has. Only include modules present in the `successfulModuleNames` list in your graph."
        },
        {
          "step 3": "Implement the core topological sort logic (Kahn's algorithm) within the `generateInstantiationOrder` method. Use the `_buildDependencyGraph` helper to get the initial graph and in-degrees. Initialize a queue with all modules that have an in-degree of 0. Then, loop while the queue is not empty: dequeue a module, add it to your sorted list, and for each of its neighbors, decrement their in-degree. If a neighbor's in-degree becomes 0, enqueue it."
        },
        {
          "step 4": "Enhance your topological sort implementation to include robust cycle detection. A cycle exists if the final sorted list of modules does not contain all the modules that were initially in the graph (i.e., the `successfulModuleNames`). If a cycle is detected, throw a specific `Error` with a message that clearly indicates a circular dependency was found and lists the modules that could not be sorted."
        },
        {
          "step 5": "Refactor the `Integrator` class to ensure clear separation of concerns. The `generateInstantiationOrder` method should be the main public entry point that orchestrates the calls to `_buildDependencyGraph` and the sorting loop. Ensure the final output is the correctly ordered list of module names for instantiation, or an error is thrown for cycles."
        },
        {
          "step 6": "Create a new test file `src/agents/integrator.test.ts`. Write unit tests for the `Integrator` class using a testing framework like Jest. Your tests should cover successful sorting scenarios. Use mock `ModuleContract` objects to test at least the following cases: a simple linear dependency (e.g., A depends on B, B depends on C), a more complex directed acyclic graph (e.g., A depends on B and C, B depends on D, C depends on D), and a set of modules with no dependencies."
        },
        {
          "step 7": "Add unit tests to `src/agents/integrator.test.ts` specifically for failure conditions. Test that the `generateInstantiationOrder` method correctly throws an error when the dependency graph contains a cycle. Create mock contracts for a simple two-module cycle (A -> B -> A) and a more complex three-module cycle (A -> B -> C -> A). Verify that the error message is informative."
        },
        {
          "step 8": "Add a final unit test case to handle scenarios where a module lists a dependency that is not in the list of successful modules. The `_buildDependencyGraph` method should gracefully ignore dependencies on modules that are not in the `successfulModuleNames` input array, as those modules are considered failed and out of scope for integration."
        }
      ],
      "Task 4.7: Enhance the 'Integrator' agent to generate the main application entry point (e.g., main.ts) by correctly importing and instantiating all verified modules.": [
        {
          "step 1": "Create a new file `src/agents/integrator.ts`. This file will house the logic for the Integrator agent, specifically the function to generate the main application entry point."
        },
        {
          "step 2": "In `src/agents/integrator.ts`, import the necessary types, especially `ModuleContract` from your schema definitions. Then, define the function signature for the entry point generator: `export function generateMainEntryPoint(contracts: ModuleContract[], verifiedModuleNames: string[]): string`. This function will take the full list of contracts and the names of the modules that have successfully passed verification."
        },
        {
          "step 3": "Implement a helper function within `integrator.ts` to perform a topological sort on the module dependency graph. The function signature should be `function topologicalSort(contracts: ModuleContract[], verifiedModuleNames: string[]): string[]`. It should first build a directed graph (e.g., using an adjacency list `Map<string, string[]>`) where nodes are module names and edges represent dependencies. Crucially, only include modules present in the `verifiedModuleNames` list. The function should return an array of module names in the correct instantiation order or throw an error if a cycle is detected."
        },
        {
          "step 4": "In the `generateMainEntryPoint` function, begin by calling the `topologicalSort` function to get the ordered list of modules. Handle the potential error for cyclic dependencies gracefully. Store the result in a variable, for example, `instantiationOrder`."
        },
        {
          "step 5": "Next, implement the code generation for the import statements. Iterate through the `verifiedModuleNames`. For each module name, find its corresponding contract, and generate a TypeScript import statement. For a module named 'Database', the output should be `import { Database } from './modules/Database';`. Concatenate these import strings into a single block."
        },
        {
          "step 6": "Now, implement the code generation for module instantiation. Iterate through the `instantiationOrder` array. For each module name: \n1. Find its contract in the `contracts` array.\n2. Look up its `constructorParams`. \n3. Generate the instantiation code, e.g., `const database = new Database(config);`. \n4. The arguments for the constructor must be the variable names of the dependencies, which should have already been instantiated due to the topological sort. Use a convention like camelCase for variable names (e.g., 'Database' module becomes 'database' variable). Keep a map of module names to their instance variable names for easy lookup."
        },
        {
          "step 7": "After generating the imports and instantiations, add a simple asynchronous IIFE (Immediately Invoked Function Expression) to the end of the generated code string. This will serve as the main execution block. For example: `\n\n(async () => {\n  console.log('Application starting...');\n  // You can add a call to a method on the final module in the chain here if applicable.\n})();\n`. This makes the generated `main.ts` file runnable."
        },
        {
          "step 8": "Create a new test file `src/agents/integrator.test.ts`. Import the `generateMainEntryPoint` function and the `ModuleContract` type."
        },
        {
          "step 9": "Write unit tests for the `topologicalSort` helper function. Create mock `ModuleContract` data to test several scenarios: \n1. A simple linear dependency (A depends on B, B depends on C). \n2. A more complex graph with multiple dependencies (e.g., a diamond shape). \n3. A graph with a cycle, and assert that your function correctly throws an error. \n4. A case where some modules are not in the `verifiedModuleNames` list and ensure they are excluded from the sort."
        },
        {
          "step 10": "Write a comprehensive test for the `generateMainEntryPoint` function. Create a set of mock `ModuleContract` objects representing a small but non-trivial project. Call `generateMainEntryPoint` with these mocks and a list of verified modules. Assert that the returned string contains: \n1. The correct import statements for all verified modules. \n2. The correct instantiation order as determined by a topological sort. \n3. The correct dependency injection, where constructor arguments are the variable names of previously instantiated modules."
        },
        {
          "step 11": "Finally, review the complete implementation in `src/agents/integrator.ts`. Add JSDoc comments to all functions explaining their purpose, parameters, and return values. Ensure strong typing is used throughout and that any potential edge cases (like an empty list of verified modules) are handled correctly. Refactor the code for clarity and maintainability."
        }
      ],
      "Task 4.8: Task the 'Integrator' agent with generating necessary project configuration files (package.json, tsconfig.json, README.md).": [
        {
          "step 1": "First, you must determine the project's dependencies to create an accurate `package.json`. Scan the `implementationCode` for all successfully verified modules. Analyze the `import` statements to identify all external npm packages. Ignore relative imports (e.g., './module') and built-in Node.js modules (e.g., 'fs', 'path'). Compile these into a list of production dependencies. Your dev dependencies should include `typescript`, `ts-node`, `jest`, `ts-jest`, `@types/node`, and `@types/jest`. Store these two lists for the next step."
        },
        {
          "step 2": "Using the dependency lists from the previous step, generate the `package.json` file. The file should be created in the root of the project directory. Use the original high-level user goal to create a kebab-case `name` and a descriptive `description`. Set the `version` to `1.0.0` and `main` to `dist/main.js`. Populate the `dependencies` and `devDependencies` fields. Define the `scripts` section with the following commands: `\"start\": \"ts-node src/main.ts\"`, `\"build\": \"tsc\"`, and `\"test\": \"jest\"`."
        },
        {
          "step 3": "Generate the TypeScript configuration file, `tsconfig.json`, in the project root. Use the following JSON content, which provides a robust configuration for a modern Node.js project. Ensure the file is created with exactly this content. \n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"CommonJS\",\n    \"rootDir\": \"./src\",\n    \"outDir\": \"./dist\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*.ts\"],\n  \"exclude\": [\"node_modules\", \"**/*.test.ts\"]\n}\n```"
        },
        {
          "step 4": "Generate a comprehensive `README.md` file in the project root. Synthesize information from the original user goal and the `ModuleContract[]` document. The README should have the following structure:\n1.  **Project Title:** A main heading (`#`) derived from the user goal.\n2.  **Description:** A paragraph summarizing the project's purpose.\n3.  **Architecture Overview:** A sub-heading (`##`) followed by a list of all modules defined in the `ModuleContract[]` document. For each module, list its name and `purpose`.\n4.  **Installation:** A sub-heading with instructions: `npm install`.\n5.  **Running the Application:** A sub-heading with instructions: `npm start`.\n6.  **Running Tests:** A sub-heading with instructions: `npm test`."
        }
      ],
      "Task 4.9: Implement the 'Final Assembler' utility that writes all generated source code, tests, and configuration files into a coherent project directory structure.": [
        {
          "step 1": "Create a new file at `src/utils/final_assembler.ts`. Inside this file, define the necessary types for the inputs. Create a `SuccessfulModule` type with `name: string`, `implementationCode: string`, and `testCode: string`. Then, define an `AssemblyData` type that includes `successfulModules: SuccessfulModule[]`, `packageJsonContent: string`, `tsConfigJsonContent: string`, `mainTsContent: string`, and `readmeContent: string`. Finally, define the main function signature: `export async function assembleProject(data: AssemblyData, outputDir: string): Promise<string>`. The function will eventually return the path to the final zip archive."
        },
        {
          "step 2": "In `assembleProject`, implement the project directory creation logic. Use the `fs/promises` module. First, create the main output directory specified by `outputDir`. Then, create the `src` and `tests` subdirectories within it. Use `path.join` for constructing paths to ensure cross-platform compatibility. Hint: Use the `{ recursive: true }` option in `fs.mkdir` to prevent errors if the directory already exists."
        },
        {
          "step 3": "Implement the logic to write the module source code and test files. Iterate over the `data.successfulModules` array. For each module, create a suitable filename from its `name` (e.g., 'MyApiModule' -> 'myApiModule.ts'). Write the `implementationCode` to a file in the `src` directory (e.g., `[outputDir]/src/myApiModule.ts`) and the `testCode` to a file in the `tests` directory (e.g., `[outputDir]/tests/myApiModule.test.ts`). Use `fs/promises.writeFile` for all file operations."
        },
        {
          "step 4": "Next, write the static configuration and entry point files to the root of the project directory. Use `fs/promises.writeFile` to create the following files with their corresponding content from the `data` object: `[outputDir]/package.json`, `[outputDir]/tsconfig.json`, `[outputDir]/README.md`, and `[outputDir]/main.ts`."
        },
        {
          "step 5": "Now, implement the zipping functionality. First, add the `archiver` library to the project dependencies by running `npm install archiver` and `npm install @types/archiver --save-dev`. Create a new private helper function `async function zipDirectory(sourceDir: string, outPath: string): Promise<void>`. Inside this function, use `archiver` to create a zip archive of the `sourceDir` and save it to `outPath`. Ensure you handle the stream events correctly (`'close'`, `'error'`) within a Promise."
        },
        {
          "step 6": "Integrate the zipping functionality into the `assembleProject` function. After all files and directories have been written successfully, define the output path for the zip file (e.g., `${outputDir}.zip`). Call your `zipDirectory` helper function with the `outputDir` and the new zip file path. The `assembleProject` function should return the path to this generated zip file upon successful completion. Add comprehensive `try...catch` blocks around all I/O operations and include `console.log` statements to provide feedback on the assembly process (e.g., 'Creating directories...', 'Writing module file X...', 'Zipping project...')."
        },
        {
          "step 7": "Create a new test file at `src/utils/final_assembler.test.ts`. To test the file system operations without writing to disk, install the `mock-fs` library: `npm install mock-fs --save-dev` and `npm install @types/mock-fs --save-dev`. Set up a basic test suite using your preferred test runner (e.g., Jest) and import `assembleProject` and `mock-fs`."
        },
        {
          "step 8": "Write a comprehensive unit test for `assembleProject`. In the test, define mock `AssemblyData`. Use `mock-fs` to set up a virtual file system before the test runs and restore it afterward (`mock.restore()`). Call `assembleProject` with the mock data. After it executes, use `fs.readFileSync` and `fs.existsSync` (which will operate on the mocked file system) to assert that: 1. The `src` and `tests` directories were created. 2. All module source files and test files exist in the correct locations with the correct content. 3. All configuration files (`package.json`, etc.) exist in the root directory with the correct content."
        }
      ],
      "Task 4.10: Implement the final project archiving utility to package the assembled project directory into a single downloadable .zip file.": [
        {
          "step 1": "Create a new file at `src/services/archiver.service.ts`. This file will contain the utility function for creating zip archives."
        },
        {
          "step 2": "To handle zip file creation efficiently, you will use the `archiver` library. Add it and its corresponding type definitions to the project's development dependencies. Execute the following command: `npm install archiver --save` and `npm install @types/archiver --save-dev`."
        },
        {
          "step 3": "In `src/services/archiver.service.ts`, define and export an asynchronous function named `createProjectZip`. This function should accept two string parameters: `sourceDir` (the path to the directory to be zipped) and `outPath` (the file path for the output zip archive). It should return a `Promise<void>` that resolves upon successful creation of the archive and rejects on error."
        },
        {
          "step 4": "Implement the logic for the `createProjectZip` function. Use the `fs` module to create a write stream to `outPath`. Initialize an `archiver` instance with the 'zip' format. Your implementation must handle the full lifecycle: pipe the archiver to the output stream, listen for the 'close' event on the stream to resolve the promise, and listen for 'error' events on both the stream and the archiver to reject the promise. Use `archiver.directory(sourceDir, false)` to add the contents of the source directory to the root of the archive. Finally, call `archiver.finalize()` to start the process."
        },
        {
          "step 5": "Create a corresponding test file at `src/services/archiver.service.test.ts` to ensure the archiving utility is robust and reliable."
        },
        {
          "step 6": "In `src/services/archiver.service.test.ts`, write a test case for the successful creation of a zip archive. Use the `fs/promises` and `path` modules to create a temporary directory structure for testing (e.g., `tmp/test-project/`). Populate it with a few dummy files (e.g., `index.js`, `data/file.txt`). Call `createProjectZip` and assert that the output zip file exists after the function completes. Ensure you implement proper setup and teardown logic to create and remove the temporary files and directories for each test."
        },
        {
          "step 7": "To verify the integrity of the created archive, add a library for reading zip files to your dev dependencies. `adm-zip` is a good choice. Run `npm install adm-zip @types/adm-zip --save-dev`. Enhance your primary success test case: after creating the zip, use `adm-zip` to read the archive and assert that the list of file entries and their contents match the temporary source directory you created."
        },
        {
          "step 8": "Add a test case to verify the error handling. Call `createProjectZip` with a path to a non-existent source directory. Assert that the returned promise is rejected, and that the error message is appropriate. This ensures the function behaves predictably when given invalid input."
        }
      ]
    },
    "Phase 5: Final Integration, Assembly, and Packaging": {
      "Task 5.1: Determine the final set of successful modules by propagating dependency failures.": [
        {
          "step 1": "Create a new script file named `src/integration/propagate_failures.ts` to house the logic for determining the final set of successful and failed modules."
        },
        {
          "step 2": "In `propagate_failures.ts`, define the necessary type definitions to represent the module contracts and verification results. You will need to read `build/contracts.json` and `build/verification_results.json`. Assume `verification_results.json` is an array of objects, each with `moduleName: string` and `status: 'success' | 'failure'`."
        },
        {
          "step 3": "Implement a function to load the module contracts from `build/contracts.json` and the verification results from `build/verification_results.json`. This function should return both data structures for further processing."
        },
        {
          "step 4": "Implement a function `buildDependencyGraphs(contracts: ModuleContract[])`. This function should create and return two data structures: a `dependencies` graph and a `dependents` graph. A `Map<string, string[]>` is a suitable choice for both. The `dependencies` graph maps a module to the modules it depends on. The `dependents` graph maps a module to the modules that depend on it (the reverse mapping)."
        },
        {
          "step 5": "Implement the core failure propagation logic in a function `calculateFinalStatuses`. This function should take the list of all module names, the verification results, and the `dependents` graph as input. Follow this algorithm: \n1. Initialize a `Set<string>` called `failedModules` with the names of all modules that have a 'failure' status in the verification results. \n2. Initialize a queue (e.g., an array) with the initial list of failed modules. \n3. While the queue is not empty, dequeue a module name. \n4. Find all modules that depend on this failed module using your `dependents` graph. \n5. For each dependent module, if it's not already in the `failedModules` set, add it to the set and enqueue it. \n6. After the loop terminates, the `failedModules` set will contain the complete list of all failed modules (initial and propagated). \n7. Determine the list of `successfulModules` by taking the set difference between all module names and the final `failedModules` set."
        },
        {
          "step 6": "Create a main execution function that orchestrates the entire process: \n1. Call the function to load contracts and verification results. \n2. Call `buildDependencyGraphs` to get the dependency mappings. \n3. Call `calculateFinalStatuses` to get the final lists of successful and failed modules. \n4. Write the results to a new file at `build/final_module_statuses.json`. The JSON structure should be: `{ \"successfulModules\": string[], \"failedModules\": string[] }`."
        },
        {
          "step 7": "Add a command to your `package.json` scripts section, e.g., `\"propagate:failures\": \"ts-node src/integration/propagate_failures.ts\"`, to allow for easy execution of this script."
        }
      ],
      "Task 5.2: Perform a topological sort on the dependency graph of successful modules.": [
        {
          "step 1": "Create a new file at `src/integrator/dependency_sorter.ts`. This utility file will be responsible for performing a topological sort on the dependency graph of the verified modules."
        },
        {
          "step 2": "In `src/integrator/dependency_sorter.ts`, define and export a function named `topologicalSort`. This function should accept two arguments: `allModules: ModuleContract[]` (the full list of module contracts from the contract document) and `successfulModuleNames: Set<string>` (a set of names for the modules that have passed verification). The function should return a `string[]` representing the correctly ordered list of module names for instantiation. Import the `ModuleContract` type from `src/types/contract.ts`."
        },
        {
          "step 3": "Implement the `topologicalSort` function using Kahn's algorithm. Start by filtering the `allModules` array to only include the modules present in the `successfulModuleNames` set. Then, build the necessary data structures for the algorithm: an in-degree map (`Map<string, number>`) and an adjacency list (`Map<string, string[]>`).\n\n**Hint:**\n1. Initialize the in-degree for every successful module based on the length of its `dependencies` array.\n2. The adjacency list should map a dependency to the modules that depend on it. For a module `A` that depends on `B`, the entry should be `adj.get('B').push('A')`."
        },
        {
          "step 4": "Continue the implementation of `topologicalSort`. Initialize a queue with all successful modules that have an in-degree of 0 (i.e., no dependencies within the successful set). Then, begin processing the queue: dequeue a module, add its name to the final sorted list, and for each module that depends on it (using your adjacency list), decrement its in-degree. If a dependent's in-degree becomes 0, add it to the queue. Continue this process until the queue is empty."
        },
        {
          "step 5": "Finalize the `topologicalSort` function by adding robust error handling for circular dependencies. After the main processing loop is complete, compare the length of your resulting sorted list with the total number of successful modules. If they do not match, it indicates a cycle in the dependency graph. In this case, throw a `new Error('Circular dependency detected among successful modules. Cannot complete integration.')`."
        },
        {
          "step 6": "Create a corresponding test file `src/integrator/dependency_sorter.test.ts`. Write a comprehensive suite of unit tests for the `topologicalSort` function using Jest. Mock the `ModuleContract` data to test the following scenarios:\n1. A simple linear dependency chain.\n2. A complex Directed Acyclic Graph (DAG) with multiple branches (e.g., a diamond dependency).\n3. A graph containing modules with no dependencies.\n4. A graph with a direct circular dependency (A -> B, B -> A) to verify that an error is thrown.\n5. A graph with an indirect circular dependency (A -> B -> C -> A) to verify error handling.\n6. A scenario where `successfulModuleNames` correctly filters out a module that would otherwise be part of a cycle."
        }
      ],
      "Task 5.3: Generate the main application entry point (e.g., main.ts) to integrate all successful modules.": [
        {
          "step 1": "Analyze the dependency graph of all successfully verified modules. You will be provided with the full `module_contracts.json` document and a list of module names that have passed verification. Filter the contracts to include only the successful modules. From these, construct a directed graph where an edge from module A to module B means A depends on B. Perform a topological sort on this graph to determine the precise order in which modules must be instantiated. Output the topologically sorted list of module names."
        },
        {
          "step 2": "Using the topologically sorted list of module names from the previous step, generate the TypeScript import statements for the main entry point file. For each module (e.g., 'Database'), assume its class is exported from a file with the same name within a 'src/modules' directory (e.g., `import { Database } from './modules/Database';`)."
        },
        {
          "step 3": "Generate the TypeScript instantiation code for all successful modules. Iterate through the topologically sorted list of module names. For each module, create a `const` variable (e.g., `const database = new Database(...)`). Use the `module_contracts.json` to determine the correct constructor parameters (`constructorParams`). The arguments passed to the constructor must be the variable names of the dependencies, which will have already been instantiated due to the topological sort. Ensure variable names are a camelCase version of the module class name (e.g., 'ApiServer' -> 'apiServer')."
        },
        {
          "step 4": "Assemble the final `main.ts` file. Combine the import statements from step 2 and the instantiation code from step 3. Wrap the instantiation logic within a self-executing `async function main()`. Include `try/catch` error handling for the initialization process. Add console logs to indicate the start of initialization and its successful completion. Add a placeholder comment for where application startup logic (e.g., `server.listen()`) would be called after all modules are instantiated."
        }
      ],
      "Task 5.4: Generate the project's package.json file, including all necessary dependencies and scripts.": [
        {
          "step 1": "Analyze all verified module code to identify external dependencies. Read the `implementationCode` and `testCode` for every successful module. Scan for all `import` or `require` statements that point to external npm packages. Ignore Node.js built-in modules (e.g., 'fs', 'path') and local relative imports (e.g., './', '../'). Create two distinct lists: one for production dependencies found in `implementationCode` and one for development dependencies found in `testCode`."
        },
        {
          "step 2": "Augment the development dependencies list with standard TypeScript project tooling. To the list of development dependencies you identified in the previous step, add the following essential packages if they are not already present: 'typescript', 'ts-node', 'jest', 'ts-jest', '@types/jest', and '@types/node'. Ensure the final list of development dependencies is unique."
        },
        {
          "step 3": "Define the project metadata and scripts. Using the original high-level user goal as a reference, create a suitable 'name' (e.g., 'real-time-chat-app') and 'description' for the project. Prepare a JSON object with the following standard fields and values: 'version': '1.0.0', 'main': 'dist/main.js', 'author': 'Autonomous AI Agent', 'license': 'MIT'."
        },
        {
          "step 4": "Define the standard npm scripts for the project. Create a 'scripts' object with the following key-value pairs: 'start': 'ts-node src/main.ts', 'test': 'jest', and 'build': 'tsc'."
        },
        {
          "step 5": "Assemble and create the final package.json file. Combine the production dependency list, the augmented development dependency list, the project metadata, and the scripts into a single, well-formatted JSON object. For all packages in the dependency lists, use 'latest' as the version string. Write this final JSON object to a new file named 'package.json' in the project's root directory."
        }
      ],
      "Task 5.5: Generate the tsconfig.json configuration file.": [
        {
          "step 1": "Analyze the project's file structure, specifically noting the location of source files (e.g., in a `src` directory) and test files. Also, review the `package.json` file to identify TypeScript-related dependencies (`typescript`, `ts-node`, `ts-jest`, etc.) and scripts. This context will inform the creation of the `tsconfig.json` file."
        },
        {
          "step 2": "Generate the `compilerOptions` for a modern, robust Node.js TypeScript project. Create a JSON object with the following recommended settings:\n- `target`: \"ES2022\"\n- `module`: \"NodeNext\"\n- `moduleResolution`: \"NodeNext\"\n- `outDir`: \"./dist\"\n- `rootDir`: \"./src\"\n- `strict`: true\n- `esModuleInterop`: true\n- `skipLibCheck`: true\n- `resolveJsonModule`: true\n- `sourceMap`: true\n- `declaration`: true\n- `baseUrl`: \".\"\nEnsure these options are appropriate for a backend application that will be compiled to JavaScript for production."
        },
        {
          "step 3": "Now, add the `include` and `exclude` properties to your configuration object. Set `include` to an array containing `[\"src/**/*\"]` to ensure all files within the source directory are processed. Set `exclude` to an array containing `[\"node_modules\", \"dist\", \"**/*.test.ts\", \"**/*.spec.ts\"]` to prevent the compiler from processing dependencies, the output directory, and test files during the main build."
        },
        {
          "step 4": "Combine the `compilerOptions`, `include`, and `exclude` properties into a single, valid JSON object. Write this final configuration to a new file named `tsconfig.json` in the root directory of the project. Ensure the file is well-formatted with standard indentation."
        }
      ],
      "Task 5.6: Generate a comprehensive README.md file for the project.": [
        {
          "step 1": "Analyze all available project artifacts to gather context for the README.md file. Load and parse the original user goal, the `reasoning_tree.json`, the final `ModuleContract[]` document, and the `package.json` file. Extract key information such as the project's main objective, the high-level architecture (module names and their purposes), and the commands required for installation and execution."
        },
        {
          "step 2": "Draft the content for the README.md in Markdown format. Based on the artifacts analyzed in the previous step, generate text for the following sections: \n1. **Project Title:** A concise and descriptive title based on the user goal. \n2. **Description:** A one or two-paragraph overview of what the project does. \n3. **Architecture Overview:** A section that lists each module from the `ModuleContract[]` document, briefly explaining its purpose and its primary dependencies. This explains *how* the project is built. \n4. **Installation:** A 'Getting Started' section that provides the exact command (e.g., `npm install`) from `package.json` to install dependencies. \n5. **Usage:** A section with sub-headings for 'Running the Application' and 'Running Tests', providing the specific commands defined in the `package.json` scripts. \n6. **Built With:** A brief concluding note stating that the project was autonomously generated by this framework, highlighting the principles of Hierarchical Planning and Contract-First Design."
        },
        {
          "step 3": "Assemble the drafted sections into a single, cohesive Markdown document. Ensure proper formatting with appropriate headings (e.g., `#`, `##`), code fences for commands (```bash...```), and lists. Pay attention to clarity and readability."
        },
        {
          "step 4": "Write the final, formatted Markdown string to a new file named `README.md` in the root directory of the project."
        }
      ],
      "Task 5.7: Assemble all generated source code, tests, and configuration files into the final project directory structure.": [
        {
          "step 1": "Create the root directory for the final project named `output_project`. Inside `output_project`, create two subdirectories: `src` and `tests`."
        },
        {
          "step 2": "Inside the `output_project/src` directory, create a new subdirectory named `modules`. Similarly, inside the `output_project/tests` directory, create a subdirectory named `modules`. This will keep the module source code and their corresponding tests organized."
        },
        {
          "step 3": "Access the collection of all verified modules from Stage 3. For each module, retrieve its `implementationCode` and `moduleName`. Write the `implementationCode` to a new file inside the `output_project/src/modules/` directory. The filename must be `{moduleName}.ts`, using the exact name from the module contract (e.g., `Logger.ts`, `APIClient.ts`)."
        },
        {
          "step 4": "Using the same collection of verified modules, now write the corresponding test files. For each module, retrieve its `testCode` and `moduleName`. Write the `testCode` to a new file inside the `output_project/tests/modules/` directory. The filename must be `{moduleName}.test.ts` (e.g., `Logger.test.ts`, `APIClient.test.ts`)."
        },
        {
          "step 5": "Retrieve the `main.ts` content that was generated by the Integrator agent in Task 5.3. Write this content to the file path `output_project/src/main.ts`."
        },
        {
          "step 6": "Retrieve the contents for `package.json` (from Task 5.4), `tsconfig.json` (from Task 5.5), and `README.md` (from Task 5.6). Write each of these files to the root of the `output_project` directory."
        },
        {
          "step 7": "As a final assembly step, create a standard `.gitignore` file in the `output_project` root directory to ensure version control hygiene. Populate it with common patterns for a Node.js/TypeScript project. Hint: Include entries such as `node_modules/`, `dist/`, `build/`, `.env`, `*.log`, `coverage/`, and IDE-specific folders like `.vscode/`."
        }
      ],
      "Task 5.8: Create a final, downloadable .zip archive of the complete project.": [
        {
          "step 1": "Create a new JavaScript file named `create_archive.js` in the project's root directory. This script will be responsible for packaging the final project."
        },
        {
          "step 2": "To handle the creation of the zip archive, you will need the `archiver` library. Add this as a development dependency to the project by running `npm install archiver --save-dev` in the terminal. Ensure the `package.json` and `package-lock.json` files are updated."
        },
        {
          "step 3": "Implement the logic in `create_archive.js` to compress the contents of the `./dist` directory into a zip file. The final archive should be named `project_archive.zip` and placed in the project's root directory. Hint: Use the `fs` and `archiver` modules. Your script should: 1. Define the output file path and the source directory. 2. Create a write stream for the output file. 3. Initialize the archiver with the 'zip' format. 4. Pipe the archive data to the file stream. 5. Add the entire `./dist` directory to the root of the archive using `archive.directory('dist/', false)`. 6. Finalize the archive. 7. Include console logs to indicate when the process is complete or if an error occurs."
        },
        {
          "step 4": "Execute the script you just created to generate the zip archive. Run the command `node create_archive.js` from the project's root directory in your terminal."
        },
        {
          "step 5": "Verify that the task was successful. List the files in the root directory and confirm that a file named `project_archive.zip` exists. You can use the command `ls -l project_archive.zip` to check for its presence and size."
        }
      ]
    }
  },
  "last_phase": "Phase 3: Parallel Module Code Generation (Stage 2)",
  "last_task": "Develop the Stage 2 orchestrator logic to load the validated `ModuleContract[]` document.",
  "last_step_index": 3
}