{
  "Phase 1: Requirements Definition & Architectural Design": {
    "Task 1.1: Define Target User Profile(s) and Key Use Cases": [
      {
        "step 1": "Brainstorm a list of potential target user groups for a new Integrated Development Environment (IDE). Consider factors like programming experience (beginner, intermediate, expert), primary programming languages (e.g., Python, JavaScript, Java, C++, Go, Rust), development domain (e.g., web development, data science, systems programming, game development, education), and typical project size/complexity. Aim for at least 5 distinct groups. Document these initial ideas in a temporary file or internal memory."
      },
      {
        "step 2": "Analyze the brainstormed list from Step 1. Select 1 to 2 primary target user groups that the IDE will focus on initially. Justify the selection based on potential impact, market opportunity, or feasibility. Hint: Focusing on a niche initially can be more manageable than trying to cater to everyone."
      },
      {
        "step 3": "For each selected primary target user group, create a detailed user persona. Each persona should include: a fictional name, role/job title, technical skills/experience level, primary programming languages/tools used, development goals, motivations for using an IDE, and key pain points with existing IDEs or text editors. Hint: Search the web for 'developer user persona examples' for inspiration."
      },
      {
        "step 4": "Based on the created user personas (Step 3), identify the key high-level use cases for the IDE. Think about the core tasks these users need to accomplish daily. Examples include: 'Writing and editing code', 'Debugging applications', 'Running and testing code', 'Managing project files', 'Integrating with version control (e.g., Git)', 'Navigating large codebases'. List at least 5-7 core use cases."
      },
      {
        "step 5": "Refine the use cases identified in Step 4 by adding more detail. For each high-level use case, describe the typical workflow or specific actions involved. For example, for 'Writing and editing code', sub-actions might include 'Code completion', 'Syntax highlighting', 'Code formatting', 'Refactoring'. For 'Debugging applications', it might include 'Setting breakpoints', 'Stepping through code', 'Inspecting variables'."
      },
      {
        "step 6": "Prioritize the detailed use cases identified in Step 5 using the MoSCoW method (Must-have, Should-have, Could-have, Won't-have for this initial version). Base the prioritization on the needs and pain points defined in the user personas (Step 3). Hint: Focus on the 'Must-have' and 'Should-have' features that provide the most value to the target users."
      },
      {
        "step 7": "Consolidate the target user profiles, detailed personas, and prioritized use cases (including their MoSCoW rating) into a single, well-structured Markdown document named 'user_requirements.md'. Ensure the document is clear, concise, and easy to understand. This document will serve as a foundational reference for subsequent design and development phases."
      }
    ],
    "Task 1.2: Elicit and Document Functional Requirements (Core Features: editor, build, debug, VCS, etc.)": [
      {
        "step 1": "Identify and list the core functional modules required for a minimally viable Integrated Development Environment (IDE). Store this list internally for subsequent steps. Hint: Consider common modules like Code Editor, Build System Integration, Debugger, Version Control System (VCS) Integration, and Project/File Management. Briefly review features of popular IDEs (e.g., VS Code, IntelliJ IDEA, PyCharm, Eclipse) for inspiration."
      },
      {
        "step 2": "Focusing on the 'Code Editor' module identified in the previous step, elicit and list detailed functional requirements for essential editing capabilities. Store these requirements internally. Hint: Include requirements for syntax highlighting (note the need, specific languages TBD), basic code completion (e.g., keywords, known variables), text manipulation (cut, copy, paste, undo, redo), find/replace, line numbering, automatic indentation, and saving/loading files. Search web for 'essential code editor features' or 'minimal viable code editor requirements'."
      },
      {
        "step 3": "Focusing on 'Build System Integration', elicit and list detailed functional requirements. Store these requirements internally. Hint: Include requirements for executing predefined build commands (e.g., invoking `make`, `gcc`, `npm run build`), displaying build command output (stdout/stderr) in a dedicated panel/view, indicating build success or failure status, and allowing users to configure build commands (perhaps on a per-project basis). Consider how errors reported by the build tool might be surfaced."
      },
      {
        "step 4": "Focusing on the 'Debugger' module, elicit and list detailed functional requirements for core debugging actions. Store these requirements internally. Hint: Include setting/clearing breakpoints visually (e.g., in the editor gutter), starting a program in debug mode, stepping operations (step over, step into, step out), resuming execution (continue), viewing the current call stack, and inspecting the values of local variables at breakpoints. Consider researching the Debug Adapter Protocol (DAP) briefly to understand common debugger capabilities, but list user-facing features."
      },
      {
        "step 5": "Focusing on 'Version Control System (VCS) Integration', elicit and list detailed functional requirements, initially targeting Git. Store these requirements internally. Hint: Include requirements for viewing file status changes (e.g., modified, new, staged) within the file explorer, staging/unstaging individual files or changes, committing staged changes with a user-provided message, viewing a simple commit history (log), and displaying differences (diff) for modified files."
      },
      {
        "step 6": "Focusing on 'Project/File Management', elicit and list detailed functional requirements. Store these requirements internally. Hint: Include requirements for displaying project files and directories in a hierarchical tree view, opening files from the tree view into the editor, creating new files and folders within the project structure, renaming/deleting files and folders (consider adding confirmation dialogs), and establishing the concept of a 'project root' or workspace directory."
      },
      {
        "step 7": "Briefly consider requirements related to IDE extensibility or plugin support. Decide if basic extensibility is a core V1 requirement or deferred. If core, list high-level requirements; otherwise, note it as a future consideration. Store this decision and any related requirements internally. Hint: Consider if the initial architecture needs hooks for future plugins (e.g., for new languages, themes, or tools). A simple requirement might be: 'The core architecture should be modular to facilitate future addition of extensions'."
      },
      {
        "step 8": "Consolidate all the functional requirements elicited in the previous steps into a single, structured document. Create a new Markdown file named `functional_requirements.md` (place it in a `docs/` directory, creating the directory if it doesn't exist). Organize the requirements clearly, grouping them under headings corresponding to the core modules (e.g., 'Code Editor', 'Build System', 'Debugger', 'VCS Integration', 'Project Management', 'Extensibility'). Use bullet points or numbered lists for individual requirements. Ensure each requirement is stated clearly and concisely."
      }
    ],
    "Task 1.3: Specify Initial Target Programming Languages and Platforms": [
      {
        "step 1": "Research and identify the top 5-7 most popular programming languages currently in use. For each language, briefly note its primary domain (e.g., web development, data science, system programming) and the typical requirements for IDE support (e.g., availability of Language Server Protocol (LSP) implementations, debug adapter protocol (DAP) support, common build systems). Hint: Search the web for 'most popular programming languages [current year]', 'Language Server Protocol', 'Debug Adapter Protocol'."
      },
      {
        "step 2": "Define criteria for selecting the initial target programming language(s) for the MVP IDE. Consider factors such as language popularity, complexity of providing basic IDE features (syntax highlighting, basic linting/completion), availability of mature tooling (LSPs, debuggers, linters), and potential user base. Aim for criteria that prioritize a feasible starting point."
      },
      {
        "step 3": "Based on the research from Step 1 and the criteria from Step 2, propose and justify the selection of 1 or 2 initial programming languages for the IDE's MVP. Clearly explain why these languages are suitable starting points compared to others."
      },
      {
        "step 4": "Identify the major desktop operating systems (e.g., Windows, macOS, Linux). Research common approaches and frameworks for building cross-platform desktop applications (e.g., Electron, Tauri, Qt, Flutter Desktop, Compose Multiplatform). Briefly list pros and cons for each framework regarding performance, native look-and-feel, development language, and ecosystem maturity. Hint: Search web for 'desktop OS market share', 'cross-platform desktop frameworks comparison'."
      },
      {
        "step 5": "Define criteria for selecting the initial target platform(s) for the MVP IDE. Consider factors like developer familiarity (if applicable), target user base reach, ease of development and distribution using cross-platform tools, and performance implications."
      },
      {
        "step 6": "Based on the research from Step 4 and the criteria from Step 5, propose and justify the selection of the initial target platform(s) (e.g., Windows, macOS, Linux). Recommend whether to start with a single platform or aim for cross-platform support from the beginning, potentially suggesting a specific cross-platform framework identified in Step 4."
      },
      {
        "step 7": "Document the decisions made in this task. Create or update a designated project file (e.g., 'requirements.md' or 'architecture.md') with sections detailing the 'Initial Target Programming Languages' and 'Initial Target Platforms'. Include the selected languages/platforms and the rationale behind each choice as determined in Steps 3 and 6."
      }
    ],
    "Task 1.4: Define Non-Functional Requirements (Performance, Extensibility, Usability)": [
      {
        "step 1": "Create a new section or document named 'NonFunctionalRequirements.md' within the project's documentation directory. This document will consolidate all defined NFRs. Initialize it with headings for 'Performance', 'Extensibility', and 'Usability'."
      },
      {
        "step 2": "Define and document the 'Performance' NFRs. Consider aspects like startup time, UI responsiveness (e.g., typing latency, UI element updates), memory footprint, CPU usage during idle and active states, and performance when handling large files or projects. Propose initial, measurable targets for key metrics (e.g., 'Startup time < 3 seconds on target hardware', 'Typing latency < 50ms'). Hint: Research common performance benchmarks for existing IDEs like VS Code or IntelliJ IDEA for realistic targets. Add these definitions under the 'Performance' heading in 'NonFunctionalRequirements.md'."
      },
      {
        "step 3": "Define and document the 'Extensibility' NFRs. Outline the goals and principles for the IDE's plugin/extension system. Specify requirements for the extension API, including stability guarantees, documentation standards, ease of development for third-party developers, and the scope of customization allowed (e.g., adding language support, themes, UI components, custom commands). Hint: Analyze the extension models of popular IDEs (VS Code, IntelliJ, Eclipse, Sublime Text) to inform the requirements. Add these definitions under the 'Extensibility' heading in 'NonFunctionalRequirements.md'."
      },
      {
        "step 4": "Define and document the 'Usability' NFRs. Focus on aspects relevant to the target user groups identified in Task 1.2. Define goals for learnability (ease of getting started), efficiency (speed of performing common tasks), memorability, error prevention/recovery, user satisfaction, and accessibility (compliance with standards like WCAG). Hint: Consider applying usability heuristics (e.g., Nielsen's Heuristics) and specify how usability might be evaluated later (e.g., user testing). Add these definitions under the 'Usability' heading in 'NonFunctionalRequirements.md'."
      },
      {
        "step 5": "Review and refine the content in 'NonFunctionalRequirements.md'. Ensure each NFR is clear, concise, unambiguous, and ideally testable or verifiable. Check for consistency with the functional requirements and overall project goals defined previously. Format the document for readability."
      }
    ],
    "Task 1.5: Prioritize Features for Minimum Viable Product (MVP)": [
      {
        "step 1": "Access the comprehensive list of potential IDE features generated in Task 1.4. Assume this list is available in the project documentation, likely in a file named `potential_features.md` or similar. Load this list for review."
      },
      {
        "step 2": "Define and document the criteria for prioritizing features for the Minimum Viable Product (MVP). Focus on criteria such as: 1) **Core Functionality:** Is the feature absolutely essential for a basic code editing/running workflow? 2) **Technical Feasibility:** Can this feature be implemented relatively quickly with manageable complexity? 3) **User Value:** Does the feature provide significant value to the initial target user? 4) **Risk Mitigation:** Does including this feature help validate core assumptions early? Document these criteria in a new markdown file named `mvp_prioritization_criteria.md`."
      },
      {
        "step 3": "Evaluate each feature from the `potential_features.md` list against the criteria defined in `mvp_prioritization_criteria.md`. Suggestion: Create a temporary table or add annotations (e.g., tags like 'Must-have', 'Should-have', 'Could-have', or scores 1-5 for each criterion) to each feature to facilitate comparison. Store this evaluation, perhaps as an annotated version of the feature list or a separate evaluation file."
      },
      {
        "step 4": "Based on the evaluation performed in the previous step, identify the final set of features that will constitute the MVP. Select features marked as 'Must-have' or those scoring highest on 'Core Functionality' and 'User Value' while being feasible. Aim for the smallest possible feature set that delivers a usable, basic IDE experience."
      },
      {
        "step 5": "Create a new markdown file named `mvp_features.md`. List the selected MVP features clearly in this file. For each feature, include a concise description of its intended functionality within the MVP scope."
      },
      {
        "step 6": "In a separate section within `mvp_features.md` or in a dedicated file (e.g., `prioritization_rationale.md`), document the rationale for the selection. Explain *why* each chosen feature is critical for the MVP, referencing the criteria from `mvp_prioritization_criteria.md`. Also, briefly mention major features that were *explicitly deferred* and the reasoning behind their exclusion from the MVP (e.g., high complexity, lower initial priority)."
      }
    ],
    "Task 1.6: Conduct Competitive Analysis of Existing IDEs": [
      {
        "step 1": "Identify the primary competitors for our planned IDE. Based on the target user profile (from Task 1.1) and core feature requirements (from Task 1.2), list 3-5 existing IDEs that are most relevant. Consider both general-purpose and potentially niche IDEs. Hint: Use web searches like 'top IDEs for [target language/platform]', 'VS Code alternatives', 'lightweight IDEs', 'IDE market share'. Store this list in a temporary text file `competitors.txt`."
      },
      {
        "step 2": "Define the criteria for comparing the identified IDEs. Create a list of comparison points relevant to our project goals. Include at least: Core Features (code editing, debugging, build integration, version control), Language/Platform Support, Performance (perceived speed, resource usage - based on reviews/benchmarks), Usability & UI/UX, Extensibility (plugin architecture, marketplace size, API availability), Pricing & Licensing, Target Audience, Unique Selling Propositions (USPs), Major Weaknesses. Save these criteria to a file named `analysis_criteria.txt`."
      },
      {
        "step 3": "Initiate the research phase. Create a new document named `competitive_analysis_raw_data.md`. For the *first* competitor listed in `competitors.txt`, research information pertaining to each criterion defined in `analysis_criteria.txt`. Hint: Use targeted web searches for '[Competitor Name] features', '[Competitor Name] performance benchmarks', '[Competitor Name] pricing', '[Competitor Name] plugin system', '[Competitor Name] user reviews'. Structure the findings clearly under a heading for this competitor in the raw data file."
      },
      {
        "step 4": "Continue the research for the remaining competitors. For each subsequent competitor listed in `competitors.txt`, repeat the research process outlined in Step 3. Append the findings for each competitor under its own heading in `competitive_analysis_raw_data.md`. Ensure consistent information gathering across all competitors based on the defined criteria."
      },
      {
        "step 5": "Synthesize the research into a structured comparison table. Create a new file named `competitive_analysis_summary.md`. Using the information gathered in `competitive_analysis_raw_data.md`, create a Markdown table where rows represent the analysis criteria (from `analysis_criteria.txt`) and columns represent the competing IDEs. Populate the table concisely."
      },
      {
        "step 6": "Analyze the structured comparison table in `competitive_analysis_summary.md`. Identify recurring strengths and weaknesses among competitors. Pinpoint potential market gaps, underserved user needs, or areas where existing solutions fall short, especially concerning our project's specific goals and target audience (Tasks 1.1, 1.2, 1.4)."
      },
      {
        "step 7": "Document the analysis findings. Add a 'Summary & Strategic Implications' section to `competitive_analysis_summary.md`. In this section, summarize the key competitive landscape findings. Explicitly state potential opportunities (e.g., 'Opportunity: Lack of focus on [specific niche] by major players') and threats (e.g., 'Threat: High user satisfaction with [Competitor X]'s extensibility'). Suggest potential differentiation strategies for our IDE based on this analysis."
      },
      {
        "step 8": "Review and refine the `competitive_analysis_summary.md` document. Ensure the comparison table is accurate and easy to understand. Check that the 'Summary & Strategic Implications' section clearly links the competitive analysis back to our project's objectives and provides actionable insights for subsequent design and development phases. Refactor for clarity and conciseness."
      }
    ],
    "Task 1.7: Select Core Technology Stack (IDE Language, UI Framework, Key Libraries)": [
      {
        "step 1": "Analyze the previously defined functional and non-functional requirements (especially target platform(s), performance expectations, extensibility needs, and desired core features like language support) to identify key constraints and drivers for technology stack selection. Summarize these key drivers in a temporary file or internal note."
      },
      {
        "step 2": "Identify and list potential programming languages suitable for developing the core IDE application (e.g., C++, Rust, Java, C#, Python, Go, Swift, JavaScript/TypeScript). Hint: Consider factors like performance, memory safety, ecosystem maturity for desktop apps, cross-platform capabilities, and ease of integrating native features."
      },
      {
        "step 3": "Evaluate the candidate programming languages identified in Step 2. For each language, assess its pros and cons concerning the key drivers identified in Step 1. Create a comparative summary table. Hint: Search the web for comparisons like '[Language A] vs [Language B] for desktop application development', 'Performance benchmarks for IDE development languages'."
      },
      {
        "step 4": "Based on the language evaluation (Step 3), narrow down the choices to the top 2-3 contenders. For each of these languages, identify and list potential UI frameworks suitable for building a cross-platform (or target-platform specific, if defined) IDE interface (e.g., Qt, wxWidgets, GTK, Electron, Tauri, Flutter, Compose Multiplatform, .NET MAUI, JavaFX, Swing, egui, Fyne). Hint: Ensure compatibility between the language and the UI framework."
      },
      {
        "step 5": "Evaluate the candidate UI frameworks identified in Step 4. Assess pros and cons regarding cross-platform support, native look-and-feel, performance, widget/component availability, community support, licensing, and ease of use, particularly in relation to the chosen language(s). Update the comparative summary. Hint: Search for '[Framework A] vs [Framework B] comparison', 'Best UI framework for [Language] on desktop'."
      },
      {
        "step 6": "Identify essential library categories required for core IDE functionality based on requirements (e.g., text editor component, syntax highlighting engine, file system interaction/watching, Language Server Protocol (LSP) client, build system integration, version control integration). For the preferred Language + UI Framework combinations, research specific, well-maintained libraries in these categories. Hint: Search for 'text editor component for [Framework]', 'syntax highlighting library for [Language]', 'LSP client library [Language]', 'git library [Language]'."
      },
      {
        "step 7": "Based on the comprehensive evaluation (Steps 3, 5, 6) and alignment with project requirements (Step 1), propose a definitive technology stack: select the primary programming language, the main UI framework, and initial key libraries (especially for text editing and syntax highlighting). Provide a detailed justification for this selection, explaining the trade-offs considered."
      },
      {
        "step 8": "Document the selected technology stack (Language, UI Framework, Key Libraries with potential version constraints) and the justification in the project's designated architecture or technical documentation file (e.g., `ARCHITECTURE.md` or create `TECH_STACK.md`). Ensure the documentation clearly states the chosen components and the reasoning behind their selection."
      }
    ],
    "Task 1.8: Design High-Level System Architecture (e.g., Modular, Plugin-based)": [
      {
        "step 1": "Research common software architectural patterns suitable for Integrated Development Environments (IDEs). Focus on understanding the principles, advantages, and disadvantages of: Monolithic, Modular, Microservices, and Plugin-based architectures. Hint: Search the web for 'IDE architectural patterns', 'plugin architecture for desktop applications', 'modular software design'."
      },
      {
        "step 2": "Evaluate the researched architectural patterns (Monolithic, Modular, Microservices, Plugin-based) against the typical requirements of an IDE, such as extensibility (adding new languages, features, themes), maintainability, performance, complexity, and scalability. Document the pros and cons of each pattern specifically for the IDE context in a temporary file (`docs/architecture/pattern_evaluation.md`)."
      },
      {
        "step 3": "Based on the evaluation in the previous step and considering the high-level goal of building a flexible and extensible IDE, select and justify the most appropriate high-level system architecture. Hint: Plugin-based architectures built upon a modular core are often favored for IDEs due to their extensibility. Clearly state the chosen architecture and the reasons for its selection in the `docs/architecture/pattern_evaluation.md` file."
      },
      {
        "step 4": "Identify the core high-level components/modules required for the IDE based on the chosen architecture (e.g., if Plugin-based: Core Shell/Framework, Editor Component, Plugin Manager, Workspace/Project Manager, Language Support Interface (e.g., LSP Client), Debugger Interface, Build System Interface, Version Control Interface, UI Toolkit Abstraction). List these components and briefly describe the primary responsibility of each."
      },
      {
        "step 5": "Define the primary interaction mechanisms between the core components identified in the previous step. For a plugin-based architecture, specify how plugins will be discovered, loaded, and unloaded by the Plugin Manager, and outline the core APIs or Service Provider Interfaces (SPIs) the core framework will expose for plugins to extend functionality (e.g., adding menu items, editor features, new views). Consider using an event bus or message queue for decoupling communication where appropriate."
      },
      {
        "step 6": "Create a high-level architectural diagram illustrating the chosen architecture, the core components, and their main interactions. Hint: Use Mermaid syntax (```mermaid ... ```) for a text-based diagram that can be version-controlled. Alternatively, provide a clear textual description of the component relationships."
      },
      {
        "step 7": "Consolidate the selected architecture, component list and responsibilities, interaction mechanisms, and the architectural diagram into a single markdown document: `docs/architecture/high_level_design.md`. Ensure the justification for the chosen architecture is included. Remove the temporary `pattern_evaluation.md` file."
      }
    ],
    "Task 1.9: Identify Major System Components (Editor Core, UI Shell, Language Service Client, Debug Adapter Interface, etc.)": [
      {
        "step 1": "Analyze the previously defined high-level requirements and features for the IDE. Based on these and general knowledge of Integrated Development Environments (e.g., VS Code, IntelliJ, Eclipse), brainstorm a preliminary list of essential functional areas and subsystems. Consider user interactions like code editing, navigation, debugging, version control, building, etc. Document these initial ideas in a temporary file named `scratchpad/component_ideas.md`."
      },
      {
        "step 2": "Review the brainstormed list in `scratchpad/component_ideas.md`. Group related functionalities and refine them into distinct, high-level system components representing major architectural blocks. Focus on separation of concerns. For example, group text manipulation, rendering, and basic highlighting under an 'Editor Core'."
      },
      {
        "step 3": "Identify and define the 'UI Shell' (or 'Workbench') component. This component is responsible for the main application window, menus, toolbars, panel management (like file explorer, output, problems), view layout, and overall visual structure coordination. Describe its primary responsibilities in `docs/architecture/major_components.md`."
      },
      {
        "step 4": "Identify and define the 'Editor Core' component. This component handles the fundamental text editing capabilities: managing text buffers, text manipulation (insert, delete, copy, paste), rendering text (potentially including basic syntax highlighting and code folding), cursor management, and selection. Add its description to `docs/architecture/major_components.md`."
      },
      {
        "step 5": "Define the component responsible for providing rich language intelligence (completion, diagnostics, hover info, go-to-definition). Research the Language Server Protocol (LSP). Define a 'Language Service Client' component responsible for managing communication (spawning, interacting via JSON-RPC) with external language servers based on LSP. Document its role in decoupling language specifics from the IDE core in `docs/architecture/major_components.md`."
      },
      {
        "step 6": "Define the component responsible for debugging capabilities (breakpoints, stepping, variable inspection, call stack). Research the Debug Adapter Protocol (DAP). Define a 'Debug Adapter Interface' (or 'Debugger Client') component responsible for managing communication with debug adapters via DAP, providing a generic interface for the UI. Document its role in `docs/architecture/major_components.md`."
      },
      {
        "step 7": "Identify and define components for other essential IDE functionalities. Consider: 'Workspace Manager' (handling project/folder structure, settings), 'File System Access' (abstracting file operations), 'Version Control System (VCS) Integration' (e.g., Git interface), 'Search Service' (text search across files), 'Task Runner/Build System Interface' (executing build scripts, tasks), and 'Integrated Terminal'. Add these components with brief descriptions of their responsibilities to `docs/architecture/major_components.md`."
      },
      {
        "step 8": "Consider extensibility. Define an 'Extension Manager' (or 'Plugin System') component. This component should be responsible for discovering, loading, activating, managing the lifecycle, and potentially isolating extensions/plugins to allow third-party contributions. Describe its role in `docs/architecture/major_components.md`."
      },
      {
        "step 9": "Review the complete list of components documented in `docs/architecture/major_components.md`. Ensure each component has a clear, distinct responsibility and that the set covers all major required functionalities. Check for logical consistency and potential overlaps or gaps. Refine the names and descriptions for clarity."
      },
      {
        "step 10": "Optionally, create a simple diagram (e.g., using Mermaid syntax in `docs/architecture/component_overview.md`) illustrating these major components and their primary expected interactions at a high level. This provides a visual overview of the proposed architecture."
      }
    ],
    "Task 1.10: Define Interfaces and Interactions between Major Components": [
      {
        "step 1": "Retrieve the list of major architectural components defined in the previous steps (Task 1.9). List these components (e.g., UIManager, EditorManager, FileSystemManager, BuildManager, DebugManager, PluginManager, ProjectManager, LanguageServerClient) to ensure we have a common understanding for defining their interactions."
      },
      {
        "step 2": "Analyze the interactions between the `UIManager` and other components. Define the specific functions/methods the `UIManager` needs to call on other components (e.g., `EditorManager.open_file(path)`, `FileSystemManager.browse_directory()`, `BuildManager.trigger_build()`). Also, define the events or callbacks other components need to trigger in the `UIManager` (e.g., `UIManager.display_error(message)`, `UIManager.update_file_tree()`, `UIManager.show_build_output(output)`). Document these as method signatures, including parameters and expected return types or callback signatures."
      },
      {
        "step 3": "Define the interface for the `EditorManager`. Specify the methods it exposes (e.g., `open_editor(file_path)`, `get_content(editor_id)`, `set_content(editor_id, text)`, `get_cursor_position(editor_id)`, `apply_syntax_highlighting(editor_id, language)`) and the events it might emit (e.g., `content_changed`, `cursor_moved`). Detail its interactions with `FileSystemManager` (saving/loading), `LanguageServerClient` (sending document changes, receiving diagnostics/completions), and `UIManager` (displaying editor tabs, content)."
      },
      {
        "step 4": "Define the interface for the `FileSystemManager`. Specify methods for file/directory operations (e.g., `read_file(path)`, `write_file(path, content)`, `list_directory(path)`, `watch_directory(path, callback)`). Define how it communicates results (e.g., file content, directory listings) and events (e.g., file change notifications) back to callers like `UIManager`, `EditorManager`, and `ProjectManager`. Consider making I/O operations asynchronous to avoid blocking the main thread. Hint: Use `async/await` patterns or callbacks."
      },
      {
        "step 5": "Define the interface for the `ProjectManager`. Specify methods for managing project context (e.g., `load_project(root_path)`, `get_project_files()`, `get_project_settings(setting_key)`, `add_file_to_project(path)`). Detail its interactions with `FileSystemManager` (reading project files/structures), `UIManager` (displaying project structure), `BuildManager` (providing build configurations), and `LanguageServerClient` (providing project root/settings)."
      },
      {
        "step 6": "Define the interface for the `BuildManager`. Specify methods to control build processes (e.g., `configure_build(config)`, `start_build(target)`, `cancel_build()`, `run_target(target)`). Define how build progress, output, and errors are reported back, likely to the `UIManager`. Consider interactions with `ProjectManager` for build settings and `FileSystemManager` for accessing source/output files. Define data structures for build configurations and results."
      },
      {
        "step 7": "Define the interface for the `DebugManager`. Specify methods following the Debug Adapter Protocol (DAP) concepts if applicable (e.g., `launch_debugger(config)`, `attach_debugger(config)`, `set_breakpoints(file, lines)`, `step_over()`, `step_into()`, `continue_execution()`, `get_variables()`). Define how debug state changes, breakpoints hit, variable values, and output are communicated back, primarily to the `UIManager` and potentially `EditorManager` (for highlighting current line/breakpoints). Hint: Search the web for the 'Debug Adapter Protocol Specification'."
      },
      {
        "step 8": "Define the interface for the `LanguageServerClient`. Specify methods for managing the lifecycle and communication with Language Servers (e.g., `start_server(language, project_root)`, `stop_server(language)`, `send_notification(method, params)`, `send_request(method, params)`). Define how responses (e.g., completions, definitions) and notifications (e.g., diagnostics) are received and routed, primarily to the `EditorManager` and `UIManager`. Specify that communication should adhere to the Language Server Protocol (LSP). Hint: Search the web for the 'Language Server Protocol Specification'. Define key data structures for LSP messages (Requests, Responses, Notifications, Diagnostics, Completions etc.)."
      },
      {
        "step 9": "Define the interface for the `PluginManager`. Specify methods for plugin lifecycle management (e.g., `load_plugins()`, `enable_plugin(id)`, `disable_plugin(id)`). Crucially, define the extension points and APIs that the `PluginManager` exposes *to* plugins, allowing them to interact with core IDE components (e.g., `register_command(command_id, callback)`, `register_view(view_id, view_component)`, `get_editor_api()`, `get_project_api()`). Consider security and isolation implications. Document the structure of a plugin manifest file."
      },
      {
        "step 10": "Consolidate all defined interfaces into a central document (e.g., a Markdown file named `ARCHITECTURE_INTERFACES.md`). For each component interface, list its methods (with signatures: parameters, types, return types) and the events/callbacks it uses or emits. Define any common Data Transfer Objects (DTOs) used for passing complex data between components (e.g., `FileChangeNotification`, `BuildResult`, `DiagnosticInfo`). Hint: Consider using diagrams (e.g., UML component diagrams or sequence diagrams generated using tools like PlantUML or Mermaid.js) to visually represent the components and their primary interactions. Add these diagrams or links to them in the document."
      },
      {
        "step 11": "Review the consolidated interfaces for clarity, consistency, and completeness. Identify potential performance bottlenecks or complex dependencies. Explicitly mark interactions that should be asynchronous (e.g., file I/O, network requests, build processes, LSP communication) versus synchronous. Ensure error handling strategies are considered within the interface definitions (e.g., how errors are propagated or reported). Refine the documentation based on this review."
      }
    ],
    "Task 1.11: Design Preliminary Plugin/Extensibility Model": [
      {
        "step 1": "Research common plugin architectures used in modern IDEs and text editors. Focus on VS Code, IntelliJ/Eclipse, Sublime Text, and Atom. Identify their approaches to plugin discovery, loading, execution (sandboxing/processes), extension points, API design, and lifecycle management. Summarize findings in a Markdown document named `plugin_architecture_research.md`."
      },
      {
        "step 2": "Based on the research and the previously defined core IDE features, define the fundamental concepts for our IDE's plugin model. Define terms like 'Plugin', 'Extension Point', 'Plugin Manifest', 'Plugin API', and 'Plugin Host'. Document these definitions clearly in a new section within the main architectural design document (`architecture.md`)."
      },
      {
        "step 3": "Propose 1-2 simple mechanisms for plugin discovery for the initial version. Consider options like scanning a predefined directory (`plugins/`) or reading a configuration file listing enabled plugins. Detail the chosen mechanism(s), including potential file structures or formats, in `architecture.md`. Hint: Prioritize simplicity for the preliminary design."
      },
      {
        "step 4": "Define the basic structure of a plugin package. Specify the necessary files and their purpose, including a `plugin manifest` file (e.g., `plugin.json` or `plugin.yaml`). Define the essential fields for this manifest (e.g., `name`, `version`, `main_entry_point`, `activation_events`, `contributes`). Document this structure and manifest format in `architecture.md`."
      },
      {
        "step 5": "Define a preliminary core Plugin API interface or base class. This should include essential methods for the IDE to interact with the plugin, such as `activate()` and `deactivate()`. Specify the expected function signatures and responsibilities. Use the primary language chosen for the IDE core (e.g., Python, TypeScript). Add this definition to `architecture.md`. Hint: Keep this initial API minimal."
      },
      {
        "step 6": "Identify and list 3-5 initial, high-priority 'Extension Points' based on the core IDE features defined earlier (e.g., `commands`, `menuItems`, `editor.languageProvider`, `ui.viewContainers`). For each extension point, briefly describe its purpose and how a plugin might contribute to it. Document these in `architecture.md`."
      },
      {
        "step 7": "Design the mechanism by which plugins register their contributions to specific extension points. Consider whether this is primarily declarative (via the manifest file's `contributes` section) or programmatic (via API calls during activation), or a hybrid approach. Document the proposed registration process in `architecture.md`."
      },
      {
        "step 8": "Outline the basic plugin lifecycle, including the sequence of events: Discovery -> Loading -> Activation -> Deactivation -> Unloading. Describe briefly what triggers each stage and the role of the `activate()` and `deactivate()` methods. Add this outline to `architecture.md`. Hint: Consider deferring activation until needed ('lazy loading') based on `activation_events` defined in the manifest."
      },
      {
        "step 9": "Briefly discuss potential approaches for plugin isolation and security (e.g., running plugins in separate processes, using web workers, permission models) as considerations for future development, but without deep design work at this stage. Add this discussion as a 'Future Considerations' subsection in the plugin model section of `architecture.md`."
      },
      {
        "step 10": "Review and consolidate all the design decisions made in the previous steps into a cohesive 'Plugin and Extensibility Model' section within the main `architecture.md` document. Ensure clarity, consistency, and that it aligns with the overall architectural goals."
      }
    ],
    "Task 1.12: Create Initial UI/UX Wireframes for Key Workflows": [
      {
        "step 1": "Analyze the previously defined core features and requirements (Tasks 1.1-1.11) to identify the essential user workflows that require UI/UX wireframing. List these workflows (e.g., Project Creation/Opening, Code Editing, File Navigation, Build/Run Process, Debugging Session, Search/Replace). Store this list temporarily for the subsequent steps."
      },
      {
        "step 2": "Define the format for the wireframes. We will use Markdown (`*.md`) files. Represent UI elements using textual descriptions, ASCII art, or Markdown tables/code blocks to outline the layout and components. Create a directory `docs/ui/` if it doesn't exist."
      },
      {
        "step 3": "Create the first wireframe for the 'Project/File Creation and Opening' workflow. Detail the initial state of the IDE (e.g., welcome screen or empty state), options for creating/opening files/projects, and how recent items might be displayed. Use placeholders like `[File Menu]`, `[Open Project Button]`, `[Recent Projects List]`. Save this section under an appropriate heading in a new file named `docs/ui/wireframes.md`."
      },
      {
        "step 4": "Append the wireframe for the 'Main Code Editing' workflow to `docs/ui/wireframes.md`. Illustrate the primary editor layout, including placeholders for `[Menu Bar]`, `[File Tree/Explorer Panel]`, `[Editor Pane with Tabs]`, `[Code Area with Line Numbers]`, `[Minimap (Optional)]`, and `[Status Bar]`."
      },
      {
        "step 5": "Append the wireframe for the 'Build/Run/Debug' workflow to `docs/ui/wireframes.md`. Show the necessary controls like `[Run Button]`, `[Debug Button]`, `[Stop Button]`. Include representations of panels for `[Build Output/Console]` and `[Debugger Information (Variables, Watchlist, Call Stack)]`."
      },
      {
        "step 6": "Append the wireframe for the 'Search/Replace' workflow to `docs/ui/wireframes.md`. Design the interface for finding and replacing text within a file or project. Include elements like `[Search Input Field]`, `[Replace Input Field]`, `[Find Next/Previous Buttons]`, `[Replace/Replace All Buttons]`, and options like `[Case Sensitive Checkbox]`, `[Regex Checkbox]`, `[Scope Selector (Current File, Project)]`. Decide if this is a modal dialog, a sidebar panel, or integrated into the editor."
      },
      {
        "step 7": "If version control integration (e.g., Git) was identified as a key requirement earlier, append a basic wireframe for its core interactions to `docs/ui/wireframes.md`. Include placeholders for `[Changed Files List]`, `[Diff View Area]`, `[Commit Message Input]`, `[Commit Button]`, `[Push/Pull Buttons]`, and `[Branch Indicator]`."
      },
      {
        "step 8": "Review the consolidated `docs/ui/wireframes.md` file. Ensure each identified key workflow from Step 1 has a corresponding wireframe section. Check for consistency in presentation style and terminology. Verify that the wireframes visually represent the essential components and interactions defined in the earlier requirements gathering phase."
      }
    ],
    "Task 1.13: Define Project Configuration and User Settings Data Structures": [
      {
        "step 1": "Analyze and list the common categories and specific settings required for both project-specific configurations and global user preferences within a typical Integrated Development Environment (IDE). Consider aspects like build systems, run/debug configurations, language-specific tooling (linters, formatters), version control integration, editor appearance (theme, font), editor behavior (indentation, auto-save), keybindings, terminal settings, and plugin management. Document these potential settings in a structured list or markdown format."
      },
      {
        "step 2": "Evaluate common configuration file formats (e.g., JSON, YAML, TOML, INI) for storing both project and user settings. Compare them based on criteria such as human readability, ease of parsing by machines, support for comments, schema validation capabilities, and existing library support in potential implementation languages (like Python). Recommend a format for both project configuration and user settings, providing justification for your choice. For subsequent steps, assume JSON unless you strongly justify another format."
      },
      {
        "step 3": "Define a preliminary hierarchical structure (schema) for the **project configuration** file using the chosen format (e.g., conceptual JSON structure). Outline the main top-level keys (e.g., `project_name`, `version`, `build`, `run`, `dependencies`, `language_specific`, `vcs`, `plugins`). Briefly describe the purpose of each top-level section."
      },
      {
        "step 4": "Elaborate on the project configuration schema defined in the previous step. Detail the expected fields, nested structures, and data types (string, number, boolean, array, object) within each major section. Provide descriptive comments or annotations for each field. Include examples for common use cases, such as defining a build command, specifying source directories, or configuring a linter for a specific language. Hint: Ensure the structure allows for extensibility, particularly for adding language-specific or plugin-specific settings without modifying the core schema drastically."
      },
      {
        "step 5": "Define a preliminary hierarchical structure (schema) for the **user settings** file using the chosen format (e.g., conceptual JSON structure). Outline the main top-level keys (e.g., `editor`, `ui`, `keybindings`, `terminal`, `updates`, `plugins`). Briefly describe the purpose of each top-level section."
      },
      {
        "step 6": "Elaborate on the user settings schema defined in the previous step. Detail the expected fields, nested structures, and data types within each major section (e.g., `editor`: {`font_family`, `font_size`, `theme`, `tab_size`, `auto_save`}, `ui`: {`sidebar_visible`, `panel_layout`}, `keybindings`: {`command`: `shortcut` mapping structure}). Specify potential default values for key settings. Hint: Think about how settings might be layered or overridden (e.g., default vs. user-defined)."
      },
      {
        "step 7": "Consolidate the detailed schemas for both project configuration and user settings into a single, well-formatted documentation file (e.g., using Markdown). For each configuration type, include the overall structure, field names, data types, descriptions, whether a field is mandatory or optional, and example snippets illustrating usage. Ensure clarity and readability."
      },
      {
        "step 8": "Outline potential strategies and considerations for loading, validating, merging (e.g., default, user, project settings), and persisting these configuration structures. Specify conventional file locations (e.g., `.ide_project/config.json` within the project directory, `~/.config/YourIDE/settings.json` or platform-specific user config directories). Mention potential libraries or techniques for schema validation (like JSON Schema). Note: This step focuses on the design considerations, not the implementation."
      }
    ],
    "Task 1.14: Document Chosen Architecture, Technology Stack, and Key Design Decisions": [
      {
        "step 1": "Create a new Markdown file named `ARCHITECTURE_DESIGN.md` in the project's `docs` directory (create the directory if it doesn't exist). This file will serve as the central document for the chosen architecture, technology stack, and key design decisions."
      },
      {
        "step 2": "Define the main sections of the `ARCHITECTURE_DESIGN.md` document using Markdown headings. Include sections for: '1. Introduction', '2. Architectural Overview', '3. Technology Stack', '4. Key Design Decisions', and '5. Future Considerations'."
      },
      {
        "step 3": "In the '1. Introduction' section, briefly describe the purpose of the document and summarize the high-level goals for the IDE, linking them to the architectural and technological choices documented herein. Reference the refined requirements from previous tasks (e.g., Task 1.3)."
      },
      {
        "step 4": "Populate the '2. Architectural Overview' section. Describe the chosen architectural pattern (e.g., Plugin-based, Microkernel, Layered). Detail the main components (e.g., Core Editor, Plugin Manager, File System Abstraction, UI Layer, Language Server Protocol Client) and their responsibilities and interactions. Justify why this architecture was selected over alternatives considered in previous steps (e.g., Task 1.10), referencing specific requirements like extensibility, maintainability, or performance."
      },
      {
        "step 5": "Consider adding a high-level architectural diagram to the '2. Architectural Overview' section. Hint: Use Mermaid syntax directly within the Markdown for a simple diagram, or create a separate image file (e.g., using draw.io or similar tools) and embed it."
      },
      {
        "step 6": "Fill in the '3. Technology Stack' section. List the specific technologies chosen for each part of the IDE (e.g., Frontend Framework: React/Vue/Svelte, Desktop Shell: Electron/Tauri, Core Editor Logic: Monaco Editor/CodeMirror, Backend/Core Services: Node.js/Rust/Python, Language Integration: LSP, UI Toolkit: Custom/MUI/TailwindCSS, Build System: Webpack/Vite/esbuild). For each technology, provide a brief justification based on the evaluation performed in previous tasks (e.g., Task 1.11), considering factors like performance, ecosystem, team familiarity, licensing, and cross-platform support."
      },
      {
        "step 7": "Detail the '4. Key Design Decisions' section. Document significant choices made that impact the IDE's structure, functionality, or development process. Examples include: Cross-platform strategy, Extensibility API design, State management approach, Handling of background tasks, Error reporting mechanism, Data persistence strategy, Initial set of core plugins/features. For each decision, explain the rationale and trade-offs considered (referencing discussions from e.g., Task 1.12, 1.13)."
      },
      {
        "step 8": "Draft the '5. Future Considerations' section. Briefly mention potential future evolutions of the architecture or technology stack, known limitations of the current design, or areas identified for further investigation or refactoring later in the project."
      },
      {
        "step 9": "Review the entire `ARCHITECTURE_DESIGN.md` document for clarity, consistency, accuracy, and completeness. Ensure that the documentation accurately reflects the decisions made in the preceding requirement and design tasks. Check for grammatical errors and formatting issues."
      },
      {
        "step 10": "Commit the `ARCHITECTURE_DESIGN.md` file and any associated diagram image files to the project's version control system with a descriptive message (e.g., 'docs: Document initial architecture and technology stack')."
      }
    ],
    "Task 1.15: Create High-Level Roadmap for Subsequent Development Phases": [
      {
        "step 1": "Access and synthesize the key decisions documented from previous tasks in Phase 1 (Requirements & Architecture). Specifically, recall the core features (including MVP scope), target user profile, primary language(s) to be supported initially, chosen architectural patterns (e.g., MVC, Microkernel), and the selected technology stack (UI framework, backend language, etc.). Log these key inputs as they will directly inform the roadmap."
      },
      {
        "step 2": "Based on the synthesized project context, propose a list of 4-6 distinct, high-level development phases for building the IDE. Aim for logical groupings of work. Hint: Consider common IDE development stages like 'Core Editor Implementation', 'Language Support Integration (Syntax Highlighting, Basic IntelliSense)', 'Build System Integration', 'Debugging Capabilities', 'UI/UX Refinement', 'Plugin Architecture Development', 'Testing & QA', 'Release Preparation'."
      },
      {
        "step 3": "For each development phase identified in the previous step, define 2-4 key milestones or major deliverables. These should represent significant, measurable progress points within each phase. For example, within 'Core Editor Implementation', milestones might be 'Basic text rendering and editing', 'File open/save functionality', 'Initial syntax highlighting engine'."
      },
      {
        "step 4": "Organize the proposed phases and their respective milestones into a logical sequence based on dependencies. Determine the most sensible order for tackling these phases (e.g., core functionality usually precedes advanced features or UI polish). Hint: Justify the sequence briefly, noting dependencies like needing a core editor before adding language-specific features."
      },
      {
        "step 5": "Create a new markdown file named `ROADMAP.md` in the project's root directory (or a designated `/docs` folder if it exists). Structure the document clearly: use top-level headings (`##`) for each phase name and bullet points (`*` or `-`) for the milestones within that phase. Add a brief introductory sentence summarizing the roadmap's purpose and potentially include the sequence justification."
      },
      {
        "step 6": "Review the contents of `ROADMAP.md`. Verify that the phases and milestones are presented clearly, the sequence is logical, and the overall roadmap aligns with the project's scope, architecture, and goals defined earlier. Ensure the level of detail is high-level, focusing on *what* will be built in each phase, not *how*. Refine the wording and structure for clarity and conciseness."
      }
    ]
  },
  "Phase 2: Core Editor & UI Framework Implementation": {
    "Task 2.1: Select and initialize UI framework (e.g., Electron, Tauri, Web).": [
      {
        "step 1": "Analyze the primary trade-offs between Electron, Tauri, and a purely Web-based approach (e.g., using Vite + React/Vue/Svelte hosted on a local server) for building the IDE's user interface. Focus on: performance overhead, final bundle size, security implications (sandboxing, native access), cross-platform compatibility (Windows, macOS, Linux), ease of native feature integration (file system access, menus, dialogs), and developer experience/tooling. Document your findings in a markdown file named `docs/ui_framework_analysis.md` in the project root."
      },
      {
        "step 2": "Based on the analysis in `docs/ui_framework_analysis.md`, recommend one specific UI framework/approach. Justify your recommendation by highlighting the key factors that make it suitable for an IDE project, considering the balance between performance, features, and development complexity. Add this recommendation and justification to the end of `docs/ui_framework_analysis.md`. For this project, we will proceed assuming **Tauri** is selected due to its balance of performance, security, and ability to leverage web technologies. If your analysis strongly contradicts this, please state your reasoning clearly."
      },
      {
        "step 3": "Initialize a new Tauri project within the current repository structure. Use the command `npm create tauri-app@latest` (or `cargo generate --git https://github.com/tauri-apps/tauri-starter` if preferred). Choose **React** with **TypeScript** as the UI template/recipe when prompted. Name the application `ide-core-ui`. Place the generated project files in a subdirectory named `ide-core-ui`."
      },
      {
        "step 4": "Navigate into the newly created `ide-core-ui` directory. Install all necessary frontend and backend (Rust/Tauri) dependencies using the appropriate package managers (e.g., `npm install` and potentially `cargo check` or an initial `cargo build` within `src-tauri` to fetch Rust dependencies)."
      },
      {
        "step 5": "Modify the default boilerplate React component (likely located at `ide-core-ui/src/App.tsx`) to display a simple, static heading like `<h1>IDE Core Shell</h1>`. Remove any default interactive elements (like counters or buttons) and placeholder logos or styling provided by the template."
      },
      {
        "step 6": "Run the Tauri development environment using the command `npm run tauri dev` (or `cargo tauri dev`) from within the `ide-core-ui` directory. Verify that the application compiles and a window appears displaying only the `IDE Core Shell` heading. Check the terminal output for any build or runtime errors."
      },
      {
        "step 7": "Commit the initialized Tauri project structure and the basic UI modification to the version control system. Ensure the `docs/ui_framework_analysis.md` file is also included. Use a descriptive commit message like 'feat: Initialize Tauri with React+TS for core UI'."
      }
    ],
    "Task 2.2: Implement main window structure and layout (menu bar, editor pane, status bar, sidebars).": [
      {
        "step 1": "Create a new Python file named `main_window.py`. Define a class `MainWindow` within this file that inherits from `QMainWindow` (assuming PyQt6/PySide6 was chosen). Include a basic `__init__` method."
      },
      {
        "step 2": "In your main application entry point file (e.g., `main.py`), import `QApplication` and your `MainWindow` class. Instantiate `QApplication`, create an instance of `MainWindow`, set a default window title (e.g., \"CodeForge IDE\"), set a reasonable initial size (e.g., 1200x800 pixels), show the window, and start the application event loop (`app.exec()`)."
      },
      {
        "step 3": "Inside the `MainWindow` class (`main_window.py`), implement the menu bar. Use `self.menuBar()` to get the menu bar instance. Add top-level menus like 'File', 'Edit', 'View', 'Run', 'Help'. For now, these menus don't need functional actions, just placeholder text. Hint: Use `addMenu()`."
      },
      {
        "step 4": "Within the `MainWindow` class, implement the status bar. Use `self.statusBar()` to get the status bar instance. Display a default message like 'Ready' using `showMessage()`. Hint: You might call this setup within the `__init__` method or a separate UI setup method."
      },
      {
        "step 5": "Create a central widget for the main editor area. Import `QTextEdit`. Instantiate a `QTextEdit` object and set it as the central widget of the `MainWindow` using `self.setCentralWidget()`. Hint: This `QTextEdit` will serve as the basic code editor pane for now."
      },
      {
        "step 6": "Implement the left sidebar using `QDockWidget`. Import `QDockWidget` and a placeholder widget like `QListWidget` or `QLabel`. Create a `QDockWidget` instance, set its window title (e.g., 'Explorer'), set the placeholder widget as its widget using `setWidget()`. Add the dock widget to the main window's left dock area using `self.addDockWidget(Qt.DockWidgetArea.LeftDockWidgetArea, dock_widget)`. Ensure `Qt` is imported (e.g., `from PyQt6.QtCore import Qt`)."
      },
      {
        "step 7": "Implement a right sidebar similarly using `QDockWidget`. Create another `QDockWidget`, set its title (e.g., 'Outline / Properties'), add a different placeholder widget (e.g., a `QLabel` with text 'Outline Placeholder'), and add it to the main window's right dock area using `self.addDockWidget(Qt.DockWidgetArea.RightDockWidgetArea, dock_widget)`."
      },
      {
        "step 8": "Refactor the UI setup code within `MainWindow`. Create a private helper method (e.g., `_setup_ui`) and move the creation and configuration of the menu bar, status bar, central widget, and dock widgets into this method. Call `_setup_ui()` from the `__init__` method."
      },
      {
        "step 9": "Run the application (`main.py`). Verify that the main window appears with the title, menu bar, a central text editing area, a status bar displaying 'Ready', and dockable sidebars on the left ('Explorer') and right ('Outline / Properties') containing their respective placeholder widgets."
      }
    ],
    "Task 2.3: Integrate or build the core text editor component.": [
      {
        "step 1": "Analyze the UI framework chosen in Task 2.1 (e.g., Electron, PySide/PyQt, Tkinter). Research and select a suitable embeddable code editor library compatible with this framework. Document your choice and the reasons for it in the project's documentation. *Hint: Popular choices include Monaco Editor (Web/Electron), CodeMirror (Web/Electron), Ace Editor (Web/Electron), QScintilla (Qt), or enhancing a native text widget. Prioritize libraries with good documentation, community support, and features like syntax highlighting.*"
      },
      {
        "step 2": "Install the chosen editor library and any necessary bindings or dependencies using the project's designated package manager (e.g., npm, pip). *Hint: Carefully follow the installation instructions provided in the library's documentation. Some libraries might require additional build tools or system dependencies.*"
      },
      {
        "step 3": "Create a new file/module (e.g., `editor_component.js`, `editor_widget.py`, `EditorView.java`) and define a class or component that will encapsulate the chosen editor library, acting as a wrapper within your UI framework. *Hint: This wrapper will isolate the editor's specific API from the rest of your application.*"
      },
      {
        "step 4": "Within the new editor component's initialization logic (e.g., constructor, `__init__`, `componentDidMount`, `initialize`), instantiate the chosen editor library and embed its view/widget into the component's structure. *Hint: Refer to the editor library's documentation for specific embedding examples within your chosen UI framework. Ensure proper handling of the editor's lifecycle.*"
      },
      {
        "step 5": "Configure the editor instance with essential basic settings. Enable line numbers, set a default font, and select a default theme (e.g., a light or dark theme provided by the library). *Hint: Consult the editor's API documentation for configuration options. Keep the initial configuration minimal.*"
      },
      {
        "step 6": "Modify the main application window/layout component (developed in Task 2.2) to incorporate an instance of your new editor component. Ensure the editor component occupies the primary content area and is configured to resize correctly when the main window is resized. *Hint: Utilize the layout managers provided by your UI framework (e.g., CSS Flexbox/Grid, Qt Layouts, Tkinter Pack/Grid).* "
      },
      {
        "step 7": "Load initial placeholder text into the editor upon application startup (e.g., `// Welcome to Your IDE! Start typing here...`). This helps visually confirm the editor is rendering and functional. *Hint: Use the editor's API to set the initial content during or shortly after initialization.*"
      },
      {
        "step 8": "Implement basic text access methods within your editor wrapper component. Create a `getText()` method to retrieve the entire content of the editor and a `setText(content: string)` method to replace the entire content. *Hint: These methods will interface with the underlying editor library's API and serve as the primary interface for file operations later.*"
      },
      {
        "step 9": "Run the application. Verify that: (1) The editor component displays within the main window. (2) The placeholder text is visible. (3) Basic text editing (typing, deleting) works. (4) Line numbers are visible. (5) The editor component resizes correctly along with the main window."
      }
    ],
    "Task 2.4: Implement basic text editing features (typing, selection, deletion).": [
      {
        "step 1": "Locate the primary text editing widget/component within the project's UI code (e.g., the `QTextEdit` in PyQt, `Text` widget in Tkinter, or the equivalent if using a web framework). Ensure you have a reference to this widget instance."
      },
      {
        "step 2": "Implement basic typing functionality. Capture keyboard events for printable characters. When a character key is pressed, insert the corresponding character at the current cursor position within the text widget. Hint: Look for methods like `insertPlainText`, `insert`, or manipulating the widget's text content and cursor position directly. Consider framework-specific event listeners (e.g., `keyPressEvent`, `<KeyPress>`)."
      },
      {
        "step 3": "Implement cursor movement using arrow keys. Handle `KeyUp`, `KeyDown`, `KeyLeft`, and `KeyRight` events. Update the cursor position within the text widget accordingly. Hint: Use the widget's API to get and set the cursor position (e.g., `moveCursor`, `setTextCursor`). Ensure movement respects text boundaries (start/end of document, line breaks)."
      },
      {
        "step 4": "Implement the Backspace key functionality. Handle the `Key_Backspace` event. If text is selected, delete the selection. If no text is selected, delete the character immediately preceding the cursor. Handle edge cases like being at the beginning of the text or the beginning of a line. Hint: Use cursor manipulation methods like `deletePreviousChar` or manually adjust text content and cursor position."
      },
      {
        "step 5": "Implement the Delete key functionality. Handle the `Key_Delete` event. If text is selected, delete the selection. If no text is selected, delete the character immediately following the cursor. Handle edge cases like being at the end of the text or the end of a line. Hint: Similar to Backspace, use cursor methods or manual text manipulation."
      },
      {
        "step 6": "Implement basic text selection using Shift + Arrow Keys. Modify the arrow key event handlers (from Step 3) to check if the Shift modifier key is pressed. If Shift is pressed, instead of just moving the cursor, extend or create a text selection between the original cursor position (anchor) and the new position. Hint: Frameworks often have methods to set/manage selection start and end points (e.g., `setTextCursor` with `MoveMode.KeepAnchor` in PyQt, tag manipulation in Tkinter)."
      },
      {
        "step 7": "Refine deletion logic to handle selections. Ensure that both the Backspace (Step 4) and Delete (Step 5) handlers correctly delete the entire selected text range when a selection exists, before attempting single-character deletion."
      },
      {
        "step 8": "Implement 'typing replaces selection' functionality. Modify the character key event handler (from Step 2). Before inserting the typed character, check if any text is currently selected. If so, delete the selected text first, then insert the new character at the resulting cursor position."
      },
      {
        "step 9": "Review and refactor the event handling logic for Steps 2-8. Ensure clarity, efficiency, and proper handling of edge cases (empty document, start/end of lines, start/end of document). Add comments explaining the logic. Perform manual testing: type text, move the cursor with arrows, use Backspace/Delete, select text with Shift+Arrows, delete selections, and type over selections."
      }
    ],
    "Task 2.5: Implement file opening logic and UI integration (e.g., File > Open menu).": [
      {
        "step 1": "Locate the UI code responsible for the main application menu bar (likely defined in a previous step). Add a new menu item labeled 'Open...' under the 'File' menu. Connect this menu item's trigger/action signal to a new, placeholder callback function (e.g., `on_open_file_requested`)."
      },
      {
        "step 2": "Implement the `on_open_file_requested` callback function. Within this function, use the chosen UI framework's standard file dialog library to display a native 'Open File' dialog box, allowing the user to select a file."
      },
      {
        "step 3": "Modify the `on_open_file_requested` function to retrieve the file path selected by the user from the file dialog. Ensure the function handles the case where the user cancels the dialog (e.g., by returning an empty string or None) without raising an error."
      },
      {
        "step 4": "Create a dedicated function, potentially in a separate utility module (e.g., `file_operations.py`), named `read_file(filepath: str) -> tuple[str | None, str | None]`. This function should: \n   a. Take a file path as input.\n   b. Attempt to open and read the entire content of the file.\n   c. Return a tuple containing `(content, None)` on success, or `(None, error_message)` on failure.\n   *Hint:* Use a `try...except` block to handle potential `FileNotFoundError`, `PermissionError`, `IOError`, and `UnicodeDecodeError`. Specify UTF-8 encoding (`encoding='utf-8'`) when opening the file, as it's a common standard."
      },
      {
        "step 5": "Integrate the file reading logic into the `on_open_file_requested` function. If a valid file path is obtained from the dialog, call the `read_file` function with this path."
      },
      {
        "step 6": "In `on_open_file_requested`, check the result from `read_file`. If the content was read successfully (i.e., `content` is not None), update the core editor widget to display this new content. Ensure any previous content in the editor is cleared first."
      },
      {
        "step 7": "Enhance `on_open_file_requested` for error handling. If `read_file` returns an error message (i.e., `error_message` is not None), use the UI framework's message box or notification system to display the error message clearly to the user."
      },
      {
        "step 8": "After successfully loading the file content into the editor, update the main application window's title to reflect the name of the opened file (e.g., 'MyIDE - [filename]'). Store the full path of the currently opened file in an instance variable (e.g., `self.current_file_path`) within your main application or editor state class for future reference (like saving)."
      },
      {
        "step 9": "Review the code added in the previous steps (`on_open_file_requested`, `read_file`, and menu integration). Refactor for clarity, ensuring good separation between UI interaction (dialogs, updates) and file I/O logic. Add comments and docstrings to explain the implementation."
      }
    ],
    "Task 2.6: Implement file saving logic and UI integration (e.g., File > Save/Save As menu).": [
      {
        "step 1": "Ensure the application state includes variables to track the `current_file_path` (string, initially None or empty) and `is_modified` (boolean, initially False). If these don't exist in your main application class or state management module, add them."
      },
      {
        "step 2": "Implement a core function `save_content_to_file(file_path: str, content: str)` that takes a file path and string content, and writes the content to the specified file. Include basic error handling (e.g., using `try...except IOError`) and return `True` on success, `False` on failure. Hint: Use standard file I/O operations."
      },
      {
        "step 3": "Implement a function `trigger_save_as()` that uses the UI framework's standard 'Save As' file dialog to prompt the user for a file path. Hint: Search for your UI framework's specific file dialog implementation (e.g., `tkinter.filedialog.asksaveasfilename`, `PyQt5.QtWidgets.QFileDialog.getSaveFileName`)."
      },
      {
        "step 4": "Implement the main `handle_save_as()` logic. This function should: \n1. Call `trigger_save_as()` to get a file path from the user.\n2. If a valid path is provided:\n   a. Retrieve the current content from the text editor widget.\n   b. Call `save_content_to_file()` with the chosen path and content.\n   c. If saving is successful, update the application's `current_file_path` state to the new path and set `is_modified` to `False`.\n   d. Update the window title to reflect the new file path.\n   e. Handle potential errors during saving (e.g., display an error message pop-up)."
      },
      {
        "step 5": "Implement the main `handle_save()` logic. This function should:\n1. Check the `current_file_path` state.\n2. If `current_file_path` is valid (not None or empty):\n   a. Retrieve the current content from the text editor widget.\n   b. Call `save_content_to_file()` with the `current_file_path` and content.\n   c. If saving is successful, set `is_modified` to `False`.\n   d. Handle potential errors during saving.\n3. If `current_file_path` is *not* valid, call `handle_save_as()` instead."
      },
      {
        "step 6": "Modify the text editor component's event handling. Whenever the content of the editor is changed by the user, set the application's `is_modified` state flag to `True`. Hint: Look for events like 'text changed', 'key release', etc., depending on your editor widget."
      },
      {
        "step 7": "Integrate the save actions into the UI menu bar. Add 'Save' and 'Save As...' items under the 'File' menu (create the 'File' menu if it doesn't exist). Hint: Use your UI framework's menu creation tools."
      },
      {
        "step 8": "Connect the 'Save' menu item's action/command signal to the `handle_save()` function."
      },
      {
        "step 9": "Connect the 'Save As...' menu item's action/command signal to the `handle_save_as()` function."
      },
      {
        "step 10": "Implement logic to dynamically enable/disable the 'Save' menu item. It should be enabled only when the `is_modified` flag is `True`. Hint: You might need to update the menu item's state whenever `is_modified` changes, or check the flag just before showing the menu."
      },
      {
        "step 11": "(Optional) Refactor the file saving functions (`save_content_to_file`, `handle_save`, `handle_save_as`) for clarity and separation of concerns. Consider moving file I/O logic to a dedicated module if appropriate."
      },
      {
        "step 12": "(Optional) Write unit tests for the `save_content_to_file` function. You may need to mock file system interactions (e.g., using `unittest.mock` or `pytest-mock`) to test success and failure scenarios without actual disk I/O."
      }
    ],
    "Task 2.7: Integrate basic undo/redo functionality in the editor.": [
      {
        "step 1": "Analyze the current code editor widget implementation. Identify the specific widget class being used (e.g., `tkinter.Text`, `QTextEdit`, a custom widget). Search the documentation for this widget to determine if it provides built-in undo/redo capabilities. Report your findings on whether built-in support exists and if it appears sufficient for basic undo/redo operations (tracking text changes, providing undo/redo actions)."
      },
      {
        "step 2": "Based on Step 1: If sufficient built-in undo/redo support exists and you choose to use it, proceed directly to Step 7. Otherwise, design and implement a Python class named `UndoRedoManager`. This class should manage two lists or `collections.deque` objects: `undo_stack` and `redo_stack`. Implement the following methods:\n    - `__init__(self)`: Initializes empty undo and redo stacks.\n    - `add_change(self, current_state)`: Appends the `current_state` (representing the editor content *before* a change) to `undo_stack` and clears the `redo_stack`.\n    - `undo(self, current_state_before_undo)`: Pops the last state from `undo_stack`, pushes `current_state_before_undo` onto `redo_stack`, and returns the popped state (which is the state to restore).\n    - `redo(self, current_state_before_redo)`: Pops the last state from `redo_stack`, pushes `current_state_before_redo` onto `undo_stack`, and returns the popped state (which is the state to restore).\n    - `can_undo(self)`: Returns `True` if `undo_stack` is not empty, `False` otherwise.\n    - `can_redo(self)`: Returns `True` if `redo_stack` is not empty, `False` otherwise.\n*Hint:* For `current_state`, initially store the complete text content of the editor as a string."
      },
      {
        "step 3": "Instantiate the `UndoRedoManager` within your main application or editor class, making it accessible to the editor widget's logic. Locate the code segments within the editor component where text modifications occur (e.g., handling key presses, pasting text, deleting text). Modify these segments so that *before* the text content is actually changed, the current text content of the editor is retrieved and passed to the `undo_redo_manager.add_change()` method. *Hint:* Ensure you capture the state *before* the modification is applied by the event handler."
      },
      {
        "step 4": "Implement an `undo_action` method within your editor class or relevant UI controller. This method should:\n    1. Check if `undo_redo_manager.can_undo()` returns `True`.\n    2. If true, get the current text content of the editor widget (`current_state_before_undo`).\n    3. Call `undo_redo_manager.undo(current_state_before_undo)` to get the previous state (`state_to_restore`).\n    4. Update the editor widget's content to `state_to_restore`. *Crucially*, ensure this update operation itself does *not* trigger the `add_change` logic again (e.g., use a temporary flag or mechanism to bypass the change listener during programmatic updates).\n*Hint:* Consider how to handle the cursor position; for now, simply restoring the text is the primary goal."
      },
      {
        "step 5": "Implement a `redo_action` method, similar to `undo_action`. This method should:\n    1. Check if `undo_redo_manager.can_redo()` returns `True`.\n    2. If true, get the current text content of the editor widget (`current_state_before_redo`).\n    3. Call `undo_redo_manager.redo(current_state_before_redo)` to get the next state (`state_to_restore`).\n    4. Update the editor widget's content to `state_to_restore`, again ensuring this update does not trigger `add_change`.\n*Hint:* Cursor position handling can be refined later."
      },
      {
        "step 6": "If you used the widget's built-in undo/redo (skipped steps 2-5), identify the methods provided by the widget for performing undo and redo (e.g., `widget.edit_undo()`, `widget.edit_redo()` in Tkinter). Create simple wrapper methods `undo_action` and `redo_action` in your editor class that call these built-in widget methods."
      },
      {
        "step 7": "Integrate the `undo_action` and `redo_action` methods with the user interface:\n    1. Bind the standard keyboard shortcuts to these actions. Use the UI framework's key binding mechanism (e.g., `widget.bind('<Control-z>', ...)` or `QShortcut`). Common bindings are `Control+Z` (or `Command+Z` on macOS) for Undo, and `Control+Y`, `Command+Y`, `Control+Shift+Z`, or `Command+Shift+Z` for Redo.\n    2. If an 'Edit' menu exists in the UI, add 'Undo' and 'Redo' menu items. Connect these items to trigger `undo_action` and `redo_action` respectively.\n    3. (Recommended if using custom manager) Update the 'Edit' menu items' enabled/disabled state based on the return values of `undo_redo_manager.can_undo()` and `undo_redo_manager.can_redo()` whenever the state might change (e.g., after adding a change, undoing, or redoing)."
      },
      {
        "step 8": "Perform manual testing of the undo/redo functionality. Verify the following scenarios:\n    - Typing text, then undoing/redoing.\n    - Deleting text (using backspace/delete), then undoing/redoing.\n    - Cutting/Pasting text, then undoing/redoing.\n    - Performing multiple actions followed by multiple undos.\n    - Performing multiple undos, then multiple redos.\n    - Performing an undo, then typing new text (should clear the redo history).\n    - Trying to undo/redo when the respective stacks are empty.\nDocument any bugs or unexpected behavior found during testing."
      }
    ],
    "Task 2.8: Set up initial syntax highlighting mechanism (basic language support).": [
      {
        "step 1": "Identify the core text editor widget currently used in the IDE's UI framework (e.g., `QPlainTextEdit` in PyQt, `Text` in Tkinter, or a specific component in a web framework). Research and select a suitable syntax highlighting library or mechanism compatible with this widget. Hint: For PyQt/PySide, `QSyntaxHighlighter` is the standard approach. For web-based editors, consider libraries like Monaco Editor's built-in features, Prism.js, or Highlight.js."
      },
      {
        "step 2": "Assuming a Qt-based framework (like PyQt/PySide) and `QSyntaxHighlighter`: Create a new Python file (e.g., `syntax_highlighter.py`) and define a class that inherits from `QSyntaxHighlighter`. This class will contain the logic for highlighting."
      },
      {
        "step 3": "Within the new `QSyntaxHighlighter` subclass, define basic highlighting rules for a simple language, starting with Python. Focus on keywords, single-line comments (`#`), and string literals (single and double quoted). Hint: Use regular expressions (`re` module) to define patterns for these elements."
      },
      {
        "step 4": "Define `QTextCharFormat` objects within the highlighter class to specify the visual styles (color, font weight, etc.) for each token type (e.g., keyword, comment, string, default text). Choose distinct and readable colors for basic highlighting."
      },
      {
        "step 5": "Implement the `highlightBlock(self, text)` method in your `QSyntaxHighlighter` subclass. This method receives each block of text (usually a line) and should apply the defined `QTextCharFormat` styles based on the regex patterns you created in Step 3. Hint: Iterate through regex matches and use `self.setFormat(start, count, format)`."
      },
      {
        "step 6": "In the UI code where the main text editor widget is instantiated, import your custom highlighter class. Create an instance of your highlighter, passing the editor widget's document (`editor.document()`) to its constructor."
      },
      {
        "step 7": "Modify the highlighter class to handle multi-line constructs if necessary for the chosen basic features (e.g., multi-line strings in Python). Update the `highlightBlock` method to manage state between blocks using `self.previousBlockState()` and `self.setCurrentBlockState()`. Start with basic handling for Python triple-quoted strings."
      },
      {
        "step 8": "Test the implementation by running the IDE application. Load or type some Python code containing keywords, comments, and strings into the editor. Verify that the syntax is highlighted according to the defined rules and styles. Check that highlighting updates correctly as you type and edit."
      },
      {
        "step 9": "Refactor the `syntax_highlighter.py` file for clarity and organization. Ensure patterns, formats, and the `highlightBlock` logic are well-structured and commented. Consider separating rule definitions (patterns and formats) from the core highlighting logic if the class becomes complex."
      }
    ],
    "Task 2.9: Implement line number display in the editor component.": [
      {
        "step 1": "Locate the primary source file(s) for the core text editor component within the project structure. Identify the main UI element used for text input (e.g., `<textarea>`, `div[contenteditable]`, or a specific library component like CodeMirror/Monaco)."
      },
      {
        "step 2": "Analyze the editor component's structure and logic. Determine how it currently renders text content and handles updates (e.g., state management, props, event listeners like `onChange`, `onInput`)."
      },
      {
        "step 3": "Modify the editor component's template (HTML/JSX/etc.) to include a new container element (e.g., a `<div>`) positioned to the left of the text input area. This will serve as the 'gutter' for line numbers. Use CSS (Flexbox or Grid are good options) to arrange the gutter and the text area side-by-side."
      },
      {
        "step 4": "Implement logic within the editor component to calculate the number of lines based on its current text content. Store this line count in the component's state or derive it dynamically. *Hint: Split the text content string by newline characters (`\\n`). The number of lines is typically the length of the resulting array. Handle the edge case of empty content (0 or 1 line depending on desired behavior).* "
      },
      {
        "step 5": "Update the component's rendering logic to populate the gutter element created in step 3. Generate a vertical list of numbers (1, 2, 3, ...) up to the calculated line count. *Hint: You can render a `<pre>` tag containing numbers separated by newlines, or map over an array of numbers to create individual `<div>` or `<span>` elements for each line number.*"
      },
      {
        "step 6": "Ensure the line number display updates dynamically whenever the editor's content changes. Hook into the existing content update mechanism (identified in step 2) to trigger a recalculation of the line count and re-render the gutter content."
      },
      {
        "step 7": "Implement vertical scroll synchronization between the text input area and the line number gutter. Add an `onScroll` event listener to the primary text input/scrolling element. Inside the event handler, read the `scrollTop` property of the text area and apply the same `scrollTop` value to the gutter element. *Hint: If using an editor library like CodeMirror or Monaco, check its documentation first for built-in gutter or line number options, which often handle scrolling automatically. Search for '[Library Name] line numbers' or '[Library Name] gutter scroll sync'.*"
      },
      {
        "step 8": "Apply CSS styling to the gutter and the line numbers within it. Ensure correct alignment, padding, width, text alignment (usually right-aligned), font size, and line height to match the editor's text visually. *Hint: Use your browser's developer tools to inspect the editor's text element and copy relevant font and line-height styles. Ensure the gutter has `overflow: hidden` to prevent its own scrollbar.*"
      },
      {
        "step 9": "Review the implementation for potential edge cases and performance. Consider large files – does the line number generation or scrolling become slow? Optimize if necessary. *Hint: For very large files, consider virtual scrolling techniques for the line numbers if performance degrades, though this significantly increases complexity.*"
      },
      {
        "step 10": "Manually test the line number functionality thoroughly. Verify: correct number count on load, updates during typing/deleting/pasting, accurate scroll synchronization, consistent alignment, and behavior with empty or single-line content."
      }
    ],
    "Task 2.10: Build the main application menu bar structure (File, Edit, View...).": [
      {
        "step 1": "Identify the UI framework being used for the IDE (e.g., Tkinter, PyQt, Kivy). Locate the main application window instance created in previous steps. Create a new file, if it doesn't exist, named `menu_bar.py` within the UI component directory (e.g., `src/ui/menu_bar.py`) to house the menu bar logic."
      },
      {
        "step 2": "In `menu_bar.py`, define a function or class responsible for creating the menu bar (e.g., `create_main_menu(parent_window)`). Within this function/class, instantiate the main menu bar widget appropriate for the chosen UI framework (e.g., `tk.Menu(parent_window)` for Tkinter)."
      },
      {
        "step 3": "Create the top-level cascade menus: 'File', 'Edit', 'View', 'Run', and 'Help'. Use the appropriate widget from the UI framework (e.g., `tk.Menu` for Tkinter, tearoff=0 is recommended for Tkinter). Add these cascade menus to the main menu bar created in the previous step, labelling them correctly."
      },
      {
        "step 4": "Populate the 'File' menu. Add the following menu items: 'New File', 'Open File...', 'Save', 'Save As...', a separator, and 'Exit'."
      },
      {
        "step 5": "Populate the 'Edit' menu. Add the following menu items: 'Undo', 'Redo', a separator, 'Cut', 'Copy', 'Paste', a separator, and 'Select All'."
      },
      {
        "step 6": "Populate the 'View' menu. Add placeholder items relevant to an IDE, such as: 'Toggle Theme', 'Show/Hide Line Numbers', 'Zoom In', 'Zoom Out'."
      },
      {
        "step 7": "Populate the 'Run' menu. Add placeholder items such as: 'Run Current File', 'Debug Current File', 'Build Project'."
      },
      {
        "step 8": "Populate the 'Help' menu. Add placeholder items such as: 'View Documentation', 'Check for Updates...', 'About'."
      },
      {
        "step 9": "Define placeholder command functions (e.g., within the `menu_bar.py` module or its class). Create a simple function like `_placeholder_action(item_name)` that prints f'Action: {item_name} triggered.' or logs the action. Associate each menu item created in steps 4-8 with a corresponding placeholder command (using lambda functions if necessary to pass item names or specific identifiers)."
      },
      {
        "step 10": "Integrate the menu bar into the main application window. Call the `create_main_menu` function/method, passing the main window instance. Configure the main window to use the generated menu bar (e.g., `main_window.config(menu=main_menu_widget)` for Tkinter). Run the application to visually verify the menu bar structure and test clicking several menu items to confirm the placeholder actions are triggered."
      },
      {
        "step 11": "Review the code in `menu_bar.py`. Ensure it is well-organized, follows the project's coding style, and uses clear variable names. Add comments explaining the purpose of the placeholder actions and marking them for future implementation (e.g., `# TODO: Implement New File action`)."
      }
    ],
    "Task 2.11: Build the status bar and display basic editor/file information.": [
      {
        "step 1": "Identify the main UI layout component file within the project structure. Also, identify the chosen UI framework (e.g., React, Vue, Svelte with Electron, or Tkinter, PyQt, etc.) and the established styling approach (e.g., CSS Modules, styled-components, standard CSS)."
      },
      {
        "step 2": "Create a new component file (e.g., `StatusBar.jsx`, `status_bar.py`) dedicated to the status bar UI. Structure it as a distinct component according to the project's framework conventions."
      },
      {
        "step 3": "Implement the basic structure of the status bar component. It should be a container (e.g., a `div` or equivalent) that spans the width of the application window. Apply initial styling to position it fixed at the bottom, give it a distinct background color, and appropriate padding. Ensure it doesn't overlap content or get scrolled away. Hint: Use CSS `position: fixed`, `bottom: 0`, `left: 0`, `right: 0`, `z-index`, or framework-specific layout managers."
      },
      {
        "step 4": "Define distinct sections within the status bar for different information categories (e.g., left, center, right). Use layout techniques like Flexbox or Grid to arrange these sections. Add placeholder text elements (e.g., `<span>` or framework equivalent) within these sections for: 'Cursor Position', 'File Name', 'Language Mode', 'Encoding', 'Line Endings'."
      },
      {
        "step 5": "Identify how the application manages the state of the active editor, including cursor position and the currently open file. This might involve a central state store (like Redux, Zustand, Context API), direct event listeners on the editor component, or message passing. Hint: Look for existing state management setup or editor API documentation/usage within the project."
      },
      {
        "step 6": "Connect the `StatusBar` component to the editor's state or events. Implement logic to receive updates for the cursor's line and column number. Update the 'Cursor Position' placeholder in the status bar dynamically as the cursor moves. Format it clearly (e.g., 'Ln X, Col Y')."
      },
      {
        "step 7": "Implement logic to receive updates about the currently active file/editor tab. Update the 'File Name' placeholder in the status bar to display the name of the currently active file. Display a default message like 'No file open' if no file is active."
      },
      {
        "step 8": "Implement logic to determine and display the language mode or file type of the active file (e.g., 'Python', 'JavaScript', 'Plain Text'). This might involve checking the file extension or using existing language detection logic if available. Update the 'Language Mode' placeholder accordingly."
      },
      {
        "step 9": "Access file metadata or properties related to the active file to retrieve its encoding (e.g., 'UTF-8') and line endings (e.g., 'LF', 'CRLF'). Update the corresponding placeholders in the status bar. Hint: This might require coordination with the file loading/saving module implemented previously."
      },
      {
        "step 10": "Integrate the newly created `StatusBar` component into the main application layout identified in Step 1. Ensure it renders correctly at the bottom of the window below other UI elements like the editor and file explorer."
      },
      {
        "step 11": "Review and refine the implementation. Ensure the status bar updates efficiently without causing performance issues, especially during rapid cursor movement. Check styling consistency with the rest of the application. Add comments where necessary and ensure code adheres to project standards."
      }
    ],
    "Task 2.12: Implement a rudimentary file tree view panel.": [
      {
        "step 1": "Create a new Python file named `file_tree_view.py`. This file will contain the class and logic for the file tree panel."
      },
      {
        "step 2": "In `file_tree_view.py`, import necessary libraries: `os`, `tkinter`, and `tkinter.ttk`. Ensure you are using the UI framework established in previous steps (assuming Tkinter/ttk here; adjust if a different framework like PyQt/PySide was chosen)."
      },
      {
        "step 3": "Define a class `FileTreeView` that inherits from an appropriate widget container (e.g., `ttk.Frame`). Its constructor (`__init__`) should accept the parent widget and optionally a starting path."
      },
      {
        "step 4": "Inside the `FileTreeView` constructor, create a `ttk.Treeview` widget. Configure it with necessary columns (e.g., 'Name', 'Type', 'Size') but initially hide all columns except the main tree column ('#0'). Set the heading for the main tree column (e.g., 'Project')."
      },
      {
        "step 5": "Add vertical and horizontal scrollbars (`ttk.Scrollbar`) to the `ttk.Treeview` widget created in the previous step. Configure them to control the treeview's scrolling and arrange them using `pack` or `grid` layout managers within the `FileTreeView` frame."
      },
      {
        "step 6": "Implement a method within `FileTreeView` called `populate_tree(self, parent_node, path)`. This method will scan the directory specified by `path` using `os.listdir`, `os.path.isdir`, and `os.path.join`."
      },
      {
        "step 7": "Inside `populate_tree`, iterate through the items found in the directory. For each item, use `self.tree.insert()` to add it to the treeview under the `parent_node`. Differentiate between files and directories (e.g., using tags or icons if possible later, for now, just insert). For directories, insert a dummy child item (e.g., with text 'Loading...') so the '+' expansion icon appears. Store the full path associated with each item using the `values` or a separate dictionary."
      },
      {
        "step 8": "Implement a method `_on_node_expand(self, event)` that will be triggered when a directory node is expanded. Use `self.tree.bind('<<TreeviewOpen>>', self._on_node_expand)` in the constructor to link the event."
      },
      {
        "step 9": "In `_on_node_expand`, get the selected node (directory). Retrieve its associated path. Find and remove the dummy 'Loading...' child item. Call `populate_tree` for the selected node and its path to load its actual contents. Add logic to prevent reloading already populated directories."
      },
      {
        "step 10": "Implement a method `_on_node_select(self, event)` to handle item selection. Bind it using `self.tree.bind('<<TreeviewSelect>>', self._on_node_select)`. For now, this method should retrieve the selected item, get its associated path, and print the path to the console. (Hint: Use `self.tree.selection()` and `self.tree.item()` methods)."
      },
      {
        "step 11": "In the main application file (e.g., `main.py` or `app.py`), import the `FileTreeView` class."
      },
      {
        "step 12": "Instantiate `FileTreeView` within your main application window/frame. Place it in the desired layout position (typically on the left side, potentially using a `ttk.PanedWindow` or similar resizable container alongside the editor area)."
      },
      {
        "step 13": "Call the `populate_tree` method on the `FileTreeView` instance after instantiation, passing an empty string (`''`) for the `parent_node` and a default directory path (e.g., the current working directory `os.getcwd()`) to show the initial file structure."
      },
      {
        "step 14": "Add basic error handling within the directory scanning logic (`populate_tree`, `_on_node_expand`) using `try...except` blocks to catch potential `OSError` exceptions (e.g., permission denied)."
      },
      {
        "step 15": "Review and refactor the `file_tree_view.py` code. Add docstrings to the class and methods, and comments where necessary to explain complex logic."
      }
    ],
    "Task 2.13: Establish communication/event handling between UI elements and core logic.": [
      {
        "step 1": "Identify the primary UI elements involved in user interaction (e.g., the main text editor widget, 'File > Open' menu item, 'File > Save' menu item/button) and the core logic functions they should trigger (e.g., functions for loading file content, saving file content, tracking text changes). List these pairings."
      },
      {
        "step 2": "Define the initial strategy for communication. For now, use direct callbacks or signal/slot mechanisms provided by your chosen UI framework (e.g., `command` parameter in Tkinter, `connect` in PyQt/PySide, `addEventListener` in web frameworks). Avoid overly complex event bus patterns at this stage unless absolutely necessary."
      },
      {
        "step 3": "Implement an event listener/binding for the main code editor widget that detects text changes (e.g., key presses resulting in content modification). Hint: Look for events like 'TextChanged', 'key-release-event', or 'input' depending on your UI framework."
      },
      {
        "step 4": "Create a handler function (callback) that is triggered by the text change event from Step 3. Initially, this function can simply print a confirmation message (e.g., 'Text changed') or update an internal state variable indicating unsaved changes (e.g., `self.is_dirty = True`). Ensure this handler has access to the necessary application state or core logic module."
      },
      {
        "step 5": "Implement an event listener/binding for the 'Save' action (e.g., 'File > Save' menu item or a dedicated Save button). This listener should trigger when the user activates the save command."
      },
      {
        "step 6": "Create a handler function for the 'Save' action. This function should: \n    a. Retrieve the current content from the main code editor widget.\n    b. Determine the target file path (this might involve prompting the user if the file is new or using the currently open file path).\n    c. Call the appropriate core logic function (e.g., `core_logic.save_file(filepath, content)`), passing the file path and content. \n    d. Handle potential errors returned by the core logic (e.g., file permissions). \n    Hint: Stub the core logic function if it doesn't fully exist yet, ensuring it accepts the expected arguments."
      },
      {
        "step 7": "Implement an event listener/binding for the 'Open' action (e.g., 'File > Open' menu item)."
      },
      {
        "step 8": "Create a handler function for the 'Open' action. This function should: \n    a. Prompt the user to select a file (using a framework-specific file dialog).\n    b. If a file is selected, call the appropriate core logic function (e.g., `core_logic.open_file(filepath)`).\n    c. Upon successful file loading by the core logic, retrieve the loaded content.\n    d. Update the main code editor widget to display the loaded content.\n    e. Handle potential errors (e.g., file not found, read errors). \n    Hint: Ensure the `open_file` core logic function returns the content or provides a way to access it."
      },
      {
        "step 9": "Establish a basic mechanism for the core logic to send feedback or updates back to the UI. Start by creating a function within your UI management code (e.g., `ui_manager.update_status(message: str)`) that can update a status bar label or print to a console area within the IDE."
      },
      {
        "step 10": "Integrate the UI update mechanism from Step 9 into the 'Save' and 'Open' handlers (Steps 6 and 8). Call `ui_manager.update_status()` after successful operations (e.g., 'File saved successfully', 'File opened') or upon errors (e.g., 'Error saving file: [details]')."
      },
      {
        "step 11": "Perform manual testing: \n    a. Type text into the editor and check if the change handler (Step 4) is triggered.\n    b. Use the 'Save' action, save a file, and verify the content is saved correctly and the status updates.\n    c. Use the 'Open' action, select the saved file, and verify the content loads into the editor and the status updates."
      },
      {
        "step 12": "Review the implemented event handlers and communication paths. Consider if the direct callback approach is becoming complex. Add comments explaining the connections. Note areas where error handling could be improved or where decoupling might be beneficial later (e.g., using a dedicated signal manager or event bus if many components need to react to the same events)."
      }
    ]
  },
  "Phase 3: Language Support & Tooling Integration (Syntax Highlighting, Completion, Debugger, Build)": {
    "Task 3.1: Design abstract API for language-specific features (highlighting, completion, diagnostics).": [
      {
        "step 1": "Analyze the requirements for an abstract language service API. Identify the core functionalities needed: syntax highlighting, code completion, and diagnostics (linting/error reporting). Define the goal: to create a set of interfaces or abstract classes that decouple the IDE's core from language-specific logic. Consider existing standards like the Language Server Protocol (LSP) for inspiration regarding data structures and capabilities, but focus on designing the internal API for *our* IDE."
      },
      {
        "step 2": "Create a new directory named `language_services` within the `src` directory. Inside `language_services`, create a file (e.g., `api.py`, `api.ts`) where the abstract API definitions will reside."
      },
      {
        "step 3": "Define common data structures within `src/language_services/api.py` (or equivalent). These should include structures for representing: \n- `Position` (line, column)\n- `Range` (start_position, end_position)\n- `DiagnosticSeverity` (Error, Warning, Information, Hint)\n- `Diagnostic` (range, severity, message, source?)\n- `CompletionItemKind` (Function, Variable, Class, Interface, Keyword, etc.)\n- `CompletionItem` (label, kind, detail?, documentation?, insert_text?)\n- `SyntaxToken` (range, token_type/scope, modifiers?)\n *Hint: Look at LSP specifications for standard representations of these concepts.*"
      },
      {
        "step 4": "Define an abstract interface or class named `SyntaxHighlighter` within `src/language_services/api.py`. It should include a method signature like `get_semantic_tokens(document_uri: str, text: str) -> List[SyntaxToken]`. Determine if this should be synchronous or asynchronous initially. \n*Hint: Semantic highlighting often requires context and can be complex. Consider if an asynchronous approach might be better long-term, even if starting synchronous.*"
      },
      {
        "step 5": "Define an abstract interface or class named `CompletionProvider` within `src/language_services/api.py`. It should include a method signature like `get_completions(document_uri: str, text: str, position: Position) -> List[CompletionItem]`. \n*Hint: Completion requests are triggered frequently and need to be fast, but gathering suggestions might involve analysis. Consider asynchronous execution (`async def get_completions(...) -> List[CompletionItem]`).*"
      },
      {
        "step 6": "Define an abstract interface or class named `DiagnosticsProvider` within `src/language_services/api.py`. It should include a method signature like `get_diagnostics(document_uri: str, text: str) -> List[Diagnostic]`. \n*Hint: Diagnostics often involve full file parsing or external linters and are prime candidates for asynchronous execution (`async def get_diagnostics(...) -> List[Diagnostic]`).*"
      },
      {
        "step 7": "Define a central abstract interface or class named `LanguageService` within `src/language_services/api.py`. This interface should aggregate the individual feature providers (SyntaxHighlighter, CompletionProvider, DiagnosticsProvider). An instance implementing `LanguageService` would represent the collective capabilities for a specific language. It might directly contain the methods from steps 4-6 or hold references to objects implementing those interfaces."
      },
      {
        "step 8": "Review and refactor the defined interfaces and data structures (`SyntaxHighlighter`, `CompletionProvider`, `DiagnosticsProvider`, `LanguageService`, and supporting structures). Ensure consistency in naming and parameter types (e.g., consistently using `document_uri` or `text`). Add comprehensive docstrings/comments explaining the purpose of each interface, method, parameter, return type, and data structure."
      },
      {
        "step 9": "Update the method signatures in the `LanguageService` interface (and its components) to use asynchronous patterns (e.g., `async`/`await` in Python/TypeScript, or returning Promises/Futures) for potentially long-running operations like `get_completions` and `get_diagnostics`. Ensure `get_semantic_tokens` is also considered for async if complex analysis is anticipated."
      },
      {
        "step 10": "Create a new file, e.g., `src/language_services/null_language_service.py`. Implement a concrete class `NullLanguageService` that inherits from/implements the `LanguageService` interface. This implementation should provide default, non-functional behavior (e.g., return empty lists for tokens, completions, and diagnostics). This serves as a test case and a default fallback."
      },
      {
        "step 11": "Write basic unit tests for the `NullLanguageService`. Verify that instances of `NullLanguageService` can be created and that calling its methods (e.g., `get_completions`, `get_diagnostics`, `get_semantic_tokens`) returns the expected empty results without errors. Use a testing framework appropriate for the project language (e.g., `unittest` or `pytest` for Python, `jest` or `mocha` for TypeScript)."
      }
    ],
    "Task 3.2: Select and integrate a syntax highlighting library/engine (e.g., using TextMate grammars, Tree-sitter).": [
      {
        "step 1": "Analyze the existing codebase to identify the core text editor component implementation file(s). Determine and report the specific editor library or framework being used (e.g., Monaco Editor, CodeMirror, Ace Editor, Quill, or a custom implementation)."
      },
      {
        "step 2": "Based on the editor identified in step 1, research compatible syntax highlighting libraries or built-in mechanisms. Search the web for options like the editor's native capabilities, libraries leveraging TextMate grammars (e.g., `vscode-textmate`, `monaco-textmate` with `vscode-oniguruma-wasm`), Tree-sitter (`web-tree-sitter`), or others (e.g., Prism.js, Highlight.js). List the potential options and their primary integration methods relevant to the identified editor."
      },
      {
        "step 3": "Evaluate the researched highlighting options from step 2. Create a comparison summary focusing on: Compatibility with the project's editor, Performance (especially on large files), Language grammar availability/quality (check for common languages like JavaScript, Python, HTML, CSS, Java, C++), Extensibility (adding new languages), and Maintenance/Community support. Use this evaluation to inform the selection."
      },
      {
        "step 4": "Select the most suitable syntax highlighting engine based on the evaluation in step 3. Clearly state the chosen engine and provide a justification based on the comparison criteria and the project's context (e.g., 'Selected Monaco Editor's built-in TextMate support via `monaco-textmate` due to seamless integration and wide grammar availability')."
      },
      {
        "step 5": "Develop a detailed integration plan. Outline the specific code modifications, API calls, configuration changes, and any helper functions needed to integrate the chosen engine (from step 4) into the editor component (identified in step 1). Specify the files that will need modification."
      },
      {
        "step 6": "Install the selected library/engine and its dependencies using the project's package manager (e.g., `npm install monaco-textmate vscode-oniguruma-wasm` or `npm install web-tree-sitter`). If required, locate and download/prepare grammar files (e.g., TextMate `.tmLanguage.json` files) or parser builds (e.g., Tree-sitter `.wasm` files) for at least two languages: JavaScript and Python. Place these assets in an appropriate location within the project structure (e.g., an `assets/grammars` directory)."
      },
      {
        "step 7": "Implement the core integration logic based on the plan from step 5. Modify the editor component's initialization/configuration code to load and activate the highlighting engine. Ensure the engine is correctly configured to use the grammars/parsers for JavaScript and Python. (Hint: For Monaco/TextMate, this involves wiring `monaco-textmate` and potentially `vscode-oniguruma-wasm`. For Tree-sitter, initialize the parser and load language WASM. For CodeMirror 6, configure language extensions like `@codemirror/lang-javascript`)."
      },
      {
        "step 8": "Implement or refine the logic for loading grammars/parsers. This should handle associating file types (e.g., based on file extension like `.js`, `.py`) with the corresponding language configuration and grammar/parser. Ensure this mechanism correctly triggers the loading and application of highlighting for JavaScript and Python files when they are opened or their language mode is set."
      },
      {
        "step 9": "Implement basic theme integration for syntax highlighting. Ensure that highlighted tokens/nodes are styled differently from plain text. If a theming system exists, map the semantic scopes/token types provided by the highlighter to the theme's style definitions (e.g., map TextMate scopes or Tree-sitter node types to CSS classes or editor theme rules). Aim for distinct colors/styles for common elements like keywords, strings, comments, and variables/identifiers, respecting basic light/dark modes if applicable."
      },
      {
        "step 10": "Test the syntax highlighting implementation thoroughly. Create or open sample JavaScript and Python files containing various language constructs (functions, classes, loops, conditionals, comments, strings, numbers, etc.). Verify that highlighting is applied correctly and updates dynamically and performantly during editing (typing, deleting, pasting)."
      },
      {
        "step 11": "Refactor the syntax highlighting integration code. Ensure it is well-structured, modular, and includes error handling (e.g., for missing grammars or loading failures). Add clear comments explaining the setup, configuration, and the process for adding support for new languages. Update any relevant project documentation (e.g., README) to reflect the new syntax highlighting feature."
      }
    ],
    "Task 3.3: Implement syntax highlighting definition loading and application for at least one language.": [
      {
        "step 1": "Research JavaScript libraries for parsing and applying TextMate grammars (.tmLanguage, often in JSON or Plist format) for syntax highlighting. Prioritize libraries compatible with modern web frameworks and potentially used by popular editors like VS Code. Recommend `vscode-textmate` and its dependency `oniguruma` (wasm version). Summarize your findings and chosen library."
      },
      {
        "step 2": "Install the chosen syntax highlighting library (`vscode-textmate`) and its required dependencies (`oniguruma`) using the project's package manager (e.g., npm or yarn). Ensure the necessary wasm files for `oniguruma` are correctly configured to be accessible at runtime (e.g., copied to the public/assets directory and fetched)."
      },
      {
        "step 3": "Search the web (e.g., GitHub repositories for VS Code extensions or TextMate bundles) for a standard TextMate grammar file for the Python language. Prefer the JSON format (`.tmLanguage.json`) if available, otherwise use the Plist format (`.tmLanguage`). Download the file and place it in a suitable directory within the project structure, such as `public/assets/grammars/python.tmLanguage.json`."
      },
      {
        "step 4": "Create a new module or service dedicated to syntax highlighting (e.g., `src/services/syntaxHighlightingService.js` or similar). This service will encapsulate the logic for loading grammars and tokenizing code."
      },
      {
        "step 5": "Within the `syntaxHighlightingService`, implement the setup for `vscode-textmate`. This includes: initializing the `oniguruma` WASM, creating a grammar registry (`Registry` from `vscode-textmate`), and providing options to load grammars (resolving scope names)."
      },
      {
        "step 6": "Implement a function in `syntaxHighlightingService` to load a specific grammar from a file path or URL. This function should fetch the grammar file content (e.g., the Python grammar downloaded in step 3), parse it (handling both JSON and Plist if necessary, though `vscode-textmate` might handle this), and register it with the `Registry` under a specific scope name (e.g., 'source.python'). Handle potential file loading or parsing errors gracefully."
      },
      {
        "step 7": "Implement a core tokenization function in `syntaxHighlightingService`. This function should accept the text content (potentially line by line) and the language's scope name (e.g., 'source.python') as input. It should use the `Registry` to get the grammar and call the grammar's `tokenizeLine` or `tokenizeLine2` method. Store or return the tokenization results (tokens and their scopes)."
      },
      {
        "step 8": "Define a basic set of CSS rules corresponding to common TextMate scopes. Create a CSS file (e.g., `src/styles/syntax-highlighting.css`) and add styles for scopes like `keyword.control`, `entity.name.function`, `string.quoted.double`, `comment.line.number-sign`, `variable.language`. Import or link this CSS file so it's applied to the editor."
      },
      {
        "step 9": "Integrate the `syntaxHighlightingService` with the existing text editor component. Modify the editor component to: \n    a) Instantiate the service.\n    b) Load the Python grammar on initialization.\n    c) Call the tokenization function whenever the editor's content is loaded or significantly changes.\n    d) Map the tokenization results (scopes) to the CSS classes defined in step 8.\n    e) Apply these classes to the corresponding text spans within the editor. (Hint: This might involve using the editor's specific API for decorations, overlays, or directly manipulating the DOM if it's a simple editor)."
      },
      {
        "step 10": "Implement logic to associate file types with grammar scope names. For now, hardcode a mapping where files ending in `.py` use the 'source.python' scope name. Ensure this mapping is used when a file is opened in the editor to trigger the correct highlighting."
      },
      {
        "step 11": "Test the syntax highlighting implementation thoroughly. Open a Python file containing various language constructs (keywords, functions, classes, strings, comments, numbers, decorators). Verify that the text is colored according to the defined CSS rules. Test edge cases like empty files, very long lines, and files with mixed language elements (if applicable)."
      },
      {
        "step 12": "Refactor the syntax highlighting integration code for clarity, efficiency, and error handling. Ensure that tokenization is reasonably performant and doesn't block the UI thread excessively, especially for large files or frequent edits (consider debouncing or background processing if needed, depending on the editor's capabilities)."
      }
    ],
    "Task 3.4: Define and implement theming support for syntax colors.": [
      {
        "step 1": "Define the data structure for syntax highlighting themes. Choose JSON as the format. The structure should map abstract style identifiers (e.g., `keyword`, `string`, `comment`, `number`, `operator`, `identifier`, `builtin`, `class_name`, `function_name`, `text`, `background`, `selection_background`, `gutter_foreground`, `gutter_background`) to style properties, minimally including a color value (e.g., hex code like `#RRGGBB`). Consider adding optional properties like `font_style` (e.g., `bold`, `italic`). Create a markdown file (`docs/theme_structure.md`) documenting this JSON structure."
      },
      {
        "step 2": "Create a dedicated directory named `themes` within the project's resource or assets folder. Inside this directory, create at least two default theme files: `default_light.json` and `default_dark.json`. Populate these files according to the structure defined in Step 1, using sensible color choices for a light and a dark editing environment. Hint: Search the web for popular IDE theme palettes (like Solarized, Dracula, Monokai, Nord) for inspiration on color choices and common style identifiers."
      },
      {
        "step 3": "Implement a `ThemeManager` class (e.g., in `src/theming/theme_manager.py`). This class should: \n1. Discover available theme files (scan the `themes` directory for `.json` files). \n2. Load and parse a specified theme file (handle potential JSON parsing errors). \n3. Store the currently active theme data (dictionary). \n4. Provide a method `get_style(style_identifier: str) -> dict` that returns the style properties (e.g., `{'color': '#RRGGBB', 'font_style': 'bold'}`) for a given identifier. \n5. Implement fallback logic: if a specific identifier isn't found in the current theme, return a sensible default (e.g., default text color for unknown code elements, black/white for backgrounds). \n6. Store the path/name of the currently active theme. \n7. Load a default theme (e.g., `default_light.json`) upon initialization."
      },
      {
        "step 4": "Refactor the existing syntax highlighting logic (where token types are mapped to visual styles). Modify it to use the `ThemeManager`. \n1. Instantiate the `ThemeManager`. \n2. Instead of using hardcoded colors/styles, call the `ThemeManager.get_style()` method, passing the appropriate abstract style identifier that corresponds to the token type identified by the syntax highlighter/lexer. \n3. Ensure the mapping between your syntax highlighter's token types (e.g., `Token.Keyword`, `Token.Literal.String`) and the theme's abstract style identifiers (e.g., `keyword`, `string`) is clearly defined, possibly within the syntax highlighting module itself or the `ThemeManager`. \nHint: You might need to pass the `ThemeManager` instance to the highlighting component or make it globally accessible (e.g., via a singleton or dependency injection)."
      },
      {
        "step 5": "Integrate the theme's general appearance styles with the main editor widget. Use the `ThemeManager` to retrieve the styles for `background`, `text` (default foreground), `selection_background`, `gutter_foreground`, and `gutter_background`. Apply these styles to the appropriate properties of the text editor widget and its associated components (like line number gutter). Ensure these are applied when a theme is initially loaded."
      },
      {
        "step 6": "Implement a mechanism to dynamically update the editor's appearance when the theme changes. \n1. Add a method to the `ThemeManager` like `set_active_theme(theme_name: str)` which loads the new theme. \n2. After a theme is successfully loaded/changed via `set_active_theme`, the `ThemeManager` should notify relevant parts of the UI (especially the editor component) that the theme has changed. Hint: Use an observer pattern, signals/slots (if using PyQt/Qt), or callbacks to trigger a re-styling/re-highlighting of the editor content and its surrounding elements (background, gutter, etc.)."
      },
      {
        "step 7": "If a settings UI exists (or if planned), add a component (e.g., a dropdown menu in the settings dialog or view menu) to list available themes (discovered by `ThemeManager`) and allow the user to select one. Connect this UI component's selection change event to call the `ThemeManager.set_active_theme()` method. Persist the user's selected theme name (e.g., in a configuration file) so it can be reloaded the next time the IDE starts. Update the `ThemeManager` initialization to load the persisted theme name, falling back to the default if none is saved."
      },
      {
        "step 8": "Write unit tests for the `ThemeManager`. Test theme discovery, loading valid and invalid JSON files, retrieving styles (including fallback behavior), and changing themes. Add integration tests (if feasible) to verify that changing a theme via the UI correctly updates the editor's appearance. Refactor related code for clarity and robustness based on testing."
      }
    ],
    "Task 3.5: Design and implement the code completion suggestion UI (popup list).": [
      {
        "step 1": "Define the structure for the code completion suggestion UI component. This component will be responsible for displaying a list of potential completions in a popup window near the cursor. Choose an appropriate UI element based on the project's GUI framework (e.g., a `div` for web, `QListWidget` for PyQt, a custom widget). Create a new file (e.g., `completion_popup.js`, `completion_popup.py`) for this component."
      },
      {
        "step 2": "Implement the basic rendering logic for the completion popup. It should initially be hidden. Create a function `show(suggestions: list, position: tuple)` that makes the popup visible and populates it with the provided list of suggestion strings. Create a function `hide()` that makes the popup invisible. Hint: For now, just display the raw suggestion strings."
      },
      {
        "step 3": "Implement the positioning logic within the `show` function. The `position` argument will likely represent the cursor's coordinates (e.g., `{x, y}` or `{line, ch}`). Calculate the absolute screen position for the top-left corner of the popup, placing it just below the current cursor position. Hint: You might need access to the editor's coordinate system or rendering details. Ensure the popup stays within the bounds of the main application window."
      },
      {
        "step 4": "Implement dynamic population of the suggestion list within the `show` function. Ensure the component clears previous suggestions before displaying new ones. Handle cases where the suggestion list might be empty (the popup should likely not be shown or should be hidden immediately). Hint: Make the list scrollable if the number of suggestions exceeds a certain threshold (e.g., 10 items)."
      },
      {
        "step 5": "Implement keyboard navigation within the popup list. Add event handlers (or integrate with the editor's event handling) for 'ArrowUp', 'ArrowDown', 'Enter', 'Tab', and 'Escape'. 'ArrowUp'/'ArrowDown' should change the highlighted/selected item in the list. 'Escape' should hide the popup. 'Enter'/'Tab' should confirm the selection. Hint: Maintain an internal state variable for the currently selected index. Ensure visual feedback (highlighting) for the selected item."
      },
      {
        "step 6": "Implement the selection confirmation logic. When the user presses 'Enter' or 'Tab' on a selected suggestion (or potentially clicks an item), the popup should trigger an action to insert the selected suggestion text into the editor at the current cursor position. Hint: This might involve emitting a custom event (e.g., `suggestion_selected`) with the chosen text, which the main editor component will listen for, or calling a callback function provided during initialization."
      },
      {
        "step 7": "Refine the show/hide logic. The popup should automatically hide if the user clicks outside of it, types characters that make the current suggestions irrelevant, or moves the cursor significantly. Hint: This often involves close coordination with the editor's event listeners (e.g., `onKeyPress`, `onCursorActivity`, `onBlur`)."
      },
      {
        "step 8": "Apply basic styling to the completion popup and its list items to make it visually distinct and readable. Use CSS or the styling mechanisms of your chosen GUI framework. Consider background color, text color, padding, border, and highlighting for the selected item. Hint: Look at existing IDEs for common styling patterns. Consider adding icons or type information next to suggestions later, but focus on the basic list structure now."
      },
      {
        "step 9": "Integrate the `CompletionPopup` component with the main editor view. Instantiate the popup. Add placeholder logic in the editor component to call the popup's `show()` method with dummy data and cursor position when a specific trigger occurs (e.g., typing '.') and to call `hide()` appropriately. Ensure the keyboard events intended for the popup are correctly routed when it's visible. Hint: You might need to manage focus between the editor and the popup."
      },
      {
        "step 10": "Write basic tests or perform manual testing to ensure the popup appears at the correct position, displays suggestions, allows navigation (Up/Down/Enter/Esc), handles selection correctly (triggering insertion), and hides under appropriate conditions (Esc, click outside, cursor move)."
      }
    ],
    "Task 3.6: Implement a basic completion provider (e.g., keywords based on syntax definition).": [
      {
        "step 1": "Create a new file named `completion_provider.py`. This module will contain the logic for generating code completion suggestions."
      },
      {
        "step 2": "Inside `completion_provider.py`, define a list or set containing the keywords for the primary language your IDE supports (e.g., Python). Name this variable `LANGUAGE_KEYWORDS`. *Hint: For Python, you can use the standard `keyword` module (`import keyword; LANGUAGE_KEYWORDS = keyword.kwlist`) or define a static list: `['def', 'class', 'if', 'else', 'elif', 'for', 'while', 'import', 'from', 'return', 'try', 'except', 'finally', 'with', 'as', 'pass', 'break', 'continue', 'global', 'nonlocal', 'assert', 'yield', 'lambda', 'del', 'in', 'is', 'not', 'and', 'or', 'True', 'False', 'None']`.*"
      },
      {
        "step 3": "In `completion_provider.py`, implement a function `get_current_word(text_content: str, cursor_position: int) -> str`. This function should identify and return the partial word directly preceding the `cursor_position`. *Hint: Start from `cursor_position - 1` and iterate backwards through `text_content`, collecting alphanumeric characters until whitespace or a non-alphanumeric character (like '(', '.', '{', etc.) is encountered. Handle edge cases like the cursor being at the start of the text or the start of a line.*"
      },
      {
        "step 4": "In `completion_provider.py`, create the main completion function `get_keyword_completions(text_content: str, cursor_position: int) -> list[str]`. This function should: \n1. Call `get_current_word` to get the word being typed.\n2. If a partial word is found (e.g., length > 0), filter the `LANGUAGE_KEYWORDS` list to find keywords that start with the partial word (case-insensitive comparison is recommended).\n3. Return the sorted list of matching keywords. If no partial word is found or no keywords match, return an empty list."
      },
      {
        "step 5": "Modify your main text editor widget/component. Add logic to trigger the completion process. Connect to the appropriate signal/event that fires when the text content changes (e.g., `textChanged` in Qt, `<KeyRelease>` in Tkinter). In the event handler, call the `get_keyword_completions` function, passing the current text content and cursor position."
      },
      {
        "step 6": "Design and implement a basic UI element to display the completion suggestions (e.g., a `QListWidget` or `QtWidgets.QCompleter` with a `QStringListModel` in PyQt/PySide, a `tkinter.Listbox` in Tkinter). This UI element should initially be hidden."
      },
      {
        "step 7": "Integrate the suggestion UI with the editor. In the text change event handler (from Step 5), after getting the suggestions list: \n1. If the list is not empty, populate the suggestion UI element with the items.\n2. Calculate the appropriate position to display the suggestion UI (e.g., just below the current cursor position). *Hint: Use editor functions like `cursorRect()` in Qt or `bbox()` in Tkinter to get coordinates.*\n3. Make the suggestion UI visible and give it focus.\n4. If the list is empty, hide the suggestion UI."
      },
      {
        "step 8": "Implement interaction logic for the suggestion UI. Handle key presses like:\n1. **Up/Down Arrows:** Navigate the suggestion list.\n2. **Enter/Tab:** Select the highlighted suggestion. When selected, insert the chosen keyword into the text editor, replacing the partially typed word. Then, hide the suggestion UI.\n3. **Escape:** Hide the suggestion UI without inserting anything. \n*Hint: You might need to subclass the suggestion widget or install an event filter to capture these key presses, especially Tab, which might otherwise change focus.*"
      },
      {
        "step 9": "Refine the trigger condition. Modify the event handler (from Step 5) so that completions are only triggered when the character preceding the cursor suggests a keyword might be typed (e.g., after whitespace or at the start of a line) and the partial word length is at least 1 or 2 characters. Avoid triggering inside strings or comments for now (this can be improved later)."
      },
      {
        "step 10": "Perform manual testing: \n1. Type the beginning of various keywords (e.g., `de`, `cl`, `im`, `whi`). Verify the suggestion list appears with correct items.\n2. Use arrow keys to navigate and Enter/Tab to select. Verify correct insertion.\n3. Press Escape to dismiss the list.\n4. Type in contexts where keywords aren't expected (e.g., immediately after a '.') and verify completions don't appear (based on Step 9 refinement)."
      }
    ],
    "Task 3.7: Research and integrate a Language Server Protocol (LSP) client library.": [
      {
        "step 1": "Research available Language Server Protocol (LSP) client libraries suitable for the IDE's implementation language (assume Python for now unless specified otherwise in project context). Focus on libraries that handle the JSON-RPC communication layer. Hints: Search package repositories like PyPI and code hosting platforms like GitHub. Look for libraries like `python-lsp-client` or similar. Evaluate based on documentation, maintenance status, features (async support?), and license compatibility."
      },
      {
        "step 2": "Based on your research, select the most appropriate LSP client library. Justify your choice briefly in a comment within the project's documentation or relevant code file. Consider factors like ease of integration, community support, and performance."
      },
      {
        "step 3": "Install the selected LSP client library. Update the project's dependency file (e.g., `requirements.txt`, `pyproject.toml`) accordingly. Hint: Use the appropriate package manager (e.g., `pip install <library_name>`)."
      },
      {
        "step 4": "Create a new module named `lsp_integration.py` (or similar) to encapsulate LSP client logic. Define a class, e.g., `LspClientManager`, to manage LSP clients for different languages or projects."
      },
      {
        "step 5": "Implement functionality within `LspClientManager` to start an LSP server process for a specific language (e.g., Python using `pylsp`). Initially, hardcode the path or command for a known language server for testing purposes. Hint: Use the `subprocess` module to launch the server process, ensuring its standard input/output are correctly piped for communication. Store the process handle."
      },
      {
        "step 6": "Integrate the chosen LSP client library within `LspClientManager`. Implement the logic to connect the library to the running language server process (using stdio pipes from the previous step). Implement sending the LSP `initialize` request with appropriate client capabilities and project root URI. Handle the `initialize` response and log the server capabilities. Hint: Refer to the library's documentation for establishing transport and sending/receiving messages."
      },
      {
        "step 7": "Implement sending `textDocument/didOpen` notifications via the LSP client library whenever a file relevant to the LSP server is opened in the editor. Ensure you send the correct document URI, language ID, version, and full text content. Hook this into the IDE's existing file opening mechanism."
      },
      {
        "step 8": "Implement sending `textDocument/didChange` notifications when the content of an open document managed by the LSP server is modified in the editor. Ensure you send the appropriate incremental or full content changes as supported by the server capabilities. Hook this into the editor's text changed events."
      },
      {
        "step 9": "Implement handling for `textDocument/publishDiagnostics` notifications received from the LSP server. Parse the diagnostic information (severity, range, message). Store these diagnostics, associating them with the relevant document URI. For now, log the received diagnostics clearly. Hint: Register a notification handler using the LSP client library's API."
      },
      {
        "step 10": "Define an interface or callback mechanism within `LspClientManager` to communicate received diagnostics to the UI layer. Modify the UI code (specifically the editor component or a dedicated 'problems' panel) to consume these diagnostics and display them visually (e.g., underlining text, adding icons in the gutter, listing in a panel). Hint: This requires interaction with the existing UI framework and editor widget; focus on the data flow first."
      },
      {
        "step 11": "Implement the logic to trigger `textDocument/completion` requests based on user interaction within the editor (e.g., typing specific trigger characters like '.', '(', or manually invoking completion). Send the request with the document URI and current cursor position. Hint: Hook into the editor's key press or text changed events."
      },
      {
        "step 12": "Implement handling for `textDocument/completion` responses. Receive the completion items. Parse the response and log the suggestions for now. Hint: Register a request handler or use the callback mechanism provided by the LSP client library for responses."
      },
      {
        "step 13": "Design and implement a basic UI element (e.g., a popup list) to display completion suggestions received from the LSP server near the cursor position in the editor. Handle user selection from the list and insert the chosen completion into the editor text. Hint: This is highly dependent on the UI framework."
      },
      {
        "step 14": "Refactor the LSP integration module (`lsp_integration.py`). Add configuration options (e.g., in a settings file) to specify language server commands/paths instead of hardcoding them. Implement robust error handling for server crashes, communication failures, and invalid messages. Add comprehensive logging."
      },
      {
        "step 15": "Implement sending `shutdown` and `exit` notifications to the language server process when a project/file is closed or the IDE is shutting down. Ensure the server process is terminated cleanly. Hook this into the IDE's file/project closing and application exit procedures."
      },
      {
        "step 16": "Write tests for the `LspClientManager`. Mock the subprocess management and network/stdio communication where necessary. Test the initialization sequence, sending notifications (`didOpen`, `didChange`), handling responses (`completion`), and handling notifications (`publishDiagnostics`)."
      }
    ],
    "Task 3.8: Implement LSP integration for core features (completion, diagnostics, hover) for one language.": [
      {
        "step 1": "Identify and set up the Language Server for Python. Search the web for common Python Language Servers (e.g., `pylsp`, `pyright`). Choose one (recommend `pylsp` for broader plugin support initially). Install the chosen server (`pip install python-lsp-server[all]`). Verify the installation by running its executable from the command line (e.g., `pylsp --help`)."
      },
      {
        "step 2": "Research and select a suitable LSP client library or strategy based on the IDE's implementation language and architecture. If the IDE backend is Python, consider using `python-lsp-client`. If using JavaScript/TypeScript (e.g., Electron), consider `vscode-languageclient`. Install the chosen library. If no suitable library exists or a custom implementation is preferred, outline the structure for a JSON-RPC communication handler."
      },
      {
        "step 3": "Create a new module/service (e.g., `lsp_manager.py` or `lspManager.ts`) responsible for managing LSP server lifecycle and communication. Implement a function `start_lsp_server(language_id: str, project_root: str)` that launches the chosen language server (e.g., `pylsp`) as a subprocess, capturing its stdin and stdout. Store the process handle and communication channels."
      },
      {
        "step 4": "Implement the LSP `initialize` handshake. Within the `lsp_manager` module, after starting the server process, use the chosen client library (or custom JSON-RPC handler) to send the `initialize` request over the server's stdin. Include essential `ClientCapabilities` (e.g., support for `textDocumentSync`, `completionProvider`, `hoverProvider`, `diagnosticProvider`) and the `rootUri` based on the `project_root`. Handle the server's `initialize` response and the subsequent `initialized` notification."
      },
      {
        "step 5": "Implement the `textDocument/didOpen` notification. Create a function `notify_did_open(file_uri: str, language_id: str, content: str)` in the `lsp_manager`. This function should send the `textDocument/didOpen` notification to the relevant running language server, including the document URI, language ID, version (start at 1), and the full text content. Integrate this function call into the IDE's file opening logic."
      },
      {
        "step 6": "Implement the `textDocument/didChange` notification. Create a function `notify_did_change(file_uri: str, updated_content: str, version: int)` in the `lsp_manager`. This function should send the `textDocument/didChange` notification. Determine whether to send full content (`TextDocumentSyncKind.Full`) or incremental changes (`TextDocumentSyncKind.Incremental`) based on server capabilities negotiated during initialization (start with `Full` for simplicity). Integrate this function call into the editor's content modification event handler, ensuring the document version is incremented correctly."
      },
      {
        "step 7": "Implement handling for the `textDocument/publishDiagnostics` notification. In the `lsp_manager`, set up a listener for incoming messages from the LSP server's stdout. Parse JSON-RPC messages. Specifically handle `textDocument/publishDiagnostics` notifications. Store the received diagnostics (URI, range, severity, message) in a data structure accessible by the UI, mapping them by file URI. *Hint: This data structure should allow updating and clearing diagnostics for a file.*"
      },
      {
        "step 8": "Implement the client-side logic for `textDocument/completion` requests. Create a function `request_completion(file_uri: str, line: int, character: int)` in `lsp_manager`. This function should send a `textDocument/completion` request to the server with the document URI and position. Set up a mechanism (e.g., callbacks, promises) to handle the asynchronous `CompletionList` response from the server. *Hint: The actual triggering from the UI and display will be handled in a later step.*"
      },
      {
        "step 9": "Implement the client-side logic for `textDocument/hover` requests. Create a function `request_hover(file_uri: str, line: int, character: int)` in `lsp_manager`. This function should send a `textDocument/hover` request to the server with the document URI and position. Set up a mechanism to handle the asynchronous `Hover` response from the server. *Hint: Triggering and display are separate concerns.*"
      },
      {
        "step 10": "Integrate diagnostics display with the editor UI. Connect the diagnostics data store (from step 7) to the front-end editor component. Use the editor's API to visually represent diagnostics (e.g., add error/warning markers in the gutter, apply squiggly underlines to text ranges, populate a 'Problems' panel). Ensure diagnostics are updated when new notifications arrive and cleared when a file is closed or issues are resolved."
      },
      {
        "step 11": "Integrate completion suggestions with the editor UI. Connect the completion request logic (from step 8) to an appropriate trigger in the editor (e.g., typing specific characters like '.', or manual invocation via a keybinding). When the `CompletionList` response is received, use the editor's API to display the suggestions in a context-aware popup menu near the cursor."
      },
      {
        "step 12": "Integrate hover information with the editor UI. Connect the hover request logic (from step 9) to the editor's mouse hover event. When the `Hover` response is received, use the editor's API to display the returned content (often Markdown) in a tooltip or popup that appears when the user hovers over the relevant code symbol."
      },
      {
        "step 13": "Implement the `textDocument/didClose` notification. Create a function `notify_did_close(file_uri: str)` in the `lsp_manager`. This function should send the `textDocument/didClose` notification to the server. Integrate this function call into the IDE's file closing logic. Also ensure any related UI elements (like diagnostics) for the closed file are cleared."
      },
      {
        "step 14": "Implement LSP server shutdown. Create a function `shutdown_lsp_server(language_id: str)` in `lsp_manager`. This function should send the `shutdown` request to the corresponding server process, wait for the response, and then send the `exit` notification. Ensure the server process is properly terminated. Call this function when the project is closed or the IDE is shutting down."
      },
      {
        "step 15": "Add basic configuration for the LSP server path. Modify the `start_lsp_server` function to retrieve the path to the language server executable (e.g., `pylsp`) from a configuration setting instead of hardcoding it. Provide a default path but allow users to override it in the IDE's settings."
      },
      {
        "step 16": "Write basic integration tests for the `lsp_manager`. Focus on verifying the core lifecycle and communication: test `start_lsp_server`, sending `initialize`, `didOpen`, `didChange`, `didClose`, `shutdown_lsp_server`. Mock the subprocess or, if feasible, test against a real `pylsp` instance. Verify that requests are sent correctly and that handlers for responses/notifications (like diagnostics) are invoked. *Hint: Use a testing framework appropriate for the IDE's language.*"
      }
    ],
    "Task 3.9: Research and integrate a Debug Adapter Protocol (DAP) client library.": [
      {
        "step 1": "Research available Debug Adapter Protocol (DAP) client libraries suitable for integration into a Python-based application. Search package repositories (like PyPI) and general web resources. Prioritize libraries that are actively maintained, well-documented, and potentially support asynchronous operations (asyncio), as this is often beneficial for responsive UIs. Keywords: 'python dap client library', 'debug adapter protocol client python'."
      },
      {
        "step 2": "Based on your research in Step 1, evaluate the top 2-3 candidate libraries. Consider factors like: API clarity, ease of use, completeness of DAP feature support, community activity, licensing, and compatibility with our existing project structure (e.g., async/sync requirements). Document your evaluation findings briefly in a temporary file or comment."
      },
      {
        "step 3": "Select the most suitable DAP client library based on your evaluation. Justify your choice briefly."
      },
      {
        "step 4": "Install the chosen DAP client library as a project dependency. Update the project's requirements file (e.g., `requirements.txt` or `pyproject.toml`) accordingly."
      },
      {
        "step 5": "Create a new directory named `debugger` within the project's source code structure if it doesn't already exist. Inside this directory, create a new file named `dap_client.py`."
      },
      {
        "step 6": "In `debugger/dap_client.py`, implement a class (e.g., `DAPClient`) that encapsulates the core logic for interacting with the chosen DAP library. This class should handle establishing a connection (e.g., via TCP socket or stdio) to a DAP server/adapter."
      },
      {
        "step 7": "Implement methods within the `DAPClient` class to send fundamental DAP requests: `initialize`. Ensure you handle the corresponding responses and the `initialized` event. Store the server capabilities received in the `initialize` response."
      },
      {
        "step 8": "Implement methods within the `DAPClient` class to send `launch` and `attach` requests. These methods should accept debugging configuration parameters (like program path, arguments, etc.). Handle the responses to these requests."
      },
      {
        "step 9": "Implement basic event handling within the `DAPClient` class. Set up handlers or callbacks for common DAP events like `stopped`, `continued`, `exited`, `terminated`, and `output`. Initially, these handlers can simply log the received event data."
      },
      {
        "step 10": "Create a basic test script or use an existing test setup to verify the core functionality. This test should attempt to: \n    a) Instantiate the `DAPClient`. \n    b) Connect to a sample debug adapter (Hint: You might need to install and run a debug adapter like `debugpy` for Python separately for testing purposes: `pip install debugpy`, `python -m debugpy --listen 5678 --wait-for-client my_script.py`). \n    c) Send the `initialize` request and verify a successful response. \n    d) Send a `launch` or `attach` request. \n    e) Optionally, send a `disconnect` request."
      },
      {
        "step 11": "Refactor the `debugger/dap_client.py` code for clarity, error handling (e.g., connection failures, invalid responses), and adherence to project coding standards. Add comments explaining the key parts of the DAP communication flow."
      }
    ],
    "Task 3.10: Design and implement UI components for debugging (breakpoints, call stack, variables, controls).": [
      {
        "step 1": "Design the layout for the debugging UI. Plan where the 'Debug Controls', 'Variables View', 'Call Stack View', and 'Breakpoints View' panels will be located within the main IDE window. Consider creating a dedicated 'Debug Perspective' or a collapsible/dockable panel group. Create the main container widget(s) for this layout using the project's UI framework."
      },
      {
        "step 2": "Implement the 'Debug Controls' UI component. Create a toolbar or panel containing buttons for 'Continue/Resume', 'Step Over', 'Step Into', 'Step Out', and 'Stop/Disconnect'. Use appropriate icons (if available) or text labels. Connect the click events/signals of these buttons to placeholder handler functions that log the intended action."
      },
      {
        "step 3": "Implement the 'Call Stack View' UI component. Use a list or tree view widget. Define a data structure to represent a stack frame (e.g., `{ 'file': 'main.py', 'line': 15, 'function': 'my_func', 'id': 1 }`). Populate the view with static placeholder data conforming to this structure for initial testing and layout purposes."
      },
      {
        "step 4": "Implement the 'Variables View' UI component. Use a tree view or a nested list widget suitable for displaying hierarchical data (variable scopes, names, types, values). Define a data structure for variables (e.g., `{ 'scope': 'Local', 'name': 'my_var', 'type': 'int', 'value': '10', 'children': [...] }`). Implement basic placeholder expansion logic for viewing members of objects or elements of arrays. Populate with static placeholder data."
      },
      {
        "step 5": "Implement the 'Breakpoints View' UI component. Use a list or table view to display active breakpoints. Each entry should show at least the file path and line number. Add functionality (e.g., checkboxes, buttons within the list items) to allow users to enable/disable or remove breakpoints directly from this view. Connect these interactions to placeholder handlers. Populate with static placeholder data."
      },
      {
        "step 6": "Integrate breakpoint functionality into the code editor's gutter. Access the existing code editor component. Add a visual marker (e.g., a red dot) in the gutter area next to the line numbers to indicate a breakpoint. Implement event handling for clicks within the gutter to toggle breakpoints (add/remove). Update the visual marker accordingly and trigger placeholder functions to manage the breakpoint state. *Hint: Consult the documentation of the specific code editor library being used for APIs related to gutter margins, markers, and mouse events.*"
      },
      {
        "step 7": "Assemble the complete Debug UI layout. Integrate the 'Debug Controls', 'Call Stack View', 'Variables View', and 'Breakpoints View' components into the main container(s) designed in Step 1. Ensure they are arranged logically and utilize the UI framework's layout managers (e.g., splitters, docks, grids) for proper resizing and arrangement."
      },
      {
        "step 8": "Define and document data interfaces or models for communication between the future debugger backend and these UI components. Specify the exact structure of data expected by the 'Call Stack', 'Variables', and 'Breakpoints' views. Define how state changes (e.g., debugger paused, running, stopped) will be communicated to update the UI (e.g., enabling/disabling control buttons)."
      },
      {
        "step 9": "Connect UI events to placeholder backend interactions. Ensure that all interactive elements (control buttons, breakpoint toggles in gutter and list view, variable expansion clicks) correctly call their respective placeholder handler functions defined in previous steps or emit appropriate signals/events. Verify that these placeholders log the correct intended action and parameters (e.g., file/line for breakpoints)."
      },
      {
        "step 10": "Apply basic styling to the new debug components. Use CSS or the UI framework's styling mechanism to ensure the debug panels and controls are visually consistent with the overall IDE theme. Focus on readability, clear visual distinction between elements (buttons, views, selected items), and appropriate use of spacing."
      }
    ],
    "Task 3.11: Integrate DAP client with editor for setting/managing breakpoints.": [
      {
        "step 1": "Identify the UI component responsible for displaying code (e.g., the text editor widget) and the associated line number display area. Plan the addition of a 'gutter' area next to the line numbers specifically for breakpoint markers."
      },
      {
        "step 2": "Modify the editor's UI component to include the gutter area. This area should visually align with the text lines. Ensure it's wide enough to display a breakpoint marker (e.g., a circle or dot). \n*Hint:* Depending on your UI toolkit (Tkinter, Qt, etc.), this might involve adding a separate widget (like a `tkinter.Canvas` or `QWidget`) alongside the main text area or utilizing built-in margin/gutter features if available."
      },
      {
        "step 3": "Implement an event handler (e.g., for mouse clicks) on the newly created gutter area. This handler must determine which line number the user clicked on.\n*Hint:* You'll likely need to translate the click's Y-coordinate into a line number, considering the editor's current scroll position and line heights. Log the identified line number for debugging."
      },
      {
        "step 4": "Define or locate the data structure responsible for managing the application's state related to debugging. Add a component to this state to store active breakpoints, organized by file path. A dictionary where keys are file paths (or URIs) and values are sets of line numbers is a common approach.\n*Example State Structure:* `{'file:///path/to/your/code.py': {10, 25}, 'file:///path/to/another.py': {5}}`"
      },
      {
        "step 5": "Implement a function `toggle_breakpoint(file_path: str, line_number: int)`. This function should:\n    1. Access the breakpoint state.\n    2. Check if a breakpoint exists for the given `file_path` and `line_number`.\n    3. If it exists, remove it from the state; otherwise, add it.\n    4. After modifying the state, trigger a UI update for the gutter.\n    5. Trigger the process to notify the debug adapter (DAP) about the change.\n*Hint:* Ensure `file_path` is normalized (e.g., absolute path or URI consistent with DAP expectations)."
      },
      {
        "step 6": "Connect the gutter click event handler (from Step 3) to the `toggle_breakpoint` function (from Step 5). Ensure the currently active file's path and the clicked line number are passed correctly.\n*Hint:* You'll need access to the currently edited file's path within the event handler."
      },
      {
        "step 7": "Implement a function `send_set_breakpoints_request(file_path: str)` that:\n    1. Retrieves all currently set breakpoint line numbers for the given `file_path` from the breakpoint state.\n    2. Constructs the `arguments` object for the DAP `setBreakpoints` request. This typically includes a `source` object (with the `path` or `sourceReference`) and a `breakpoints` array (containing objects like `{line: number}`).\n    3. Uses the existing DAP client instance to send the `setBreakpoints` request with the constructed arguments.\n*Hint:* Consult the DAP specification for the exact structure. Ensure the `file_path` format matches what the specific debug adapter expects (e.g., `file://` URI). Call this function after the state is updated in `toggle_breakpoint`."
      },
      {
        "step 8": "Implement the visual rendering of breakpoints in the gutter. Modify the gutter drawing code to:\n    1. Iterate through the visible lines.\n    2. For each line, check the breakpoint state for the current file.\n    3. If a breakpoint is set for that line, draw a marker (e.g., a red circle) in the gutter next to the line number.\n    4. Ensure the gutter redraws whenever the breakpoint state changes or the editor scrolls/updates.\n*Hint:* Call the gutter redraw function within `toggle_breakpoint` after updating the state."
      },
      {
        "step 9": "Implement handling for the *response* to the `setBreakpoints` request within your DAP client's message handling logic. The response body contains an array of `Breakpoint` objects, which may include information like `verified` status and potentially adjusted line numbers.\n*Hint:* Update your internal breakpoint state based on this response (e.g., store the `verified` status, update line numbers if adjusted by the adapter). Log the received response for debugging."
      },
      {
        "step 10": "Refine the gutter rendering (Step 8) to visually reflect the `verified` status received in the `setBreakpoints` response. For example, draw verified breakpoints as solid red circles and unverified ones as hollow circles or a different color.\n*Hint:* You may need to enhance your breakpoint state (Step 4) to store the verification status alongside the line number."
      },
      {
        "step 11": "[Optional but Recommended] Implement handling for the asynchronous DAP `breakpoint` *event*. This event can be sent by the adapter if breakpoints change for reasons other than a `setBreakpoints` request. The event payload usually includes a `reason` (`changed`, `new`, `removed`) and a `breakpoint` object. Update your internal state and refresh the gutter UI accordingly."
      },
      {
        "step 12": "Thoroughly test the breakpoint functionality: \n    - Set a breakpoint by clicking the gutter. Verify the marker appears and a `setBreakpoints` request is sent.\n    - Unset the breakpoint. Verify the marker disappears and a `setBreakpoints` request (likely with an empty list for that file) is sent.\n    - Set multiple breakpoints in the same file.\n    - Test with a running debug session to see if the debugger honors the breakpoints.\n    - Observe the visual feedback for verified/unverified breakpoints if implemented.\n*Hint:* Use extensive logging in the DAP client communication, state management, and UI event handlers to trace the flow."
      }
    ],
    "Task 3.12: Implement debugger session management (start, stop, step) via DAP for one language.": [
      {
        "step 1": "Identify and ensure availability of the Python debug adapter, `debugpy`. If not installed, add instructions or a mechanism to install it (e.g., `pip install debugpy`). Determine the command-line arguments needed to start `debugpy` in server mode (listening on a port or using stdio). Hint: Search the `debugpy` documentation for server startup options."
      },
      {
        "step 2": "Create a new module/class (e.g., `debugger_client.py`, `DAPClient`) responsible for managing the Debug Adapter Protocol communication. This module will handle sending requests and receiving responses/events. Hint: You'll need mechanisms for JSON-RPC message formatting, sending data (over sockets or process stdio), and receiving/parsing data."
      },
      {
        "step 3": "Implement the core logic within `DAPClient` to start the `debugpy` adapter process using the command identified in Step 1. Establish a communication channel (e.g., TCP socket connection to the specified port, or piping to/from the process's stdin/stdout). Handle potential errors during process startup or connection."
      },
      {
        "step 4": "Implement the DAP `initialize` request sequence within `DAPClient`. This involves sending the `initialize` request with client capabilities (e.g., `clientID`, `adapterID`, `linesStartAt1`, `supportsVariableType`, etc.) and handling the `initialize` response and the subsequent `initialized` event from the adapter."
      },
      {
        "step 5": "Implement the DAP `launch` request logic within `DAPClient`. Define a basic launch configuration (e.g., hardcode the path to a simple sample Python script for testing). Send the `launch` request after receiving the `initialized` event. Handle the `launch` response. Hint: The configuration will include details like the program to debug, arguments, working directory, etc. Refer to DAP specification for `launch` arguments."
      },
      {
        "step 6": "Create placeholder UI elements (buttons) within your IDE's interface for standard debug actions: 'Start Debugging', 'Continue', 'Step Over', 'Step Into', 'Step Out', 'Stop Debugging'. Initially, these buttons may be disabled or have no associated actions."
      },
      {
        "step 7": "Connect the 'Start Debugging' UI element to trigger the debugger session initiation. This should: instantiate `DAPClient`, call the methods to start the adapter process, connect, send `initialize`, and send `launch`. Update UI state (e.g., disable 'Start', enable 'Stop' and step controls) upon successful launch confirmation (often indicated by a `stopped` event after launch)."
      },
      {
        "step 8": "Implement the logic for the 'Continue' button. When clicked, it should send the DAP `continue` request via the `DAPClient`. Ensure the button is only enabled when the debugger is in a 'stopped' state."
      },
      {
        "step 9": "Implement the logic for the 'Step Over' button. When clicked, it should send the DAP `next` request via the `DAPClient`. Ensure the button is only enabled when the debugger is in a 'stopped' state."
      },
      {
        "step 10": "Implement the logic for the 'Step Into' and 'Step Out' buttons. When clicked, they should send the DAP `stepIn` and `stepOut` requests, respectively, via the `DAPClient`. Ensure these buttons are only enabled when the debugger is in a 'stopped' state."
      },
      {
        "step 11": "Implement the logic for the 'Stop Debugging' button. When clicked, it should send the DAP `disconnect` request (with `terminateDebuggee: true` if you want to kill the debugged process) via the `DAPClient`. Afterwards, close the communication channel, ensure the adapter process is terminated, and reset the UI state (e.g., enable 'Start', disable 'Stop' and step controls)."
      },
      {
        "step 12": "Implement handling for the DAP `stopped` event within `DAPClient`. When received, parse the event details (thread ID, reason, source file, line number). Update the IDE's UI to highlight the current line in the editor and enable the 'Continue', 'Step Over', 'Step Into', 'Step Out' controls. Hint: You might need to store the current thread ID for subsequent step/continue requests."
      },
      {
        "step 13": "Implement handling for the DAP `output` event within `DAPClient`. When received, parse the event details (category, output message) and display the output in a dedicated 'Debug Console' panel within the IDE UI."
      },
      {
        "step 14": "Implement handling for the DAP `terminated` event within `DAPClient`. When received, perform cleanup similar to the 'Stop Debugging' action (close connection, ensure adapter process exit, reset UI state). This handles cases where the debugged program finishes execution normally or the adapter terminates unexpectedly."
      },
      {
        "step 15": "Review and refine the debugger session management implementation. Add robust error handling for communication failures, invalid DAP messages, adapter crashes, and unexpected states. Refactor the `DAPClient` and UI integration code for clarity, separation of concerns, and maintainability. Perform manual testing with a sample Python script, covering starting, stepping through code, continuing, stopping, and observing output."
      }
    ],
    "Task 3.13: Design an abstract interface for build/task execution.": [
      {
        "step 1": "Create a new directory `src/core/build` if it doesn't exist. Inside this directory, create a new file named `task_executor_interface.py` (or equivalent based on the project's language)."
      },
      {
        "step 2": "In `task_executor_interface.py`, define an abstract base class (ABC) or interface named `TaskExecutorInterface`. Use the appropriate mechanism for defining abstract interfaces in the project's language (e.g., `abc.ABC` and `@abc.abstractmethod` in Python, `interface` in TypeScript/Java)."
      },
      {
        "step 3": "Define a data structure (e.g., a `dataclass`, `TypedDict`, or simple class) named `TaskDefinition` within the same file. This structure should represent a single discoverable task and include fields like `id` (unique identifier), `name` (user-friendly name), `description` (optional), `command` or `target` (details needed for execution), and potentially `source` (e.g., 'Makefile', 'package.json')."
      },
      {
        "step 4": "Define an abstract method within `TaskExecutorInterface` for discovering available tasks. Name it `discover_tasks`. This method should likely be asynchronous and return a list or dictionary of `TaskDefinition` objects. Consider adding parameters if context (like the project root directory) is needed for discovery. Add docstrings explaining its purpose and return value. Hint: Think about how different build systems (Makefiles, package.json scripts, CMake targets) might be scanned."
      },
      {
        "step 5": "Define data structures to manage task execution. Create `ExecutionContext` (potentially including a cancellation token/mechanism and project context) and `ExecutionReport` (including status - e.g., 'pending', 'running', 'success', 'failure', 'cancelled' - exit code, captured stdout/stderr logs, and start/end times)."
      },
      {
        "step 6": "Define an abstract method within `TaskExecutorInterface` for executing a specific task. Name it `execute_task`. This method must be asynchronous. It should accept the `TaskDefinition` (or its `id`) to execute and an `ExecutionContext`. It should return an `ExecutionReport`. Consider adding parameters for callbacks or event emitters to stream output (stdout/stderr) and report progress/status changes in real-time. Add comprehensive docstrings."
      },
      {
        "step 7": "Define an abstract method within `TaskExecutorInterface` for attempting to cancel a running task. Name it `cancel_task`. It should likely accept a task identifier or execution context identifier. Consider its return type (e.g., boolean indicating if cancellation was initiated, or void). Add docstrings explaining its behavior, noting that cancellation might not be immediate or guaranteed."
      },
      {
        "step 8": "Review the complete `TaskExecutorInterface`, `TaskDefinition`, `ExecutionContext`, and `ExecutionReport`. Ensure clear naming, consistent types, and comprehensive docstrings explaining the purpose of the interface, each method, parameters, return values, and the defined data structures. Ensure the design supports asynchronous operations effectively."
      },
      {
        "step 9": "Add type hints to all methods and data structures within `task_executor_interface.py` to improve code clarity and enable static analysis."
      }
    ],
    "Task 3.14: Implement UI for configuring and triggering build/run tasks.": [
      {
        "step 1": "Define the data model for a build/run task configuration. Create a class or data structure (e.g., `TaskConfig`) that includes fields for: task name (string), command to execute (string), working directory (string, optional, defaults to project root), command-line arguments (list of strings, optional), environment variables (dictionary, optional), and task type (e.g., 'build', 'run', 'test', 'custom'). Add relevant type hints and default values."
      },
      {
        "step 2": "Implement the loading and saving mechanism for task configurations. Define functions `load_tasks(project_path: str) -> List[TaskConfig]` and `save_tasks(project_path: str, tasks: List[TaskConfig])`. Choose a storage format (e.g., JSON) and location within the project structure (e.g., a hidden directory like `.ide/tasks.json` or `.vscode/tasks.json` for compatibility). Handle file creation, reading, writing, and potential errors (e.g., file not found, invalid format). Hint: Use the `json` library for serialization/deserialization."
      },
      {
        "step 3": "Create the main UI component for managing task configurations. This could be a dedicated panel, a section within project settings, or a modal dialog. Use the existing UI framework. Add placeholders for a list view to display tasks and buttons for 'Add', 'Edit', and 'Remove'."
      },
      {
        "step 4": "Implement the display of configured tasks in the UI component created in Step 3. Fetch the tasks using `load_tasks` for the current project and populate the list view. Display at least the task name for each entry. Ensure the list updates if the underlying configuration changes."
      },
      {
        "step 5": "Create a UI form (e.g., a separate modal dialog or an inline editor) for adding and editing task configurations. Include input fields corresponding to the `TaskConfig` model defined in Step 1 (Name, Command, Working Directory, Arguments, Environment Variables, Type selector). Hint: For arguments and environment variables, consider using dynamic list inputs or a simple text area initially."
      },
      {
        "step 6": "Implement the 'Add Task' functionality. Connect the 'Add' button from Step 3 to open the form created in Step 5. When the form is submitted/saved, create a new `TaskConfig` instance, add it to the list of tasks, update the task list UI (Step 4), and persist the changes using the `save_tasks` function (Step 2)."
      },
      {
        "step 7": "Implement the 'Edit Task' functionality. Allow the user to select a task from the list (Step 4). Connect the 'Edit' button (Step 3) to open the form (Step 5), pre-filled with the details of the selected task. When the form is submitted/saved, update the corresponding `TaskConfig` instance in the list, refresh the task list UI, and persist the changes using `save_tasks`."
      },
      {
        "step 8": "Implement the 'Remove Task' functionality. Connect the 'Remove' button (Step 3). When a task is selected and the button is clicked, prompt the user for confirmation. If confirmed, remove the selected `TaskConfig` instance from the list, update the task list UI, and persist the changes using `save_tasks`. Hint: Ensure proper handling of list selection state after removal."
      },
      {
        "step 9": "Design and stub the UI elements for triggering tasks. Choose a method (e.g., a dropdown menu in the main toolbar, entries in a command palette, a 'Run Task...' menu item). Implement the basic UI element(s) but don't connect the triggering logic yet. Hint: Consider how the user will select *which* task to run."
      },
      {
        "step 10": "Populate the task triggering UI (from Step 9) with the available tasks. When the trigger UI element is activated (e.g., dropdown opened, command palette invoked), dynamically fetch the list of task names using `load_tasks` for the current project and display them for selection."
      },
      {
        "step 11": "Define and implement a stub function for task execution. Create a function like `execute_task(task_config: TaskConfig, project_path: str) -> None`. This function will eventually be responsible for spawning processes. For now, implement it as a stub that simply logs or prints the details of the `task_config` it received (e.g., \"Attempting to execute task: [task_name] with command: [command]\")."
      },
      {
        "step 12": "Connect the task triggering UI (Step 10) to the execution stub (Step 11). When a user selects a task to run from the trigger UI, retrieve the corresponding full `TaskConfig` object (you might need to adjust `load_tasks` or maintain the loaded list) and call the `execute_task` stub function, passing the selected `TaskConfig` and the current project path."
      },
      {
        "step 13": "Create a basic UI component to display output from executed tasks. This could be an integrated terminal view, an 'Output' panel with a text area, or similar. Add this component to the main IDE window layout. Hint: Ensure it can be cleared and can append text."
      },
      {
        "step 14": "Modify the `execute_task` stub function (Step 11) to simulate sending output to the Task Output UI (Step 13). Instead of just logging to console, make the stub function append some placeholder text (e.g., `Executing task '{task_config.name}'...\nCommand: {task_config.command}\n(Stub execution - no actual process run)\nTask finished.`) to the output panel."
      },
      {
        "step 15": "Review and refactor the newly implemented UI code for task configuration, triggering, and output display. Ensure consistency with the existing UI style, add comments where necessary, and check for basic usability (e.g., clear labels, logical flow). Document the structure of the `.ide/tasks.json` (or chosen) file format."
      }
    ],
    "Task 3.15: Integrate a terminal or output panel for displaying build/task output.": [
      {
        "step 1": "Identify the appropriate location within the IDE's main window layout for an output panel. This panel will display text output from build processes, linters, and potentially other integrated tools. Consider placing it at the bottom, possibly as a dockable or tabbed widget."
      },
      {
        "step 2": "Select and implement the UI widget for the output panel using the project's chosen GUI framework (e.g., `QTextEdit` in PyQt/PySide, `Text` in Tkinter, a `<div>` with `pre` tag in Electron/Web). Ensure it's read-only for the user but programmatically updatable. Add this widget to the main window layout identified in the previous step. Give it a clear object name or ID (e.g., `output_panel`)."
      },
      {
        "step 3": "Create helper functions or methods to append text to the output panel. Design separate functions or parameters to handle standard output (`stdout`) and standard error (`stderr`), potentially using different colors or styles to distinguish them (e.g., red for errors). Ensure these functions handle potential multi-threading issues if output comes from background threads (e.g., use thread-safe update mechanisms provided by the GUI framework like Qt Signals/Slots)."
      },
      {
        "step 4": "Refactor the existing build/task execution logic (developed in previous tasks, likely involving process execution like Python's `subprocess` or Node.js's `child_process`). Modify it to capture `stdout` and `stderr` streams from the executed processes in real-time."
      },
      {
        "step 5": "Integrate the output capturing mechanism with the output panel UI. As chunks of data are received from the process's `stdout` and `stderr`, use the helper functions created in Step 3 to append the text to the `output_panel` widget. Hint: This often requires reading the streams asynchronously or in separate threads to avoid blocking the IDE's main event loop. Look into non-blocking reads or using threads/asyncio with callbacks/signals."
      },
      {
        "step 6": "Implement basic controls for the output panel. Add a 'Clear' button to empty the panel's content. Consider adding functionality to automatically scroll to the bottom as new output arrives. Hint: Most text widgets have methods to programmatically scroll (e.g., `ensureCursorVisible`, `see(END)`)."
      },
      {
        "step 7": "Test the integration thoroughly. Trigger a build process or run a simple command (e.g., `ls -l`, `dir`, `python --version`) through the IDE's task execution system. Verify that both standard output and standard error are correctly captured and displayed in the output panel in real-time, without freezing the UI. Test the 'Clear' button functionality."
      },
      {
        "step 8": "Consider adding visual cues to indicate when a task starts and finishes. For example, print a 'Task Started: [Task Name]' message before execution and 'Task Finished: [Task Name] with exit code [Code]' after completion, potentially including timing information."
      }
    ],
    "Task 3.16: Implement basic parsing of build output to identify and display errors/warnings.": [
      {
        "step 1": "Define a data structure (e.g., a class or dataclass named `BuildDiagnostic`) to represent a single error or warning parsed from build output. It should include fields for: `file_path` (string), `line_number` (integer), `column_number` (integer, optional), `severity` (e.g., 'error', 'warning'), and `message` (string)."
      },
      {
        "step 2": "Create a new module (e.g., `build_parser.py`) and define a class `BuildOutputParser` within it. This class will encapsulate the logic for parsing build output."
      },
      {
        "step 3": "Research common error and warning formats produced by build tools (e.g., GCC, Clang, common linters). **Hint:** Search the web for 'gcc error message format regex', 'clang warning message format regex'. Define at least one regular expression pattern within `BuildOutputParser` to capture file path, line number, column number (if available), severity (error/warning), and the message for a common format like GCC/Clang (e.g., `filename:line:column: type: message`). Store these patterns as class attributes or constants."
      },
      {
        "step 4": "Implement a method `parse(self, build_output: str) -> list[BuildDiagnostic]` within the `BuildOutputParser` class. This method should take the raw build output (stdout/stderr combined or separately) as a string, iterate through its lines, apply the defined regex patterns, and return a list of `BuildDiagnostic` objects for all matched errors and warnings. Handle potential `None` matches gracefully."
      },
      {
        "step 5": "Refine the `parse` method to handle potential multi-line error or warning messages if the chosen format requires it. **Hint:** This might involve looking ahead or maintaining state between lines if a pattern indicates continuation."
      },
      {
        "step 6": "Integrate the `BuildOutputParser` into the existing build execution logic (developed in Task 3.15). After capturing the stdout and stderr from the build process, instantiate `BuildOutputParser` and call its `parse` method, passing the captured output. Store the resulting list of `BuildDiagnostic` objects."
      },
      {
        "step 7": "Modify the application's state management or signaling mechanism to store or emit the list of `BuildDiagnostic` objects obtained from the parser. **Hint:** This could involve updating a central 'problems' model/store or emitting a signal like `build_diagnostics_updated(diagnostics: list[BuildDiagnostic])`."
      },
      {
        "step 8": "Update the relevant UI component (e.g., an 'Output Panel', 'Problems View', or similar, established in previous phases) to listen for updates to the build diagnostics. When new diagnostics are received, clear the previous ones and display the new list. For each diagnostic, display at least the file name, line number, and message. **Hint:** Ensure the display is user-friendly, perhaps grouping by file."
      },
      {
        "step 9": "Write unit tests for the `BuildOutputParser.parse` method in a separate test file (e.g., `test_build_parser.py`). Include test cases with: \n- Sample output with no errors/warnings.\n- Sample output with one error.\n- Sample output with multiple errors/warnings.\n- Sample output with multi-line messages (if supported).\n- Sample output that *shouldn't* match the patterns.\n**Hint:** Use the `unittest` or `pytest` framework."
      }
    ]
  },
  "Phase 4: Advanced Feature Development (Refactoring, VCS Integration, Extensibility)": {
    "Task 4.1: Design and implement core refactoring engine (e.g., AST traversal, modification)": [
      {
        "step 1": "Create a new directory named `refactoring_engine` within the project's core modules directory. Inside this directory, create an `__init__.py` file and a file named `ast_handler.py`."
      },
      {
        "step 2": "In `ast_handler.py`, import the `ast` module. Implement a function `parse_to_ast(source_code: str) -> ast.AST | None` that takes source code as input, parses it into a Python Abstract Syntax Tree using `ast.parse()`, and returns the AST object. Include error handling for `SyntaxError` and return `None` or raise a custom exception if parsing fails. Add basic logging for errors. Hint: Ensure you are targeting the AST structure for the language supported by the IDE (assuming Python for now, confirm from project context if necessary)."
      },
      {
        "step 3": "Install a library for converting AST back to source code. Search for suitable libraries like `astor` or check the standard library's `ast.unparse` (available in recent Python versions). Add the chosen library to the project's dependencies (e.g., `requirements.txt`). In `ast_handler.py`, implement a function `unparse_ast(tree: ast.AST) -> str` that takes an AST object and converts it back into formatted source code using the chosen library/method."
      },
      {
        "step 4": "Create a new file `ast_navigator.py` within the `refactoring_engine` directory. Implement a base class `NodeFinder` inheriting from `ast.NodeVisitor`. This class should provide utilities to find specific nodes based on criteria, such as line number and column offset. Hint: You'll need to store positional information (line/col) during traversal and potentially implement methods like `find_node_at(position)`."
      },
      {
        "step 5": "Create a new file `ast_modifier.py` within the `refactoring_engine` directory. Implement a base class `NodeTransformerBase` inheriting from `ast.NodeTransformer`. This class will serve as a foundation for specific refactoring transformations."
      },
      {
        "step 6": "Begin implementing the 'Rename Variable' refactoring. In `ast_navigator.py`, create a specific visitor class inheriting from `NodeFinder` (or `ast.NodeVisitor`) designed to find all occurrences (definitions and uses) of a variable identifier given a specific source code position (line, column). Hint: Consider basic scope analysis; initially, focus on finding identifiers with the same name within the relevant function or module scope. You might need to enhance scope analysis later."
      },
      {
        "step 7": "In `ast_modifier.py`, create a specific transformer class `RenameVariableTransformer` inheriting from `NodeTransformerBase` (or `ast.NodeTransformer`). This transformer should accept the target node(s) identified in the previous step (or the variable's old name and scope info) and the new variable name. Override `visit_Name` (and potentially other relevant `visit_` methods) to replace the identifier of the target variable nodes with the new name. Hint: Be careful only to rename the intended variable, respecting scope."
      },
      {
        "step 8": "Create a main orchestrator file, e.g., `core.py`, within the `refactoring_engine` directory. Define a function `rename_variable(source_code: str, position: tuple[int, int], new_name: str) -> str | None`. This function should: \n1. Parse the `source_code` using `parse_to_ast`. \n2. Use the navigator (from step 6) to identify the variable and its occurrences at the given `position`. \n3. Instantiate and use the `RenameVariableTransformer` (from step 7) to modify the AST. \n4. Unparse the modified AST back to source code using `unparse_ast`. \n5. Return the modified code or `None`/raise an exception if the refactoring cannot be performed (e.g., variable not found, parse error)."
      },
      {
        "step 9": "Create a `tests` subdirectory within `refactoring_engine`. Write unit tests for the `rename_variable` function using the `unittest` or `pytest` framework. Cover scenarios such as: \n- Renaming a local variable within a function. \n- Renaming a function parameter. \n- Renaming a global variable. \n- Cases where the variable name is shadowed. \n- Invalid input (e.g., position doesn't point to a variable). \n- Code with syntax errors. \nHint: Use sample code snippets as input for your tests."
      },
      {
        "step 10": "Refactor the implemented refactoring engine components (`ast_handler.py`, `ast_navigator.py`, `ast_modifier.py`, `core.py`) for clarity, efficiency, and extensibility. Add docstrings and type hints. Ensure the design allows for adding more refactoring operations (like 'Extract Method', 'Inline Variable') in the future by reusing the AST handling, traversal, and modification infrastructure."
      }
    ],
    "Task 4.2: Implement 'Rename' refactoring (variables, functions, classes, files)": [
      {
        "step 1": "Define the core requirements for the 'Rename' refactoring feature. Specify that it should initially support renaming local variables, function/method names, and class names within the currently active Python file. Also, include support for renaming the file itself via the file explorer."
      },
      {
        "step 2": "Design the user interaction flow. Propose triggering the symbol rename via a context menu option ('Refactor > Rename...') or a keyboard shortcut (e.g., F2) when the cursor is on an identifier in the code editor. For file renaming, propose a context menu option in the file explorer. Both actions should open a dialog box prompting the user for the new name."
      },
      {
        "step 3": "Implement the UI dialog for entering the new name. Use the existing UI toolkit. The dialog should take the current name as input (for display) and provide a text field for the new name, along with 'OK' and 'Cancel' buttons. Include basic validation for the new name (e.g., ensure it's a valid Python identifier for symbol renaming)."
      },
      {
        "step 4": "Integrate the trigger mechanism for symbol renaming in the code editor. Add the 'Refactor > Rename...' option to the editor's context menu and optionally bind the F2 key. When triggered, get the identifier under the cursor/selection and open the rename dialog created in the previous step."
      },
      {
        "step 5": "Implement the core logic for identifying the symbol at a given cursor position within a Python file. Use Python's `ast` module to parse the file content. Write a function that takes the source code and cursor position (line, column) and returns information about the symbol at that position, including its name, type (variable, function, class), and its scope definition node in the AST. Hint: You might need to traverse the AST and check node positions against the cursor position."
      },
      {
        "step 6": "Implement the logic to find all occurrences of the identified symbol within the *same file* using the AST. Write a function that takes the AST and the symbol information (from Step 5) and returns a list of all AST nodes corresponding to references of that symbol within its scope. Be mindful of variable shadowing and different scopes. Hint: Use `ast.NodeVisitor` to traverse the tree and compare identifiers, considering scoping rules."
      },
      {
        "step 7": "Implement the text replacement logic. Based on the list of AST nodes representing occurrences (from Step 6), calculate the exact start/end positions (line, column) in the source code for each occurrence. Generate a list of text edits (replace range [start, end] with new_name). Apply these edits to the editor's buffer. Ensure edits are applied correctly, possibly from bottom to top to avoid position shifting issues, or use the editor component's API for multi-cursor edits if available."
      },
      {
        "step 8": "Connect the UI and the refactoring logic for symbol renaming. When the user confirms the new name in the dialog (from Step 3), call the functions developed in Steps 5, 6, and 7 to perform the rename operation within the current file. Handle potential errors (e.g., symbol not found, invalid name)."
      },
      {
        "step 9": "Write unit tests for the single-file symbol renaming functionality. Cover renaming local variables, function arguments, function names, class names, and methods. Include tests for different scopes and potential edge cases (e.g., renaming a variable whose name appears as a substring elsewhere). Use sample Python code snippets for testing."
      },
      {
        "step 10": "Implement the file renaming functionality. Add a 'Rename...' context menu option to the file explorer component. When triggered, show the rename dialog (from Step 3) pre-filled with the current filename. Upon confirmation, use `os.rename` or `pathlib.Path.rename` to rename the file on the filesystem. Update the file explorer view."
      },
      {
        "step 11": "Implement basic import statement updating for file renames (Python specific). After successfully renaming a Python file (e.g., `old_name.py` to `new_name.py`), attempt to find and update simple import statements in other Python files within the project directory (e.g., `import old_name` -> `import new_name`, `from old_name import foo` -> `from new_name import foo`). This can be complex; start with simple cases. Hint: Use text search or AST parsing across project files. Warn the user that complex cases might require manual updates."
      },
      {
        "step 12": "Integrate the rename operations with the IDE's undo/redo system. Ensure that both symbol renames (which might involve multiple text edits) and file renames (including any automatic import updates) can be undone and redone as a single atomic action."
      },
      {
        "step 13": "Review and refine the 'Rename' feature. Test thoroughly within the IDE environment. Add user feedback mechanisms (e.g., status bar messages for success or failure). Consider adding a preview panel showing intended changes before applying, though this can be deferred."
      }
    ],
    "Task 4.3: Implement 'Extract Method/Function' refactoring": [
      {
        "step 1": "Define the scope and requirements for the 'Extract Method/Function' refactoring feature. Specify that the initial implementation will target Python code. Identify and list the necessary Python libraries for AST manipulation, such as the built-in `ast` module, and potentially `astor` or `astunparse` for reliable code generation from modified ASTs. If `astor` or `astunparse` are needed, ensure they are added to the project's dependencies."
      },
      {
        "step 2": "Integrate a trigger mechanism into the IDE's UI for the refactoring. Add a menu item (e.g., under 'Refactor') and/or a context menu option in the code editor labeled 'Extract Function/Method'. This action should capture the start and end position (line, column) of the user's text selection in the active editor and the full content of the corresponding file."
      },
      {
        "step 3": "Create the main orchestrator function for the refactoring logic, e.g., `perform_extract_refactoring(file_content: str, selection_start: tuple, selection_end: tuple, new_name: str) -> str`. This function will take the file content, selection range, and the desired name for the new function/method, and return the modified file content or raise an error. Implement basic error handling structure within this function."
      },
      {
        "step 4": "Implement AST parsing within `perform_extract_refactoring`. Use Python's `ast` module to parse the `file_content` string into an AST. Include error handling for `SyntaxError` during parsing."
      },
      {
        "step 5": "Develop logic to accurately identify the AST node(s) corresponding to the user's text selection. Traverse the parsed AST (from step 4) and compare node line/column information (`lineno`, `col_offset`, `end_lineno`, `end_col_offset`) with the provided `selection_start` and `selection_end`. Handle cases where the selection might not perfectly align with node boundaries (initially, you might choose to report an error for partial selections)."
      },
      {
        "step 6": "Implement the analysis to determine input parameters for the extracted function/method. Traverse the AST (specifically the containing scope of the selected nodes) to find variables that are defined *before* the selection but used *within* the selected nodes. Hint: Use `ast.NodeVisitor` to track variable definitions and uses within different scopes. Store these identified variables as the potential parameters."
      },
      {
        "step 7": "Implement the analysis to determine the return value(s) of the extracted function/method. Analyze variables that are assigned a value *within* the selected nodes and are used *after* the selection in the original scope. For simplicity, initially target support for a single return value. If multiple such variables exist, or if the selection modifies mutable objects passed as parameters, report an error or refine the logic later. Identify if the selection inherently contains `return` statements (initially, disallow selections containing `return`, `yield`, `break`, or `continue`)."
      },
      {
        "step 8": "Determine the context of the extraction: is it within a class method or a regular function/module scope? Analyze the parent nodes of the selected AST nodes. If the selection is inside an `ast.FunctionDef` that is itself inside an `ast.ClassDef`, it's likely a method extraction. This affects whether `self` needs to be handled as the first parameter."
      },
      {
        "step 9": "Implement the generation of the AST for the new function or method definition (`ast.FunctionDef`). Use the `new_name`, the parameters identified in step 6 (plus `self` if applicable from step 8), and the selected AST nodes (step 5) as the function body. If a return value was identified in step 7, add an `ast.Return` node at the end of the new function's body."
      },
      {
        "step 10": "Implement the generation of the AST for the call site that will replace the original selection. Create an `ast.Call` node using the `new_name`, passing the necessary variables (identified in step 6) as arguments. If the new function returns a value (step 7), wrap the call in an `ast.Assign` node to assign the result to the appropriate variable."
      },
      {
        "step 11": "Implement the transformation of the original AST. Use `ast.NodeTransformer` to visit the original AST. When the transformer encounters the nodes corresponding to the original selection, it should replace them with the call site AST generated in step 10. The transformer should also insert the new function/method definition AST (from step 9) into an appropriate location (e.g., in the class body for a method, or at the module/enclosing function level before the call site for a function)."
      },
      {
        "step 12": "Convert the modified AST (from step 11) back into Python source code. Use a library like `astor` or `astunparse` for robustness (`code = astor.to_source(modified_ast)` or `code = astunparse.unparse(modified_ast)`). Ensure the chosen library is installed and imported. Handle potential errors during this unparsing step. Return this generated code string from `perform_extract_refactoring`."
      },
      {
        "step 13": "Enhance the UI interaction. Before calling `perform_extract_refactoring`, display a dialog box prompting the user to enter the desired name for the new function/method. Pass this name to the refactoring function. After the function returns successfully, update the content of the code editor with the returned modified code. If the refactoring function raises an error, display an informative error message to the user instead of modifying the code."
      },
      {
        "step 14": "Implement specific error checking within the refactoring logic. Add checks and raise informative errors for scenarios such as: selection doesn't correspond to a valid block of statements, selection contains `return`, `yield`, `break`, or `continue`, ambiguity in determining parameters or return values, attempting to extract code across incompatible scopes."
      },
      {
        "step 15": "Write comprehensive unit tests for the core refactoring logic (`perform_extract_refactoring` or its sub-components). Create test cases using sample Python code snippets to cover: function extraction with no parameters/return, extraction with parameters, extraction with return value, method extraction (handling `self`), extraction within nested scopes, and expected failure cases (invalid selections, complex control flow)."
      },
      {
        "step 16": "Review and refactor the implemented code for the 'Extract Method/Function' feature. Focus on improving clarity, robustness, error handling, and adherence to Python best practices. Consider edge cases like comments and formatting preservation (though perfect preservation might be hard, aim for syntactic correctness and basic readability)."
      }
    ],
    "Task 4.4: Implement 'Extract Variable/Constant' refactoring": [
      {
        "step 1": "Define the user interface trigger for the 'Extract Variable/Constant' refactoring. Add a menu item under a 'Refactor' category in the editor's context menu (right-click menu). Label it 'Extract Variable/Constant...'. Ensure this menu item is only enabled when there is a text selection in the editor."
      },
      {
        "step 2": "Implement the event handler for the 'Extract Variable/Constant...' menu item. This handler should: \n1. Get the active text editor instance.\n2. Retrieve the currently selected text range (start line, start column, end line, end column).\n3. Get the full content of the active editor.\n4. If no text is selected or the content is empty, display an informative message to the user and abort."
      },
      {
        "step 3": "Integrate Abstract Syntax Tree (AST) parsing. Within the event handler, parse the editor's content into an AST. \n*   **Hint:** For Python, use the built-in `ast` module (`ast.parse(source_code)`). \n*   Implement error handling for `SyntaxError` during parsing. If parsing fails, display a message like 'Cannot refactor: Code contains syntax errors.' and abort."
      },
      {
        "step 4": "Implement AST node identification based on selection. Create a function `find_node_for_selection(ast_root, start_pos, end_pos)` where `pos` is `(line, column)`. This function should traverse the AST and find the smallest node that precisely encompasses the selected text range. \n*   **Hint:** You'll need accurate line/column information for AST nodes (`node.lineno`, `node.col_offset`, `node.end_lineno`, `node.end_col_offset`). Ensure your AST parser populates these (Python's `ast` module does this by default).\n*   Validate that the found node represents an *expression* (e.g., `ast.Call`, `ast.BinOp`, `ast.Constant`, `ast.Attribute`, `ast.Subscript`, etc.), not a statement or declaration. If the selection doesn't map cleanly to a single expression, show an error ('Invalid selection: Please select a complete expression.') and abort."
      },
      {
        "step 5": "Implement scope determination logic. Create a function `find_insertion_scope(ast_root, target_node)` that finds the appropriate scope (e.g., `ast.FunctionDef`, `ast.AsyncFunctionDef`, `ast.ClassDef`, module level) and the specific statement *before* which the new variable declaration should be inserted. \n*   **Hint:** The declaration should typically be placed just before the first statement containing the expression within the narrowest enclosing block or function. Use `ast.walk` or a custom visitor to find the parent scope and the relevant statement list."
      },
      {
        "step 6": "Implement user input for the new variable/constant name. After successfully identifying the target node and scope, prompt the user to enter a name for the new variable/constant. \n*   **Hint:** Use a simple input dialog provided by your UI framework. You could pre-populate it with a suggested name based on the expression type (e.g., if extracting `self.get_value()`, suggest `value`). Add validation for the entered name (e.g., valid identifier). Allow the user to specify if it should be a CONSTANT (e.g., via a checkbox or naming convention)."
      },
      {
        "step 7": "Implement the core AST transformation using `ast.NodeTransformer`. Create a class inheriting from `ast.NodeTransformer` that:\n1. Takes the target expression node to replace, the new variable name, and potentially flags for replacing all occurrences and constant extraction.\n2. Overrides `visit_` methods for relevant expression types.\n3. When it encounters the *first* instance of the target expression node (matching by structure/location), it replaces it with an `ast.Name(id=new_name, ctx=ast.Load())` node.\n4. Store the original expression node that was replaced (this will become the value in the assignment)."
      },
      {
        "step 8": "Refine the AST transformation to insert the declaration. After the `NodeTransformer` has replaced the expression(s), manually modify the AST:\n1. Create the new assignment node: `assign_node = ast.Assign(targets=[ast.Name(id=new_name, ctx=ast.Store())], value=original_expression_node)`.\n2. Find the statement list identified in Step 5 (scope determination).\n3. Find the index of the statement before which the declaration should be inserted.\n4. Insert `assign_node` into the statement list at the calculated index.\n*   **Hint:** Handle module-level and class-level constants appropriately (e.g., insert near the top, use `UPPER_CASE` naming based on user input from Step 6)."
      },
      {
        "step 9": "(Optional but Recommended) Enhance the `NodeTransformer` (from Step 7) to find and replace *all* identical occurrences of the expression within the determined scope. \n*   **Hint:** Before transforming, use `ast.NodeVisitor` to find all nodes within the scope that are structurally identical to the selected expression node. `ast.dump(node)` can be helpful for comparing node structures. Keep track of their locations. The `NodeTransformer` should then replace all these identified nodes."
      },
      {
        "step 10": "Implement code generation from the modified AST. Use a library to convert the transformed AST back into source code string. \n*   **Hint:** Install and use the `astor` library (`pip install astor`) via `astor.to_source(modified_ast)`. Handle potential errors during code generation."
      },
      {
        "step 11": "Update the editor content. Replace the entire content of the text editor with the newly generated source code. \n*   **Hint:** Preserve the user's scroll position if possible. Consider placing the cursor at the end of the newly inserted variable declaration line for a better user experience."
      },
      {
        "step 12": "Implement comprehensive error handling and user feedback. Review all steps and add `try...except` blocks where necessary (parsing, node finding, transformation, code generation). Provide clear, user-friendly error messages via status bar updates or dialog boxes for scenarios like invalid selections, syntax errors, inability to find scope, or transformation failures."
      },
      {
        "step 13": "Write unit tests for the refactoring logic. Create test cases specifically for:\n1. `find_node_for_selection` with various selections (exact expression, partial, invalid).\n2. `find_insertion_scope` for different code structures (functions, classes, module level).\n3. The AST transformation logic (Steps 7, 8, 9) with simple and complex expressions, testing both single and multiple replacements, and constant extraction.\n*   **Hint:** Use Python's `unittest` or `pytest`. Prepare input code strings, parse them with `ast`, simulate selections, run your functions/transformer, and compare the resulting AST (`ast.dump`) or generated code (`astor.to_source`) against expected outputs."
      }
    ],
    "Task 4.5: Integrate refactoring actions into editor UI (context menus, shortcuts)": [
      {
        "step 1": "Identify the main text editor widget component in the IDE's UI code. Also, locate the module(s) containing the refactoring functions (e.g., `rename_symbol`, `extract_method`) implemented in the previous task (Task 4.4)."
      },
      {
        "step 2": "Implement a right-click context menu for the main text editor widget. Ensure the menu appears at the cursor's location on right-click. Hint: Depending on your UI framework (Tkinter, PyQt, etc.), this involves binding to a right-click event (e.g., `<Button-3>`, `contextMenuEvent`) and creating/displaying a menu object."
      },
      {
        "step 3": "Add a 'Rename' action to the editor's context menu. Initially, connect this action to a placeholder function that prints 'Rename action triggered'."
      },
      {
        "step 4": "Implement the logic to determine the context for the 'Rename' action. When the context menu is about to be shown or when 'Rename' is selected, determine the current file path, the cursor position (line, column), and attempt to identify the symbol/token under the cursor. Hint: Use the editor widget's API to get position and potentially leverage the language server (if integrated) or basic text analysis to find the symbol boundaries."
      },
      {
        "step 5": "Connect the 'Rename' context menu action to the actual refactoring logic. When triggered: \n    a. Get the context (file path, position) as implemented in the previous step.\n    b. Prompt the user for the new name using a simple input dialog. \n    c. If a new name is provided, call the previously implemented `rename_symbol` function with the necessary parameters.\n    d. Handle potential errors returned by the refactoring function (e.g., display an error message).\n    e. If the refactoring is successful, update the content of the editor widget to reflect the changes. Hint: Reloading the file or applying the specific text changes might be necessary."
      },
      {
        "step 6": "Add an 'Extract Method/Function' action to the editor's context menu, placed below 'Rename'. Connect it to a placeholder function initially."
      },
      {
        "step 7": "Implement the logic to determine the context for the 'Extract Method/Function' action. This involves getting the current file path and the start and end positions of the currently selected text in the editor. Hint: Use the editor widget's API for retrieving selection range."
      },
      {
        "step 8": "Connect the 'Extract Method/Function' context menu action to the actual refactoring logic. When triggered:\n    a. Get the context (file path, selection range) as implemented in the previous step.\n    b. Prompt the user for the new method/function name using an input dialog.\n    c. If a name is provided, call the previously implemented `extract_method` function.\n    d. Handle errors and update the editor content upon success, similar to the 'Rename' action."
      },
      {
        "step 9": "Implement context sensitivity for the menu items. Modify the context menu creation logic so that 'Rename' is disabled if the cursor is not positioned on a recognizable identifier, and 'Extract Method/Function' is disabled if no text is selected. Hint: Perform the context checks (from steps 4 & 7) *before* showing the menu and set the state of menu items accordingly."
      },
      {
        "step 10": "Define standard keyboard shortcuts for the refactoring actions. For example, map F2 to 'Rename' and Ctrl+Alt+M (or a similar common shortcut) to 'Extract Method/Function'."
      },
      {
        "step 11": "Implement event handlers for these keyboard shortcuts within the editor widget or the main application window. These handlers should trigger the same underlying logic used by the context menu actions (steps 5 and 8), ensuring they respect the same context sensitivity (i.e., the shortcut should do nothing or show an error if the action is not applicable in the current context)."
      },
      {
        "step 12": "Refine user feedback. Ensure clear messages are displayed in a status bar or dialog box for successful refactorings, failures (with reasons if possible), and when an action cannot be performed due to context (e.g., 'Cannot rename: No identifier selected.')."
      },
      {
        "step 13": "Manually test the integration: \n    a. Right-click on whitespace -> Refactoring options should be disabled.\n    b. Right-click on a variable -> 'Rename' should be enabled.\n    c. Select code -> 'Extract Method' should be enabled.\n    d. Trigger 'Rename' via menu and shortcut (F2), enter a new name, verify change.\n    e. Trigger 'Extract Method' via menu and shortcut (Ctrl+Alt+M), enter a name, verify change.\n    f. Test error conditions (e.g., invalid new name, refactoring conflicts)."
      }
    ],
    "Task 4.6: Add preview functionality for refactoring changes": [
      {
        "step 1": "Modify existing refactoring functions (e.g., `rename_symbol`, `extract_variable`) to return a data structure representing the proposed changes instead of applying them directly. This structure should detail the file path, original code segment (start/end position), and the proposed new code segment for each change. Define a clear format, like a list of dictionaries or a custom class (e.g., `RefactoringChange`)."
      },
      {
        "step 2": "Research and select a suitable Python library for generating text differences (diffs). Integrate basic diff generation logic using the chosen library (Python's built-in `difflib` is a good starting point). Write a helper function `generate_diff(original_content: str, modified_content: str) -> str` that returns a textual representation of the differences."
      },
      {
        "step 3": "Design and implement a new UI component (e.g., a modal dialog, a dedicated panel within the IDE) specifically for displaying the refactoring preview. This component should initially include areas to display 'before' and 'after' code snippets or a unified diff view, along with 'Apply' and 'Cancel' buttons."
      },
      {
        "step 4": "Implement the logic within the preview UI component to process the list of `RefactoringChange` objects. For each affected file, read its current content. Simulate the application of the changes in memory to generate the 'modified' version of the code. Handle cases with multiple changes within the same file carefully to ensure correct offsets."
      },
      {
        "step 5": "Use the `generate_diff` function (from Step 2) with the original and simulated modified content (from Step 4) to create the diff output. Display this output clearly within the preview UI component created in Step 3. Consider using formatting (colors, bolding) or a specialized diff view widget if your UI framework supports it, to improve readability."
      },
      {
        "step 6": "Modify the existing UI triggers for refactoring actions (e.g., menu items, keyboard shortcuts, context menus). Instead of directly applying the refactoring, these triggers should now: 1. Call the refactoring logic to get the list of `RefactoringChange` objects. 2. If changes are proposed, instantiate and show the refactoring preview UI component, passing the changes to it. 3. If no changes are proposed, inform the user."
      },
      {
        "step 7": "Implement the functionality for the 'Cancel' button in the preview UI component. It should simply close the preview window without applying any changes."
      },
      {
        "step 8": "Implement the functionality for the 'Apply' button. Create a new function `apply_refactoring_changes(changes: list)` that takes the list of `RefactoringChange` objects and applies them to the actual editor buffers and/or files on disk. Ensure changes are applied correctly, considering potential offset shifts if multiple edits occur in one file (applying changes from bottom to top or end to start is often safer). Update the relevant editor views after applying changes. Connect the 'Apply' button to call this function and then close the preview window."
      },
      {
        "step 9": "Write unit tests for the `generate_diff` helper function and the logic that simulates the application of changes in memory (Step 4). Write integration tests or manual test procedures to verify the end-to-end refactoring preview workflow: triggering refactoring, viewing the preview, canceling, and applying changes for various refactoring types."
      },
      {
        "step 10": "Update internal developer documentation and any user-facing guides to reflect the addition of the refactoring preview feature, explaining its usage and benefits."
      }
    ],
    "Task 4.7: Implement backend integration for Git operations (status, diff, log, commit, add)": [
      {
        "step 1": "Identify the backend language and framework being used (e.g., Python/Flask, Node.js/Express). Based on the language, select and install a suitable library for programmatic Git interaction. For Python, consider 'GitPython'. For Node.js, consider 'simple-git' or 'nodegit'. Update the project's dependency file (e.g., 'requirements.txt', 'package.json') and install the chosen library. Ensure Git is installed on the system where the backend runs."
      },
      {
        "step 2": "Create a new backend service or module dedicated to Git operations (e.g., 'git_service.py', 'gitService.js'). This module will encapsulate all logic related to interacting with the Git repository associated with the currently open project in the IDE."
      },
      {
        "step 3": "Define and implement a backend API endpoint (e.g., `POST /api/git/status`) that takes the project path as input. Inside this endpoint, use the installed Git library to execute the equivalent of `git status --porcelain` within the specified project directory. Parse the output to create a structured JSON response detailing untracked, modified, and staged files. Handle potential errors, such as the path not being a Git repository."
      },
      {
        "step 4": "Define and implement a backend API endpoint (e.g., `POST /api/git/diff`) that takes the project path and optionally a file path and a boolean indicating whether to diff staged changes. Use the Git library to execute `git diff [file]` or `git diff --staged [file]`. Return the diff output as a string within a JSON response. Handle errors, including invalid file paths."
      },
      {
        "step 5": "Define and implement a backend API endpoint (e.g., `POST /api/git/log`) that takes the project path and optional parameters for limiting the number of commits (e.g., `?limit=50`). Use the Git library to fetch the commit history (`git log`). Format the log data into a JSON array of objects, where each object represents a commit and includes details like hash, author, date, and commit message. Handle errors gracefully."
      },
      {
        "step 6": "Define and implement a backend API endpoint (e.g., `POST /api/git/add`) that takes the project path and a list of file paths to stage. Use the Git library to execute `git add <file1> <file2> ...` for the specified files within the project directory. Return a success status or error details in the JSON response. Ensure proper handling of file paths and potential Git errors."
      },
      {
        "step 7": "Define and implement a backend API endpoint (e.g., `POST /api/git/commit`) that takes the project path and a commit message. Use the Git library to execute `git commit -m '<message>'`. Consider how to handle user configuration for author name/email if needed (perhaps retrieving from a global Git config or IDE settings). Return a success status or error details (e.g., nothing to commit) in the JSON response."
      },
      {
        "step 8": "Review all implemented Git endpoints. Add robust error handling for various scenarios: Git command failures, invalid input (paths, messages), repository not found, Git not installed, etc. Ensure all endpoints return consistent JSON responses, including informative error messages and appropriate HTTP status codes."
      },
      {
        "step 9": "Refactor the Git service module and API endpoint implementations for clarity, efficiency, and maintainability. Ensure sensitive operations or those involving file paths properly sanitize inputs to prevent potential security vulnerabilities like command injection, especially if constructing raw Git commands."
      },
      {
        "step 10": "Add basic API documentation (e.g., using Swagger/OpenAPI annotations or comments) for the newly created Git endpoints, explaining the expected request body/parameters and the structure of the JSON response for both success and error cases."
      }
    ],
    "Task 4.8: Develop UI for displaying file status and changes (diff view)": [
      {
        "step 1": "Identify or create the necessary UI components for displaying file status and diffs. Plan to integrate file status indicators (e.g., color coding, icons) directly into the existing file explorer widget. Design a new, dedicated widget (e.g., `DiffViewWidget`) for displaying side-by-side or unified diffs. Assume the file explorer widget is available from previous steps."
      },
      {
        "step 2": "Integrate with the VCS module (developed in Task 4.7). Implement logic to periodically poll or subscribe to file system events to detect changes and then call the appropriate VCS functions (e.g., `get_file_status`, `get_git_status`) to retrieve the status of files within the project workspace."
      },
      {
        "step 3": "Modify the file explorer widget's rendering logic. Update the display for each file/directory item to visually indicate its VCS status (e.g., 'M' icon or green color for modified, 'A' or blue for added, '?' or gray for untracked). Map the status results obtained in Step 2 to specific visual representations."
      },
      {
        "step 4": "Create the basic structure for the `DiffViewWidget`. Define the UI layout, potentially using two read-only text areas (e.g., `QTextEdit` in PyQt) for a side-by-side view or a single text area for a unified view. Add placeholders or labels indicating 'Original' and 'Modified' versions."
      },
      {
        "step 5": "Implement the logic within the `DiffViewWidget` (or a controller/service) to fetch the diff content for a specified file. Use the VCS module's function (e.g., `get_file_diff(filepath)`) to retrieve the diff information, likely in unified diff format."
      },
      {
        "step 6": "Implement a diff parsing function. This function should take the raw diff string (unified format) as input and parse it into a structured representation (e.g., a list of hunks, where each hunk contains lines marked as added, removed, or context). Hint: Consider using a library like `diff_match_patch` or parsing the standard diff format manually."
      },
      {
        "step 7": "Implement the rendering logic within the `DiffViewWidget`. Use the parsed diff data from Step 6 to populate the text area(s). Apply distinct background colors or text formatting to highlight added lines (e.g., green background), removed lines (e.g., red background), and context lines. Ensure proper alignment for side-by-side views if implemented. Hint: For complex rendering like syntax highlighting within diffs, you might need to integrate with the syntax highlighting component."
      },
      {
        "step 8": "Integrate the `DiffViewWidget` into the main IDE window. Modify the file explorer or create a dedicated 'Changes' panel so that when a user selects or double-clicks a file with a 'modified' status, the `DiffViewWidget` is populated with the diff for that file. Decide whether the diff view opens in a new tab, a split pane, or a dedicated area."
      },
      {
        "step 9": "Implement refresh functionality. Add a manual refresh button or action that re-runs the VCS status check and updates the file explorer and potentially the currently displayed diff. Consider implementing automatic refreshes triggered by file save events or window focus changes, but be mindful of performance."
      },
      {
        "step 10": "Refine the visual styling. Adjust the colors, fonts, and layout of the status indicators in the file explorer and the line highlighting in the `DiffViewWidget` for optimal readability and consistency with the IDE's theme. Ensure the diff view handles scrolling synchronization for side-by-side views."
      },
      {
        "step 11": "Perform manual testing. Test the following scenarios: modifying files, adding new files, deleting files, staging/unstaging changes (if applicable), viewing diffs for various file types, and refreshing the status/diff view. Verify that status indicators and diffs update correctly and efficiently."
      }
    ],
    "Task 4.9: Develop UI for staging/unstaging changes and committing": [
      {
        "step 1": "Design and create the basic UI layout for the 'Source Control' panel. This panel should have distinct sections for displaying 'Staged Changes' and 'Changes' (unstaged), a multi-line text input for the commit message, and a 'Commit' button. Place this panel appropriately within the main IDE window (e.g., in a sidebar). Hint: Use the existing UI framework (e.g., PyQt, Tkinter, Electron/React components) and define placeholder areas for now."
      },
      {
        "step 2": "Implement or update the backend function (e.g., `get_git_status()`) to retrieve the status of files in the current workspace's Git repository. This function should parse the output of `git status --porcelain` (or use a Git library like `gitpython`) to return structured data, clearly distinguishing between staged, unstaged (modified, deleted, added), and untracked files. Ensure the function returns lists of file paths for each category."
      },
      {
        "step 3": "Populate the 'Changes' (unstaged) section of the Source Control panel. Fetch the status using the backend function from Step 2. Display each unstaged file (modified, deleted, untracked) as an item in a list. Include a visual indicator (e.g., icon or label like 'M', 'D', 'A', '?') next to each file name. Hint: Use a list view or similar component."
      },
      {
        "step 4": "Add interactive elements to the 'Changes' list items to allow staging. For each file listed, add a '+' (stage) button or a context menu option. Implement the backend function `stage_files(file_paths: list[str])` if it doesn't exist, using `git add <file_path>` or the equivalent library call. Connect the UI action (clicking '+') to call this backend function with the corresponding file path."
      },
      {
        "step 5": "Populate the 'Staged Changes' section of the Source Control panel. Fetch the status using the backend function from Step 2. Display each staged file (staged modifications, additions, deletions) as an item in a list, including a visual indicator."
      },
      {
        "step 6": "Add interactive elements to the 'Staged Changes' list items to allow unstaging. For each file listed, add a '-' (unstage) button or a context menu option. Implement the backend function `unstage_files(file_paths: list[str])` if it doesn't exist, using `git reset HEAD <file_path>` (for staged modifications/additions) or `git rm --cached <file_path>` (for staged new files, though `reset` often handles this too) or the equivalent library call. Connect the UI action (clicking '-') to call this backend function with the corresponding file path."
      },
      {
        "step 7": "Implement the functionality for the 'Commit' button. Implement the backend function `commit_changes(message: str)` if it doesn't exist, using `git commit -m \"<message>\"` or the equivalent library call. Connect the UI button's click event to: 1. Retrieve the text from the commit message input area. 2. Validate that the message is not empty and there are staged changes. 3. Call the `commit_changes` backend function with the message."
      },
      {
        "step 8": "Implement automatic refreshing of the Source Control panel's content (both staged and unstaged sections) after any successful staging, unstaging, or commit operation. Ensure the commit message input is cleared after a successful commit. Hint: Trigger a re-fetch of the `get_git_status()` data and update the UI components."
      },
      {
        "step 9": "Add UI feedback for Git operations. Display success messages (e.g., 'Changes committed.') or error messages (e.g., 'Commit failed: No changes staged.', 'Staging failed for file X.') to the user, perhaps in a status bar or a dedicated output area within the Source Control panel. Ensure backend functions raise appropriate exceptions or return error statuses that the UI can handle."
      },
      {
        "step 10": "Refine the display of file paths. Show paths relative to the project root directory. Consider adding tooltips to show the full path if necessary. Ensure the UI handles potential scrolling for long lists of files."
      },
      {
        "step 11": "(Optional Enhancement) Implement 'Stage All' and 'Unstage All' buttons for the respective sections ('Changes' and 'Staged Changes'). These buttons should collect all relevant file paths from their section and call the corresponding `stage_files` or `unstage_files` backend function."
      }
    ],
    "Task 4.10: Develop UI for viewing commit history (log)": [
      {
        "step 1": "Define the data structure for representing a single commit entry. This structure should include fields for commit hash (short and full), author name, author email, commit date (formatted string), and the commit message (subject line). Create a placeholder list of these structures for temporary UI testing."
      },
      {
        "step 2": "Locate the existing VCS interaction module (likely related to Git). Create a new function `get_commit_history(repo_path: str, max_count: int = 50) -> list`. This function should use the underlying Git library (e.g., `gitpython`) or execute the `git log` command (`subprocess`) to retrieve the commit history for the repository at `repo_path`. Format the output according to the data structure defined in Step 1. Hint: Use `git log --pretty=format:'%h|%H|%an|%ae|%ad|%s' --date=short` for easy parsing, limiting the number of commits with `-n <max_count>`."
      },
      {
        "step 3": "Design the UI component for displaying the commit history. Choose an appropriate widget from the project's GUI framework (e.g., `QTreeView`/`QTableView` in PyQt/PySide, `ttk.Treeview` in Tkinter, or a custom list component in a web framework). Define columns for: Short Hash, Author, Date, and Message Subject."
      },
      {
        "step 4": "Integrate the designed UI component into the main IDE window. Place it in a suitable area, potentially a new dock widget, a dedicated tab within a side panel, or a separate dialog window. Initially, populate it with the placeholder data from Step 1."
      },
      {
        "step 5": "Implement the logic to fetch actual commit data using the `get_commit_history` function (from Step 2) when the history view is shown or refreshed. Replace the placeholder data population with the data returned by this function. Ensure the current project's repository path is correctly passed to the function."
      },
      {
        "step 6": "Add a user interface element (e.g., a menu item under 'VCS' or 'Git', a button in a toolbar, or an item in a context menu) to trigger the display and refresh of the commit history view. Connect this element's action/command to the logic implemented in Step 5."
      },
      {
        "step 7": "Implement basic error handling. If the `get_commit_history` function fails (e.g., not a Git repository, `git` command not found, parsing error), display an informative message to the user within the history UI component or via a status bar message."
      },
      {
        "step 8": "(Optional Enhancement) Implement functionality to display more details when a commit is selected in the history view. Add a separate text area or panel. When a commit row is selected, fetch and display the full commit message and potentially the list of changed files for that commit (Hint: requires another backend function using `git show <commit_hash>` or similar)."
      },
      {
        "step 9": "Refactor the newly added UI code and backend logic for clarity, adherence to project conventions, and separation of concerns (UI vs. Git logic). Add comments where necessary."
      },
      {
        "step 10": "Test the commit history view thoroughly: Check display with varying numbers of commits, test repositories with no commits, test non-Git directories (error handling), verify commit details display (if implemented), and ensure responsiveness."
      }
    ],
    "Task 4.11: Implement UI for basic branch management (view, switch, create)": [
      {
        "step 1": "Identify the designated UI area for Version Control System (VCS) information (e.g., status bar, dedicated panel). If no specific area exists, create a new container widget (e.g., a `QFrame` in PyQt/PySide or `tk.Frame` in Tkinter) within the main window layout to host VCS-related controls."
      },
      {
        "step 2": "Within the identified VCS UI area, add a non-editable UI element (e.g., `QLabel`, `tk.Label`) to display the name of the currently active Git branch. Implement the logic to fetch the current branch name using the existing Git backend functions (you likely have a function like `get_current_branch`). Ensure this element is updated when the application starts or a project/repository is loaded."
      },
      {
        "step 3": "Add a UI element that allows viewing and selecting local branches (e.g., a `QComboBox`, `tk.OptionMenu`, or a button that triggers a dropdown/list). Populate this element by fetching the list of all local branches using the relevant Git backend function (e.g., `get_local_branches`). Ensure the currently active branch is selected/highlighted by default."
      },
      {
        "step 4": "Implement the event handler for selecting a branch from the UI element created in Step 3. This handler should: \n    a) Get the selected branch name.\n    b) Call the backend Git function to switch to the selected branch (e.g., `switch_branch(branch_name)`).\n    c) Handle potential errors during the switch operation (e.g., uncommitted changes, invalid branch) by displaying informative messages to the user (e.g., using a message box).\n    d) Upon successful switching, update the current branch display element (from Step 2) and potentially trigger a refresh of the file tree/editor if needed.\n    *Hint: Ensure you prevent switching if the selected branch is already the current branch.*"
      },
      {
        "step 5": "Add a UI element (e.g., a `QPushButton` labeled 'New Branch', or a menu item) to initiate the creation of a new branch. Connect this element to an action that prompts the user for the new branch name using a simple input dialog (e.g., `QInputDialog.getText` or a custom Tkinter dialog)."
      },
      {
        "step 6": "Implement the logic triggered after the user submits the new branch name. This logic should:\n    a) Perform basic validation on the input name (e.g., not empty, potentially check for invalid characters).\n    b) Call the backend Git function to create the new branch (e.g., `create_branch(branch_name)`).\n    c) Handle potential errors during creation (e.g., branch already exists, invalid name format) and display feedback to the user.\n    d) Upon successful creation, refresh the branch list UI element (from Step 3) to include the new branch. Optionally, ask the user if they want to switch to the newly created branch."
      },
      {
        "step 7": "Integrate all the new UI elements (current branch display, branch selector/switcher, new branch button/action) into the main application window's VCS area defined in Step 1. Ensure proper layout and visibility."
      },
      {
        "step 8": "Refactor the newly added UI code for branch management. Ensure clear separation between UI event handling and calls to the backend Git functions. Add comments to explain the workflow. Test the functionality thoroughly: view branches, switch between branches (including cases with uncommitted changes), create new branches (valid and invalid names)."
      }
    ],
    "Task 4.12: Integrate VCS status indicators into file explorer and editor gutter": [
      {
        "step 1": "Enhance the VCS utility module (e.g., `vcs_utils.py`) to accurately parse file statuses. Implement or refine a function, perhaps named `get_vcs_file_statuses(repo_path)`, that executes `git status --porcelain=v1 -uall` (or the equivalent for the configured VCS) within the given `repo_path`. This function should parse the output and return a dictionary mapping file paths (relative to `repo_path`) to their specific VCS status (e.g., 'modified', 'added', 'untracked', 'deleted', 'renamed', 'conflicted'). Ensure paths are normalized and handle various status combinations reported by the porcelain format."
      },
      {
        "step 2": "Integrate the retrieved VCS status information into the application's central state management system. Define state variables to hold the status dictionary (filePath -> status). Create actions/mutations/reducers (e.g., `updateVCSStatus`, `clearVCSStatus`) to manage this state. Ensure this state is accessible by the file explorer and editor components."
      },
      {
        "step 3": "Modify the file explorer component's rendering logic. For each file and directory displayed, query the central state for its VCS status. Based on the status, apply distinct visual cues, such as changing the file name color or adding a status icon (e.g., M for modified, A for added, ? for untracked, D for deleted, U for conflicted). Define corresponding CSS classes (e.g., `.file-item.vcs-modified`, `.file-item.vcs-untracked`) for styling."
      },
      {
        "step 4": "Implement a mechanism within the file explorer to visually indicate the status of files within a directory. If a directory contains files with VCS changes (modified, added, untracked etc.), apply a visual cue (e.g., subtle color change, small indicator icon) to the directory item itself in the tree view."
      },
      {
        "step 5": "Modify the editor component to display the overall VCS status of the currently open file. Retrieve the file's status from the central state. Display this status prominently, potentially in the editor's status bar or as a persistent icon in the gutter's top area. Ensure this indicator updates if the file's status changes while it's open."
      },
      {
        "step 6": "Implement line-level change indicators (diff markers) in the editor's gutter. This involves: a) Fetching the file's content from the VCS index (e.g., `git show :<file_path>`). b) Performing a diff between the index content and the current editor buffer content. c) Parsing the diff results to identify added, modified, and deleted lines/hunks relative to the buffer. d) Rendering visual markers (e.g., colored bars or symbols) in the gutter next to the corresponding line numbers. Hint: Use a diffing library (search for suitable options for your language/framework) to simplify diff generation and parsing. This is complex; start by indicating changed lines, then differentiate between added/modified/deleted."
      },
      {
        "step 7": "Implement an efficient VCS status refresh strategy. Trigger the `get_vcs_file_statuses` function and update the central state in response to relevant events like: file saves, editor tab changes, window focus events, completion of VCS operations (commit, checkout, pull), and potentially a throttled background refresh (e.g., using polling or file system watching if available and reliable in your environment). Hint: Avoid running `git status` too frequently; debounce or throttle calls. Consider the performance impact, especially for large repositories."
      },
      {
        "step 8": "Ensure the file explorer and editor gracefully handle file renames and deletions indicated by the VCS status. Update the file explorer tree to reflect these changes (e.g., strike-through for deleted, new name for renamed). If an open file is deleted or renamed externally, the editor should potentially show a warning, update its associated path, or prompt the user."
      },
      {
        "step 9": "Integrate configuration options into the IDE's settings system. Add settings to allow users to enable/disable VCS status indicators in the file explorer (`vcs.decorations.enabled`) and the editor gutter (`vcs.gutter.enabled`). Optionally, add settings to customize the colors or icons used for different statuses."
      },
      {
        "step 10": "Write unit tests for the `get_vcs_file_statuses` parsing logic, covering various `git status --porcelain=v1` output examples (modified, added, untracked, deleted, renamed, conflicted, combinations). Write integration or component tests to verify that UI elements (file explorer items, gutter markers) update correctly when the VCS status changes in the application state. Hint: Mock the `git` command execution and the application state during testing."
      }
    ],
    "Task 4.13: Implement backend integration for Git push, pull, fetch operations": [
      {
        "step 1": "Identify the existing Git library used in the backend (e.g., `GitPython` for Python, `isomorphic-git` or shelling out to `git` CLI for Node.js). If no suitable library is integrated for remote operations, install `GitPython` (for Python backend) or choose an appropriate library for your backend stack. Ensure the library is added to your project's dependencies."
      },
      {
        "step 2": "Define new API endpoints in your backend router/controller for Git fetch, pull, and push operations. Suggested endpoints: `POST /api/git/fetch`, `POST /api/git/pull`, `POST /api/git/push`. Ensure these routes are protected if authentication/authorization is implemented."
      },
      {
        "step 3": "Implement the backend handler function for the `POST /api/git/fetch` endpoint. This function should accept the repository path and optionally the remote name (defaulting to 'origin') in the request body. Use the chosen Git library to execute the `git fetch` command for the specified repository and remote. Hint: With `GitPython`, use `repo.remotes.<remote_name>.fetch()`. Handle potential exceptions (e.g., repository not found, network errors, invalid remote). Return a success status or an appropriate error response."
      },
      {
        "step 4": "Implement the backend handler function for the `POST /api/git/pull` endpoint. This function should accept the repository path, remote name (default 'origin'), and branch name (optional, defaults to current branch) in the request body. Use the Git library to execute `git pull <remote> <branch>`. Hint: With `GitPython`, use `repo.remotes.<remote_name>.pull()`. Implement robust error handling, especially for merge conflicts, authentication issues, and network errors. Return a success status, conflict indication, or error details."
      },
      {
        "step 5": "Implement the backend handler function for the `POST /api/git/push` endpoint. This function should accept the repository path, remote name (default 'origin'), and branch name (optional, defaults to current branch) in the request body. Use the Git library to execute `git push <remote> <branch>`. Hint: With `GitPython`, use `repo.remotes.<remote_name>.push()`. Note: Pushing often requires authentication. Initially, assume credentials are configured server-side (e.g., SSH keys, Git credential helper). Handle errors robustly, including authentication failures, non-fast-forward rejections, and network errors. Return a success status or error details."
      },
      {
        "step 6": "Refine error handling for all three new endpoints (`fetch`, `pull`, `push`). Ensure that errors originating from the Git library or the `git` command are caught and translated into meaningful JSON error responses for the frontend, including appropriate HTTP status codes (e.g., 400 for bad request, 401/403 for auth issues, 409 for conflicts, 500 for server errors)."
      },
      {
        "step 7": "Add logging to the backend handlers for fetch, pull, and push operations. Log the start and end of each operation, the parameters received (excluding sensitive data), and any errors encountered. This will aid in debugging."
      },
      {
        "step 8": "Security Review: Explicitly review the implementation, especially for the `push` operation. Consider the security implications of executing Git commands based on API requests. Ensure repository paths are validated to prevent directory traversal attacks. Reiterate that handling credentials securely is critical; the current implementation relies on server-side pre-configuration, which might not be suitable for all deployment scenarios. Document these limitations."
      },
      {
        "step 9": "Write integration tests for the new API endpoints (`/api/git/fetch`, `/api/git/pull`, `/api/git/push`). Mock the Git library interactions or set up a temporary local Git repository with a remote to test the success and failure scenarios, including network errors, authentication issues (mocked), and potential conflicts (for pull/push)."
      }
    ],
    "Task 4.14: Define the Extension API surface (commands, UI contribution points, language features)": [
      {
        "step 1": "Create a new directory named 'src/extension_api' to house all files related to the extension API definition."
      },
      {
        "step 2": "Create a file named 'src/extension_api/common_types.ts'. Define fundamental types that will be used across the API, such as `Disposable`, `Event<T>`, `Uri`, `Position`, `Range`, `Location`, `TextDocument`. Hint: You can draw inspiration from existing IDE APIs like VS Code's or the Language Server Protocol (LSP) for these basic types. Ensure they are well-documented with TSDoc comments."
      },
      {
        "step 3": "Create a file named 'src/extension_api/commands.ts'. Define the interface for a command (`interface Command { id: string; title: string; execute: (...args: any[]) => Promise<any> | any; }`) and the API function signature for registering and unregistering commands (e.g., `registerCommand(command: Command): Disposable`). Document the purpose and usage."
      },
      {
        "step 4": "Create a file named 'src/extension_api/ui_contributions.ts'. Define types and structures for contributing to UI elements. Start with menu contributions: Define identifiers for common menu locations (e.g., `MainMenu.File`, `Editor.ContextMenu`, `Explorer.ContextMenu`). Define the structure for a menu item contribution (e.g., `interface MenuItemContribution { commandId: string; title?: string; group?: string; when?: string; // Context key expression }`). Hint: Consider how extensions will specify conditions (`when` clause) for showing menu items based on context (e.g., file type, editor focus)."
      },
      {
        "step 5": "In 'src/extension_api/ui_contributions.ts', define the structure for contributing custom views/panels. Specify interfaces for view providers (e.g., `interface ViewProvider { id: string; title: string; createView(panel: ViewPanel): Disposable; }`) and the panel object (`interface ViewPanel { // Methods to update view content, handle messages, etc. }`). Define contribution points (e.g., `ActivityBarView`, `BottomPanelView`)."
      },
      {
        "step 6": "In 'src/extension_api/ui_contributions.ts', define the structure for contributing status bar items. Define an interface (e.g., `interface StatusBarItemContribution { id: string; text: string; tooltip?: string; command?: string; priority?: number; alignment: 'left' | 'right'; }`) and API functions for creating and managing status bar items (e.g., `createStatusBarItem(alignment: 'left' | 'right', priority?: number): StatusBarItemHandle`, where `StatusBarItemHandle` has methods like `update(options: Partial<StatusBarItemContribution>)`, `show()`, `hide()`, `dispose()`)."
      },
      {
        "step 7": "Create a file named 'src/extension_api/language_features.ts'. Define the concept of `DocumentSelector` (e.g., `type DocumentSelector = { language?: string; scheme?: string; pattern?: string; } | Array<{ language?: string; scheme?: string; pattern?: string; }>`) used to target specific documents for language features."
      },
      {
        "step 8": "In 'src/extension_api/language_features.ts', define the API for registering completion providers. Define the `CompletionItem` type and related types (e.g., `CompletionItemKind`, `InsertTextFormat`). Define the provider interface (e.g., `interface CompletionProvider { provideCompletionItems(document: TextDocument, position: Position, context: CompletionContext): Promise<CompletionItem[]> | CompletionItem[]; }`) and the registration function (e.g., `registerCompletionProvider(selector: DocumentSelector, provider: CompletionProvider): Disposable`)."
      },
      {
        "step 9": "In 'src/extension_api/language_features.ts', define the API for registering diagnostics providers (linting/error reporting). Define the `Diagnostic` type and related types (e.g., `DiagnosticSeverity`). Define the provider interface (e.g., `interface DiagnosticProvider { provideDiagnostics(document: TextDocument): Promise<Diagnostic[]> | Diagnostic[]; }`) and a mechanism for providers to push updates (e.g., returning an `Event<Uri>` from registration or providing a `DiagnosticCollection` object). Define the registration function (e.g., `registerDiagnosticProvider(selector: DocumentSelector, provider: DiagnosticProvider): Disposable` or similar)."
      },
      {
        "step 10": "In 'src/extension_api/language_features.ts', define interfaces and registration functions for other common language features like Hover (`registerHoverProvider`), Definition (`registerDefinitionProvider`), and Formatting (`registerDocumentFormattingEditProvider`). Use LSP types as inspiration where appropriate. Ensure each registration function returns a `Disposable`."
      },
      {
        "step 11": "Create a central API entry point file, e.g., 'src/extension_api/index.ts'. This file should export all the necessary types, interfaces, and registration functions defined in the previous steps, providing a single point of access for extensions. Ensure all exported elements are clearly documented using TSDoc."
      },
      {
        "step 12": "Create a basic 'docs/extension_api.md' file. Outline the main concepts (Activation, Contribution Points, Commands, UI Contributions, Language Features) and list the key API registration functions and data structures defined in the TypeScript files. Include brief examples of how an extension might use each major part of the API."
      },
      {
        "step 13": "Review all defined interfaces, types, and function signatures in the 'src/extension_api' directory. Check for consistency in naming conventions, parameter order, return types (especially the use of `Disposable`), and documentation clarity. Refactor where necessary to improve coherence and usability."
      }
    ],
    "Task 4.15: Implement the extension loading mechanism (discovery, activation)": [
      {
        "step 1": "Define the structure and format for an extension manifest file. Create a specification (e.g., in a Markdown document or as comments in a new configuration file) for `extension.json`. This file should reside at the root of each extension's directory. Specify mandatory fields like `name` (string, unique identifier), `version` (string, semantic versioning preferred), `main` (string, relative path to the extension's entry point Python script), and `activationEvents` (list of strings, e.g., `[\"onStartup\"]`). Also include an optional `contributes` field (object, initially can be empty or define a simple structure for commands like `{\"commands\": [{\"command\": \"commandId\", \"title\": \"User Friendly Title\"}]}`). Create a placeholder `extension_api.py` file for future API definitions."
      },
      {
        "step 2": "Implement the extension discovery mechanism. Create a directory named `extensions` in the project's root if it doesn't exist. Create a new module, e.g., `extension_manager.py`. Within this module, implement a function `discover_extensions(extensions_dir: str) -> list`. This function should scan the immediate subdirectories within `extensions_dir`. For each subdirectory, it must check for the presence of `extension.json`. If found, parse the JSON file. Validate the parsed data against the mandatory fields defined in Step 1. Collect valid extension metadata (parsed JSON content plus the path to the extension directory) into a list. Implement robust error handling for missing files, invalid JSON, and missing mandatory fields, logging warnings or errors as appropriate. Hint: Use `os.scandir` for efficient directory traversal and `json.load` for parsing. Add basic logging."
      },
      {
        "step 3": "Develop the core `ExtensionManager` class within `extension_manager.py`. This class should orchestrate the extension lifecycle. Initialize it with the path to the extensions directory. Add a method `discover_and_load_extensions` that calls the `discover_extensions` function from Step 2. Add internal storage (e.g., dictionaries) to keep track of discovered extensions (`self._discovered_extensions`), loaded extension modules (`self._loaded_extensions`), and activated extensions (`self._activated_extensions`)."
      },
      {
        "step 4": "Implement the extension loading logic within the `ExtensionManager` class. Create a private method `_load_extension(extension_metadata: dict)`. This method should take the metadata for a single extension. Construct the absolute path to the extension's main script (specified in the `main` field of its manifest). Use the `importlib` module (specifically `importlib.util.spec_from_file_location` and `importlib.util.module_from_spec`) to dynamically load the extension's Python module. Store the loaded module reference in `self._loaded_extensions`, keyed by extension name or path. Implement error handling for file not found errors, import errors, and other issues during loading, logging detailed error messages. Update `discover_and_load_extensions` to attempt loading discovered extensions."
      },
      {
        "step 5": "Implement the extension activation logic in `ExtensionManager`. Add a method `activate_extension(extension_name: str)`. This method should retrieve the loaded module for the given `extension_name`. Check if the module has an `activate` function. If it exists, call `activate()`. For now, the `activate` function will take no arguments; we will inject the API context in the next step. Keep track of activated extensions in `self._activated_extensions`. Add another method `activate_startup_extensions` that iterates through the discovered extensions and activates those whose `activationEvents` list contains `\"onStartup\"`. Handle errors during activation (e.g., missing `activate` function, exceptions raised by `activate`), logging them appropriately."
      },
      {
        "step 6": "Define a basic `ExtensionAPI` context object. In `extension_api.py`, define a class `ExtensionAPI`. For this initial implementation, add a placeholder method or attribute, for example, `register_command(command_id: str, callback: callable)`. This method will later integrate with the command palette. Instantiate this API object within the `ExtensionManager`. Modify the `activate_extension` method in `ExtensionManager` to pass an instance of `ExtensionAPI` to the extension's `activate(api)` function. Update the check to ensure the `activate` function exists and accepts one argument."
      },
      {
        "step 7": "Create a simple example 'Hello World' extension. Create a subdirectory `extensions/hello_world`. Inside it, create `extension.json` with `name: \"helloWorld\"`, `version: \"0.0.1\"`, `main: \"main.py\"`, `activationEvents: [\"onStartup\"]`, and `contributes: {\"commands\": [{\"command\": \"helloWorld.sayHello\", \"title\": \"Say Hello\"}]}`. Create `main.py` within `extensions/hello_world`. Implement the required `activate(api)` function in `main.py`. Inside `activate`, define a simple function `say_hello()` that logs a message like \"Hello World from extension!\". Use `api.register_command('helloWorld.sayHello', say_hello)` to register this function."
      },
      {
        "step 8": "Integrate the `ExtensionManager` into the IDE's startup sequence. In your main application entry point (e.g., `main.py` or `app.py`), instantiate the `ExtensionManager`. After essential core services are initialized but before the main loop or UI is fully running, call the `ExtensionManager`'s methods to `discover_and_load_extensions()` and then `activate_startup_extensions()`. Run the IDE and verify that the 'Hello World' extension is discovered, loaded, and activated by checking the logs for the discovery messages, activation messages, and the \"Hello World from extension!\" message from the sample extension's `activate` function. Verify error logs for any issues."
      },
      {
        "step 9": "Write unit tests for the extension loading mechanism. Focus on testing the `ExtensionManager` class in isolation. Mock the filesystem (`os`, `json`, `importlib`) interactions. Test `discover_extensions` with various scenarios: empty directory, directory with valid extensions, directory with invalid/missing manifests, directory with invalid JSON. Test `_load_extension` for successful loading and various error conditions (file not found, import error). Test `activate_extension` for successful activation and error conditions (missing `activate` function, `activate` function raising exceptions). Use the `unittest` or `pytest` framework."
      }
    ],
    "Task 4.16: Implement the extension host process/sandbox environment": [
      {
        "step 1": "Design the architecture for the extension host. Decide whether it will run as a separate OS process (e.g., using Node.js `child_process` or Electron's `UtilityProcess`) or another mechanism like a Web Worker (if applicable to your architecture). Document this decision, including the chosen Inter-Process Communication (IPC) method (e.g., standard input/output, Node.js IPC channel, WebSockets)."
      },
      {
        "step 2": "Create a new script file that will serve as the entry point for the extension host process (e.g., `extensionHost.js`). This script will be responsible for initializing the host environment, setting up IPC communication, and loading extensions."
      },
      {
        "step 3": "Implement the basic IPC setup within the `extensionHost.js` script. Add code to listen for messages from the main IDE process and send messages back. Use the IPC mechanism decided in Step 1. (Hint: For Node.js `child_process` with the `ipc` option, use `process.on('message', handler)` and `process.send(message)`)."
      },
      {
        "step 4": "In the main IDE process code (likely where extension management resides), implement the logic to spawn the extension host process using the script created in Step 2. Ensure the chosen IPC channel is correctly configured during spawning. (Hint: Use Node.js `child_process.fork()` for easy IPC)."
      },
      {
        "step 5": "Establish the corresponding IPC handling logic in the main IDE process. Listen for messages from the spawned extension host process and implement a way to send messages/commands to it. Ensure robust error handling for process creation and communication errors (e.g., unexpected exit)."
      },
      {
        "step 6": "Define a simple message protocol for communication between the main process and the extension host (e.g., using JSON objects with `command`, `payload`, `requestId` fields). Implement serialization/deserialization if needed. (Hint: Consider using a lightweight RPC library or a simple request/response pattern)."
      },
      {
        "step 7": "In the main IDE process, implement the server-side of the extension API proxy. When the host requests an API call (via IPC), receive the message, validate it, execute the corresponding IDE functionality, and send the result (or error) back to the host via IPC."
      },
      {
        "step 8": "In the `extensionHost.js` script, implement the client-side of the extension API. Create stub functions or proxy objects that extensions can call. These stubs should serialize the call into an IPC message, send it to the main process, and asynchronously return the result when the response is received."
      },
      {
        "step 9": "Implement the extension loading mechanism within `extensionHost.js`. Upon receiving a command from the main process (e.g., 'loadExtension' with a path), the host should load the extension code (e.g., using `require(extensionPath)` in Node.js) within its environment. (Hint: Consider security implications of `require`. Research Node.js `vm` module for basic code isolation, but be aware of its limitations as a security sandbox)."
      },
      {
        "step 10": "Integrate the extension host spawning and loading logic with the existing extension activation mechanism. When an extension needs to be activated (based on activation events), ensure the extension host process is running (spawn if necessary) and send a message to the host to load and activate the specific extension."
      },
      {
        "step 11": "Implement basic sandboxing and resource limiting measures. At a minimum, the separate process provides OS-level isolation. Consider adding error handling within the host to catch exceptions from individual extensions and report them back to the main process without crashing the entire host. (Hint: Use `try...catch` around extension code execution, listen for `uncaughtException` in the host process, but report it rather than exiting)."
      },
      {
        "step 12": "Refactor the IPC communication logic to be more robust. Implement request IDs to correlate responses with requests, handle timeouts for API calls, and manage potential race conditions or out-of-order messages."
      },
      {
        "step 13": "Add lifecycle management for the extension host. Implement logic in the main process to monitor the host process health, restart it if it crashes, and gracefully shut it down when the IDE closes."
      },
      {
        "step 14": "Write integration tests to verify the end-to-end functionality: spawning the host, loading an extension, calling an API from the extension via IPC, receiving the result, and handling host crashes."
      }
    ],
    "Task 4.17: Implement API endpoints for extensions to register commands": [
      {
        "step 1": "Design the API endpoint for command registration. Define the HTTP method (e.g., POST), the URL route (e.g., `/api/extensions/commands/register`), and the expected JSON request body structure. The body should include essential command details like `commandId` (unique identifier, perhaps namespaced like 'extensionName.commandName'), `title` (user-friendly name), and potentially `description` or other metadata relevant to your command execution system."
      },
      {
        "step 2": "In your backend server code (e.g., Flask, Express), implement the route handler function for the designed endpoint (`POST /api/extensions/commands/register`). Initially, just set up the route structure without the full implementation."
      },
      {
        "step 3": "Implement input validation for the request body within the route handler. Ensure the incoming JSON payload conforms to the structure defined in Step 1. Check for the presence and correct types of required fields like `commandId` and `title`. Hint: Use a validation library appropriate for your backend framework (e.g., Pydantic for FastAPI/Flask, Joi or Zod for Express)."
      },
      {
        "step 4": "Identify or create the central 'CommandRegistry' or 'CommandManager' service/module responsible for keeping track of all registered commands in the IDE. Define an interface or method within this registry, such as `register_command(command_details: dict)`, that accepts the validated command information."
      },
      {
        "step 5": "Implement the `register_command` method in the CommandRegistry/Manager. This method should store the command details (e.g., in an in-memory dictionary keyed by `commandId`). Handle potential conflicts, such as attempting to register a command with an already existing `commandId`. Decide on a conflict resolution strategy (e.g., reject the new registration, overwrite the old one, log a warning)."
      },
      {
        "step 6": "Connect the API route handler (from Step 2) to the CommandRegistry. Inside the handler, after validating the request body (Step 3), call the `CommandRegistry.register_command()` method with the validated command details."
      },
      {
        "step 7": "Implement robust error handling in the API route handler. Return appropriate HTTP status codes and informative JSON error messages for various scenarios: 400 Bad Request for validation errors, 409 Conflict if the `commandId` already exists (and overwriting is not desired), 500 Internal Server Error for unexpected issues during registration."
      },
      {
        "step 8": "Add a placeholder comment or log message within the API endpoint handler indicating where security checks should be performed later. This check would typically verify that the request originates from a legitimate, loaded extension, possibly using an API key or token associated with the extension."
      },
      {
        "step 9": "Write unit tests for the `register_command` method in the CommandRegistry/Manager. Test successful registration, registration with missing fields (if validation is also done here), handling of duplicate `commandId`s according to your chosen strategy, and retrieval of registered commands (if applicable)."
      },
      {
        "step 10": "Write integration tests for the `/api/extensions/commands/register` endpoint. Use a testing client (like `pytest` with a Flask test client, or `supertest` for Express) to send various POST requests (valid data, invalid data, duplicate `commandId`s) and assert that the correct HTTP responses and status codes are returned, and that the command registry state is updated as expected."
      },
      {
        "step 11": "Document the new API endpoint. Add comments in the code or update your project's API documentation (e.g., OpenAPI/Swagger specification) explaining how extensions should use this endpoint, the required request format, and possible responses."
      }
    ],
    "Task 4.18: Implement API endpoints for extensions to contribute UI elements (menus, views, status bar items)": [
      {
        "step 1": "Define the data structures (JSON schemas) for UI contributions. Specify the properties for menu items (e.g., `id`, `label`, `commandId`, `icon`, `group`, `when` context), views (e.g., `id`, `name`, `icon`, `location` like 'sidebar' or 'panel', `webviewUrl` or `componentId`, `when` context), and status bar items (e.g., `id`, `text`, `tooltip`, `commandId`, `alignment` like 'left' or 'right', `priority`, `when` context). Store these definitions in a suitable location, perhaps within the `common` or `types` directory."
      },
      {
        "step 2": "In the backend application (e.g., Flask/FastAPI), implement an in-memory storage mechanism to hold registered UI contributions. Create dictionaries or similar structures to store lists of menu items, views, and status bar items, potentially grouped by extension ID or contribution point (e.g., `registered_menus`, `registered_views`, `registered_status_bar_items`). Ensure this storage is accessible by the API endpoint handlers. Consider thread-safety if necessary."
      },
      {
        "step 3": "Create new backend API endpoints for extensions (or the extension host process acting on their behalf) to register UI contributions. Implement POST endpoints like `/api/v1/ui/contributions/menus`, `/api/v1/ui/contributions/views`, and `/api/v1/ui/contributions/statusbar`. These endpoints should accept the JSON data structures defined in Step 1, validate the input, and add the contribution details (along with the contributing extension's ID) to the in-memory storage from Step 2. Hint: Ensure proper error handling for invalid data or registration failures."
      },
      {
        "step 4": "Create backend API endpoints for the frontend to retrieve the aggregated UI contributions. Implement GET endpoints like `/api/v1/ui/menus`, `/api/v1/ui/views`, and `/api/v1/ui/statusbar`. These endpoints should read from the in-memory storage (Step 2), potentially filter contributions based on context ('when' clauses, although initial implementation might return all), and return the consolidated lists of UI elements to the frontend. Hint: Consider caching strategies if fetching contributions becomes a performance bottleneck."
      },
      {
        "step 5": "Define and implement the internal API functions that extensions will call to register their UI elements. This API surface (e.g., methods on an `ide.ui` or `vscode.window` like object provided to extensions) should wrap the calls to the backend registration endpoints (Step 3). For example, create functions like `registerMenuItem(itemDefinition)`, `registerView(viewDefinition)`, `registerStatusBarItem(itemDefinition)`. Ensure these functions are exposed correctly within the extension execution environment/sandbox. Hint: This might involve modifying the extension host or the code that loads and provides APIs to extensions."
      },
      {
        "step 6": "In the frontend application, create or update a service/store (e.g., using Redux, Zustand, Vuex, or a simple service class) responsible for fetching and managing UI contribution data. Implement logic to call the backend GET endpoints (Step 4) on application startup or when extensions are loaded/activated, and store the retrieved menu, view, and status bar definitions."
      },
      {
        "step 7": "Refactor the frontend main menu component(s) (e.g., top menu bar) to dynamically generate menus and menu items based on the data fetched in Step 6. Ensure that selecting a contributed menu item triggers the associated `commandId`. Hint: You may need to map `commandId`s to actual command execution functions registered elsewhere."
      },
      {
        "step 8": "Refactor the frontend layout components (e.g., sidebar, bottom panel) to dynamically render contributed views based on the data fetched in Step 6. For each registered view, create its container (e.g., a new tab in the sidebar, a panel). Implement the mechanism to display the view's content, potentially using an `<iframe>` pointing to a `webviewUrl` or dynamically mounting a specific frontend component identified by `componentId`. Hint: Pay attention to security considerations if using webviews/iframes."
      },
      {
        "step 9": "Refactor the frontend status bar component to dynamically render contributed status bar items based on the data fetched in Step 6. Ensure items are placed according to their `alignment` and `priority`, and that clicking an item triggers the associated `commandId` if provided."
      },
      {
        "step 10": "Write unit and integration tests for the new backend API endpoints (POST for registration, GET for retrieval). Verify validation, storage, and retrieval logic. Use mock data conforming to the schemas defined in Step 1."
      },
      {
        "step 11": "Write frontend tests (unit or integration, potentially E2E using tools like Playwright or Cypress) to verify that menus, views, and status bar items are dynamically rendered based on mock data provided by the UI contribution service/store. Test command execution triggers for menu and status bar items."
      },
      {
        "step 12": "Update the extension API documentation to include detailed explanations and examples of how extensions can use the new functions (`registerMenuItem`, `registerView`, `registerStatusBarItem`) to contribute UI elements. Include the data structure definitions (Step 1) and usage examples."
      }
    ],
    "Task 4.19: Implement API endpoints for extensions to interact with the editor and workspace": [
      {
        "step 1": "Analyze the existing backend server architecture (e.g., Flask, FastAPI, Express) and identify the modules responsible for editor state management (e.g., active file, content) and workspace management (e.g., file system access). Prepare to integrate new API endpoints into this structure."
      },
      {
        "step 2": "Define the scope of the initial Extension API. Specify the core functionalities extensions should be able to access via API calls. Focus on: reading/writing active editor content, reading workspace files, listing workspace directory contents, and showing user notifications. Define basic JSON request/response structures for these actions."
      },
      {
        "step 3": "If not already present, add a dedicated API router or blueprint for extension-specific endpoints, prefixing the routes (e.g., `/api/v1/extensions`). Integrate this router into the main application."
      },
      {
        "step 4": "Implement the endpoint for getting the active editor's content. Create a `GET` endpoint (e.g., `/api/v1/extensions/editor/activeContent`). This endpoint should retrieve the content from the editor state management module and return it, likely as JSON `{ \"content\": \"...\" }`. Handle cases where no editor is active."
      },
      {
        "step 5": "Implement the endpoint for setting the active editor's content. Create a `PUT` or `POST` endpoint (e.g., `/api/v1/extensions/editor/activeContent`). It should accept JSON `{ \"content\": \"...\" }` in the request body and update the content in the editor state management module. Implement necessary validation and error handling (e.g., no active editor)."
      },
      {
        "step 6": "Implement the endpoint for reading a workspace file. Create a `GET` endpoint (e.g., `/api/v1/extensions/workspace/readFile?path=...`). It should accept a relative file path as a query parameter. Use the workspace management module to read the file content. **Hint:** Ensure robust security checks to prevent directory traversal attacks (e.g., ensure the resolved path stays within the workspace root). Return the content or an appropriate error (e.g., 404 Not Found, 400 Bad Request for invalid path)."
      },
      {
        "step 7": "Implement the endpoint for listing workspace directory contents. Create a `GET` endpoint (e.g., `/api/v1/extensions/workspace/listFiles?path=...`). It should accept an optional relative directory path (defaulting to workspace root). Use the workspace management module to list files and subdirectories. **Hint:** Again, ensure path safety. Return the list as JSON, e.g., `{ \"entries\": [{\"name\": \"...\", \"type\": \"file|directory\"}, ...] }`."
      },
      {
        "step 8": "Implement the endpoint for showing user notifications. Create a `POST` endpoint (e.g., `/api/v1/extensions/ui/showNotification`). It should accept JSON like `{ \"message\": \"...\", \"type\": \"info|warning|error\" }`. Integrate with the existing UI notification mechanism (if any) or log the notification request on the backend for now. Define clear response codes (e.g., 202 Accepted)."
      },
      {
        "step 9": "Add placeholder comments or basic checks (e.g., checking for a specific HTTP header like `X-Extension-ID`) in each endpoint handler function to indicate where authentication and authorization logic for extensions will eventually be implemented. This serves as a reminder for future security enhancements."
      },
      {
        "step 10": "Write integration tests for each implemented API endpoint. Use the testing framework associated with your backend (e.g., `pytest` with `TestClient` for FastAPI/Flask). Mock interactions with the editor and workspace modules as needed. Test success cases, error conditions (invalid input, file not found, security violations), and edge cases."
      },
      {
        "step 11": "Generate or update API documentation for the new endpoints. **Hint:** If using FastAPI, ensure Pydantic models are used for requests/responses and leverage its automatic OpenAPI/Swagger documentation generation. Otherwise, create/update a Markdown file describing the endpoints, parameters, request/response formats, and potential error codes."
      }
    ],
    "Task 4.20: Develop a basic UI for managing extensions (list, enable/disable - install maybe later)": [
      {
        "step 1": "Define the structure for the Extension Management UI. Create a new file, e.g., `ui_extension_manager.py`. Plan to use a `Toplevel` window (assuming Tkinter is the UI framework) containing a `Listbox` to display extensions and their status, and two `Button` widgets: 'Enable' and 'Disable'."
      },
      {
        "step 2": "Implement the basic `ExtensionManagerUI` class in `ui_extension_manager.py`. Initialize the `Toplevel` window and create the `Listbox`, 'Enable' button, and 'Disable' button widgets. Arrange them using appropriate layout managers (e.g., `pack` or `grid`). Add placeholder methods for button commands and list population."
      },
      {
        "step 3": "Modify the `ExtensionManagerUI` class to interact with the existing `ExtensionManager`. Add an `__init__` parameter to accept an instance of `ExtensionManager`. Store this instance for later use."
      },
      {
        "step 4": "Implement the logic to populate the `Listbox` within `ExtensionManagerUI`. Create a method (e.g., `populate_extension_list`) that retrieves the list of discovered extensions and their enabled/disabled status from the `ExtensionManager`. Format each listbox entry to clearly display the extension's name and its current status (e.g., 'MyPlugin [Enabled]' or 'AnotherPlugin [Disabled]'). Call this method when the UI window is initialized."
      },
      {
        "step 5": "Implement the command for the 'Enable' button. This command should: 1. Get the currently selected extension identifier from the `Listbox`. 2. If an extension is selected, call the appropriate method on the `ExtensionManager` instance to enable the selected extension. 3. Refresh the `Listbox` content by calling `populate_extension_list` to reflect the status change. 4. Handle the case where no extension is selected in the list (e.g., show a status message or disable the button)."
      },
      {
        "step 6": "Implement the command for the 'Disable' button. This command should mirror the 'Enable' button's logic: 1. Get the selected extension identifier. 2. If selected, call the `ExtensionManager` method to disable it. 3. Refresh the `Listbox`. 4. Handle the case where no extension is selected."
      },
      {
        "step 7": "Ensure that the `ExtensionManager`'s methods for enabling/disabling extensions persist the state changes (e.g., by updating a configuration file or internal state). If the `ExtensionManager` doesn't handle persistence yet, update it to save the enabled/disabled status of extensions. The UI interaction should trigger these persistent changes via the manager."
      },
      {
        "step 8": "Integrate the `ExtensionManagerUI` into the main IDE window. Add a menu item (e.g., under 'Tools' or 'View' menu, labelled 'Extensions') or a toolbar button that, when clicked, creates an instance of `ExtensionManagerUI` and displays the extension management window. Pass the main application's `ExtensionManager` instance to the UI."
      },
      {
        "step 9": "Refine the `ExtensionManagerUI`. Add a status bar (e.g., a `Label` widget at the bottom) to provide feedback to the user (e.g., 'Extension X enabled', 'Please select an extension'). Consider disabling the 'Enable'/'Disable' buttons if the selected extension is already in that state. Review the code for clarity and add comments where necessary."
      }
    ],
    "Task 4.21: Document the initial version of the Extension API": [
      {
        "step 1": "Create a new directory named 'docs/api' within the project's root directory to house the Extension API documentation."
      },
      {
        "step 2": "Inside the 'docs/api' directory, create a main documentation file named 'index.md'. This file will serve as the entry point for the API documentation."
      },
      {
        "step 3": "In 'index.md', write an 'Overview' section. Explain the purpose of the Extension API, its high-level capabilities (e.g., adding commands, manipulating text, interacting with the UI), and the target audience (extension developers)."
      },
      {
        "step 4": "Add a 'Getting Started' section to 'index.md'. Describe the minimal steps required to create a basic extension, including the structure of an extension project, the purpose of the manifest file (e.g., `package.json` or similar), and the main entry point script. Refer to the actual manifest structure and entry point function signature defined in previous steps."
      },
      {
        "step 5": "Create a new file 'core_concepts.md' in 'docs/api'. In this file, document key concepts. Start with 'Activation Events': explain what they are, why they are used (performance), and list the currently supported activation events (referencing the implementation from previous tasks)."
      },
      {
        "step 6": "In 'core_concepts.md', document 'Contribution Points'. Explain how extensions declare their contributions (e.g., commands, menu items, settings) typically via the manifest file. List and briefly describe the contribution points implemented so far."
      },
      {
        "step 7": "In 'core_concepts.md', document the 'Command System'. Explain how to register a command using the API (referencing the specific function, e.g., `ide.commands.registerCommand`) and how commands can be invoked (from UI, keybindings, other extensions). Link back to the 'Contribution Points' section for command declaration."
      },
      {
        "step 8": "Link the 'core_concepts.md' file from the main 'index.md' file, perhaps under a 'Core Concepts' heading."
      },
      {
        "step 9": "Create a new file 'api_reference.md' in 'docs/api'. Add a brief introduction explaining that this section provides detailed information about the available API modules and functions. Hint: Review the actual API modules/classes created in previous steps (e.g., related to workspace access, editor manipulation, notifications, commands)."
      },
      {
        "step 10": "In 'api_reference.md', document the main API namespace or object (e.g., `ide` or `vscode`-like object). List the primary modules available under this namespace (e.g., `ide.workspace`, `ide.window`, `ide.editor`, `ide.commands`). For each module, briefly describe its purpose."
      },
      {
        "step 11": "For each core API module identified in the previous step (e.g., `ide.commands`, `ide.editor`), add a subsection in 'api_reference.md'. Document the key functions/methods available in that module. Include function signatures (parameters, types, return values) and a clear description of what each function does. Hint: Use docstrings from the source code as a primary reference and ensure the documentation matches the implementation."
      },
      {
        "step 12": "Document any important data types or interfaces used by the API functions in 'api_reference.md' or a separate 'types.md' file linked from it. For example, if there's a `TextDocument` or `Position` interface, describe its properties."
      },
      {
        "step 13": "Link the 'api_reference.md' file from the main 'index.md' file under an 'API Reference' heading."
      },
      {
        "step 14": "Create an 'examples.md' file in 'docs/api'. Write 1-2 simple, complete code snippets demonstrating common use cases, such as registering a command that shows an information message or inserts text into the active editor. Ensure the examples use the API documented in 'api_reference.md'."
      },
      {
        "step 15": "Link the 'examples.md' file from 'index.md' under an 'Examples' heading."
      },
      {
        "step 16": "Review all created Markdown files ('index.md', 'core_concepts.md', 'api_reference.md', 'examples.md') for clarity, accuracy, consistency, and completeness. Check for broken links, typos, and grammatical errors. Ensure the documentation accurately reflects the *current* state of the implemented Extension API code."
      }
    ],
    "Task 4.22: Create sample extensions to validate the API and demonstrate usage": [
      {
        "step 1": "Create a dedicated directory named `sample_extensions` within the project's `extensions` directory (or equivalent location where extensions reside). This directory will house the source code for the sample extensions."
      },
      {
        "step 2": "Create the directory structure for the first sample extension: `sample_extensions/word_count`. Inside this directory, create an empty Python file named `main.py` and an empty `README.md` file."
      },
      {
        "step 3": "In `sample_extensions/word_count/main.py`, implement the `activate(context)` function. Inside this function: \n1. Use the extension API (e.g., `ide.statusbar.add_item`) to create a new status bar item (initially showing 'Word Count: 0'). Store a reference to this item.\n2. Use the extension API (e.g., `ide.workspace.get_active_editor`) to get the current editor.\n3. Define a helper function `update_word_count()` that gets the text from the active editor (using `editor.get_text()`), calculates the word count, and updates the status bar item's text (using `statusbar_item.set_text()`). Handle cases where there might be no active editor.\n4. Call `update_word_count()` initially if an editor is open.\n5. Register listeners using the extension API for events like `on_active_editor_changed` and `on_document_changed` (or similar events provided by the API). These listeners should call `update_word_count()`.\n6. Store references to the listeners or subscriptions in the `context` object provided to `activate` so they can be disposed of later. \n*Hint: Ensure robust error handling, e.g., if API methods are unavailable or return unexpected values.*"
      },
      {
        "step 4": "In `sample_extensions/word_count/main.py`, implement the `deactivate()` function. This function should use the `context` (or stored references from `activate`) to dispose of the event listeners and remove the status bar item created in the `activate` function (e.g., using `statusbar_item.dispose()` or `ide.statusbar.remove_item()`)."
      },
      {
        "step 5": "Populate `sample_extensions/word_count/README.md` with a brief description of the 'Word Count' extension, explaining what it does (displays the word count of the active editor in the status bar) and how it demonstrates API usage (status bar contribution, editor events, text access)."
      },
      {
        "step 6": "Create the directory structure for the second sample extension: `sample_extensions/hello_command`. Inside this directory, create an empty Python file named `main.py` and an empty `README.md` file."
      },
      {
        "step 7": "In `sample_extensions/hello_command/main.py`, implement the `activate(context)` function. Inside this function:\n1. Define a simple function `say_hello()` that uses the extension API to display an informational message (e.g., `ide.window.show_information_message('Hello from Sample Extension!')`).\n2. Use the extension API (e.g., `ide.commands.register_command`) to register the `say_hello` function with a unique command ID (e.g., `'sample.sayHello'`).\n3. Store the command registration disposable object in the `context`.\n*Hint: Refer to the command registration API defined in previous steps.*"
      },
      {
        "step 8": "In `sample_extensions/hello_command/main.py`, implement the `deactivate()` function. This function should use the `context` to dispose of the command registration created during activation."
      },
      {
        "step 9": "Populate `sample_extensions/hello_command/README.md` with a brief description of the 'Hello Command' extension, explaining how to trigger it (e.g., via a command palette if available) and how it demonstrates API usage (command registration, notification display)."
      },
      {
        "step 10": "Create the directory structure for the third sample extension: `sample_extensions/theme_toggler`. Inside this directory, create an empty Python file named `main.py` and an empty `README.md` file."
      },
      {
        "step 11": "In `sample_extensions/theme_toggler/main.py`, implement the `activate(context)` function. Inside this function:\n1. Define a function `toggle_theme()` that:\n    a. Uses the extension API to get the current theme setting (e.g., `ide.config.get('ui.theme')`). Assume a configuration key like 'ui.theme' exists with values like 'light' and 'dark'.\n    b. Determines the new theme (if current is 'light', set to 'dark', otherwise set to 'light').\n    c. Uses the extension API to update the theme setting (e.g., `ide.config.set('ui.theme', new_theme)`).\n    d. Optionally, shows a notification confirming the theme change.\n2. Register this `toggle_theme` function as a command with ID `'sample.toggleTheme'` using `ide.commands.register_command`.\n3. Store the command registration disposable object in the `context`.\n*Hint: This assumes a configuration API (`ide.config`) exists as defined previously.*"
      },
      {
        "step 12": "In `sample_extensions/theme_toggler/main.py`, implement the `deactivate()` function. This function should use the `context` to dispose of the command registration created during activation."
      },
      {
        "step 13": "Populate `sample_extensions/theme_toggler/README.md` with a brief description of the 'Theme Toggler' extension, explaining its command and how it demonstrates API usage (command registration, configuration access/modification)."
      },
      {
        "step 14": "Ensure each sample extension's directory (`word_count`, `hello_command`, `theme_toggler`) includes any necessary manifest file (e.g., `extension.json` or `pyproject.toml` section) if required by the IDE's extension loading mechanism defined previously. This manifest should specify the entry point (e.g., `main.py` containing `activate`/`deactivate`)."
      },
      {
        "step 15": "Update the IDE's main documentation (e.g., `docs/extensions.md` or `README.md`) to include a section about these sample extensions. Explain their purpose (API validation, usage examples) and mention where to find their source code (`sample_extensions/`)."
      },
      {
        "step 16": "Manually test the loading and functionality of each sample extension within the running IDE. Verify:\n1. 'Word Count' appears in the status bar and updates correctly.\n2. The 'sample.sayHello' command can be executed (e.g., via command palette or keybinding if set up) and shows the message.\n3. The 'sample.toggleTheme' command can be executed and successfully modifies the theme setting (verify through API or observed UI change if applicable).\n*Self-Correction/Refinement:* If testing reveals issues with the extension API, create separate specific prompts to address those API bugs before proceeding.*"
      }
    ]
  },
  "Phase 5: Testing, Performance Optimization & Quality Assurance": {
    "Task 5.1: Define Comprehensive Test Strategy and Test Plans (Unit, Integration, E2E, UI, Usability, Performance, Security)": [
      {
        "step 1": "Create a new document named `TESTING_STRATEGY.md`. Define the overall test strategy for the IDE. Include sections for: Introduction (Purpose, Goals), Scope (In-scope/Out-of-scope features), Testing Types (list all planned types: Unit, Integration, E2E, UI, Usability, Performance, Security), Test Environments (Development, Staging, Production), Roles and Responsibilities (briefly, who does what), and Test Metrics/Reporting."
      },
      {
        "step 2": "Expand the 'Unit Testing' section in `TESTING_STRATEGY.md`. Specify the primary unit testing framework(s) to be used (e.g., `pytest` for Python, `Jest` for TypeScript/JS, `JUnit` for Java, `NUnit` for C# - choose based on the IDE's implementation language). Define the target code coverage percentage (e.g., 80%). Identify critical modules/components requiring high unit test coverage (e.g., core editor logic, file parsers, language service clients, configuration management)."
      },
      {
        "step 3": "Expand the 'Integration Testing' section in `TESTING_STRATEGY.md`. Identify key integration points between different modules or services (e.g., Editor <-> Language Server, Project Manager <-> Build System, Debugger <-> Runtime Environment, UI <-> Backend Services). Describe the strategy for testing these interactions, including the use of mocks, stubs, or dedicated integration test environments. Hint: Consider using containerization (e.g., Docker) for setting up dependent services for integration tests."
      },
      {
        "step 4": "Expand the 'End-to-End (E2E) Testing' section in `TESTING_STRATEGY.md`. Define 5-7 critical user workflows that represent core IDE functionality (e.g., 1. Create project, add file, write 'Hello World', build, run. 2. Open existing project, edit file, use code completion, save. 3. Start debugging session, set breakpoint, step through code, inspect variable. 4. Install/manage a plugin. 5. Use version control integration - commit, push). Specify the E2E testing framework/tools (e.g., Playwright, Cypress, Selenium for web-based UI; platform-specific automation tools like `pywinauto`, `ldtp`, `Appium` for native UI)."
      },
      {
        "step 5": "Expand the 'UI Testing' section in `TESTING_STRATEGY.md`. Detail the approach for testing the graphical user interface. Specify tools for automated UI testing (consistent with E2E tools if possible). Mention strategies for handling UI changes (e.g., selector strategies, visual regression testing tools like Percy or Applitools). List key UI components/areas requiring specific testing (e.g., editor rendering, file explorer tree, terminal input/output, settings dialogs, menus, responsiveness across different layouts/resolutions)."
      },
      {
        "step 6": "Expand the 'Usability Testing' section in `TESTING_STRATEGY.md`. Describe the methods planned for evaluating the IDE's ease of use. Options include: Heuristic Evaluation (using Nielsen's heuristics or similar), Cognitive Walkthroughs, User Surveys/Questionnaires (e.g., SUS - System Usability Scale), and potentially informal Think-Aloud protocols with target users (if feasible for the AI agent to simulate or guide). Define target user profiles (e.g., beginner programmer, experienced polyglot developer). Identify key usability goals (e.g., learnability, efficiency, discoverability of features)."
      },
      {
        "step 7": "Expand the 'Performance Testing' section in `TESTING_STRATEGY.md`. Define key performance indicators (KPIs) and their targets (e.g., IDE startup time < X seconds, file open time for large file < Y ms, code completion latency < Z ms, memory usage under typical load < M MB, CPU usage during build/idle). Specify tools for performance measurement (e.g., built-in profilers, platform monitoring tools, custom benchmarking scripts). Describe performance testing scenarios (e.g., large project load, concurrent operations, long-running sessions, low resource conditions)."
      },
      {
        "step 8": "Expand the 'Security Testing' section in `TESTING_STRATEGY.md`. Identify potential security threat areas relevant to an IDE (e.g., arbitrary code execution via plugins/extensions, insecure handling of project files, vulnerabilities in bundled runtimes/tools, insecure network communication, data leakage through logs or caches, command injection vulnerabilities). Outline planned security testing activities: Static Application Security Testing (SAST) using tools (e.g., Bandit for Python, SonarQube linters), Dynamic Application Security Testing (DAST) if applicable (e.g., OWASP ZAP for web components), Dependency Scanning (e.g., `npm audit`, `pip-audit`, Snyk), and potentially manual code review guidelines focusing on security."
      },
      {
        "step 9": "Review the entire `TESTING_STRATEGY.md` document. Ensure consistency in terminology, clarity in descriptions, and logical flow between sections. Add a summary table mapping each testing type (Unit, Integration, E2E, UI, Usability, Performance, Security) to its primary goals, key metrics/focus areas, and proposed tools/techniques. Ensure the document is well-formatted and easy to read using Markdown."
      }
    ],
    "Task 5.2: Write and Execute Unit Tests for Core Modules and Components": [
      {
        "step 1": "Identify and confirm the testing framework to be used for the IDE project (e.g., `pytest` for Python, `Jest` for Node.js/TypeScript, `JUnit` for Java). If not already set up, install the chosen framework and any necessary plugins (like `pytest-cov` for coverage). Create a standard test directory structure (e.g., `tests/` at the project root) if it doesn't exist. Hint: Use the appropriate package manager (pip, npm, maven, etc.) to install the framework."
      },
      {
        "step 2": "Analyze the project's source code structure (e.g., in `src/` or `ide/`) and list the core modules and components that are critical for the IDE's functionality and require unit testing. Examples include: File Management, Text Editor Core Logic, Syntax Highlighting Engine, Build System Integration Interface, Debugger Communication Interface, Configuration Management. Store this list for reference in subsequent steps."
      },
      {
        "step 3": "Create a new test file (e.g., `tests/test_file_manager.py`) specifically for the File Management module. Write unit tests covering essential file operations: opening files, saving files, creating new files, deleting files, checking file existence, and listing directory contents. Hint: Use mocking libraries (like Python's `unittest.mock` or `pyfakefs`) to isolate tests from the actual file system where appropriate. Test edge cases like non-existent files, permissions errors (mocked), and empty directories."
      },
      {
        "step 4": "Create a new test file (e.g., `tests/test_editor_core.py`) for the core logic of the text editor component (the underlying document model or buffer, not the UI). Write unit tests for text manipulation functions: inserting text, deleting text, replacing text, getting text content, undo/redo functionality, cursor position logic (if applicable in the core). Hint: Focus on the data structures and algorithms managing the text, mocking any UI dependencies."
      },
      {
        "step 5": "Create a new test file (e.g., `tests/test_syntax_highlighting.py`) for the Syntax Highlighting engine. Write unit tests for the tokenization or parsing logic. Provide sample code snippets in the languages supported by the IDE. Verify that the engine correctly identifies tokens (keywords, identifiers, comments, strings, etc.) or applies the expected scopes/styles (mock the actual style application if it's UI-dependent). Hint: Test with simple and complex code structures, including edge cases and potential syntax errors."
      },
      {
        "step 6": "Create a new test file (e.g., `tests/test_build_integration.py`) for the Build System Integration module. Write unit tests for functions that prepare build commands, execute them, and parse their output. Hint: Mock external process execution (e.g., `subprocess.run` in Python, `child_process.exec` in Node.js) to avoid running actual compilers or build tools. Test the parsing of various outputs (success messages, error messages, warnings)."
      },
      {
        "step 7": "Create a new test file (e.g., `tests/test_debugger_interface.py`) for the Debugger Communication Interface. Write unit tests for functions that interact with a debugger backend (e.g., via Debug Adapter Protocol - DAP). Mock the communication channel or the debugger process itself. Test functions for setting/removing breakpoints, stepping commands (step over, step into, step out), resuming execution, and requesting variable/stack information."
      },
      {
        "step 8": "Create a new test file (e.g., `tests/test_config_manager.py`) for the Configuration Management module. Write unit tests for loading configuration settings from files (e.g., JSON, INI, YAML), saving settings, retrieving setting values, and handling default values. Hint: Use temporary files or a mocked file system to avoid interfering with actual user configuration."
      },
      {
        "step 9": "Execute all the unit tests written in the previous steps using the chosen test runner (e.g., run `pytest` in the terminal from the project root). Ensure the runner discovers and executes all tests within the `tests/` directory. Capture the results."
      },
      {
        "step 10": "Generate a test coverage report. If using `pytest`, ensure `pytest-cov` is installed and run the tests with coverage enabled (e.g., `pytest --cov=<your_source_directory> --cov-report term-missing`). <your_source_directory> is the main directory containing the IDE's code (e.g., `src`, `ide`). Review the report."
      },
      {
        "step 11": "Analyze the test execution results and the coverage report. Identify any failing tests and debug them. Identify core modules or functions with low test coverage. Based on this analysis, write additional unit tests to cover critical gaps identified in the coverage report or to address any discovered bugs. Re-run tests and coverage analysis until a satisfactory level of quality is achieved."
      }
    ],
    "Task 5.3: Write and Execute Integration Tests for Interactions Between Components": [
      {
        "step 1": "Analyze the existing IDE components (e.g., file explorer, editor, terminal, build system, debugger, language server client) and identify the key interfaces and workflows where they interact. List at least 5 critical interaction points. For example: File Explorer selection updating Editor, Editor triggering Build System, Build System output appearing in Terminal/Output Panel, Editor setting breakpoints for Debugger, Debugger controlling execution flow, Editor sending requests to Language Server."
      },
      {
        "step 2": "Based on the identified interaction points and the project's language/framework, determine the most suitable integration testing strategy. Consider options like service-level integration tests (testing component APIs directly), potentially using mocking for external dependencies, or higher-level tests simulating user workflows. Confirm the testing framework (e.g., Pytest, Jest, Go testing package) to be used, ensuring it's set up from previous testing phases or configuring it now. Hint: If using Pytest, consider using fixtures (`pytest.fixture`) to manage component setup and teardown. If using Jest, explore mocking capabilities (`jest.mock`)."
      },
      {
        "step 3": "Define detailed test scenarios for the interaction between the File Explorer and the Editor. Scenarios should cover: 1) Selecting a file in the explorer opens it in the editor. 2) Selecting a different file replaces the content in the editor (or opens a new tab, depending on IDE design). 3) Attempting to open an unsupported file type results in appropriate feedback (e.g., an error message, no action). 4) Opening a file triggers syntax highlighting (if applicable, may need LSP interaction test later)."
      },
      {
        "step 4": "Implement the integration test cases defined in the previous step for the File Explorer -> Editor interaction. Instantiate or mock the necessary components. Use assertions to verify that the editor's state (e.g., current file path, content, active tab) changes correctly based on actions simulated on the file explorer. Place these tests in an appropriate integration test directory (e.g., `tests/integration`). Hint: Ensure tests clean up after themselves, closing files or resetting component states."
      },
      {
        "step 5": "Define detailed test scenarios for the interaction between the Editor, Build System, and Terminal/Output Panel. Scenarios should cover: 1) Triggering a 'build' action from the editor (e.g., via command or menu) invokes the build system. 2) Build system output (stdout, stderr) is correctly routed to and displayed in the terminal or output panel. 3) Build success/failure status is correctly reported (e.g., UI notification, status bar update). 4) Triggering a 'run' action executes the compiled code (if applicable) and shows its output."
      },
      {
        "step 6": "Implement the integration test cases for the Editor -> Build System -> Terminal/Output interaction. Mock external build tools if necessary, focusing on the communication flow between IDE components. Instantiate the Editor, Build System handler, and Terminal/Output panel. Simulate the 'build' or 'run' trigger and assert that the build system method is called and that the expected output appears in the correct UI panel component. Hint: You might need asynchronous testing utilities if interactions involve background processes."
      },
      {
        "step 7": "Define detailed test scenarios for the interaction between the Editor and the Debugger. Scenarios should cover: 1) Setting a breakpoint in the editor is registered by the debugger backend. 2) Starting a debug session launches the target process and pauses at the first breakpoint. 3) Stepping actions (step over, step into, step out) initiated via UI/commands correctly control the debugger backend. 4) Variable inspection requests retrieve and display correct data from the debugger. 5) Execution resuming correctly after a breakpoint."
      },
      {
        "step 8": "Implement the integration test cases for the Editor -> Debugger interaction. This might require a mock debugger backend conforming to the Debug Adapter Protocol (DAP) or interacting with a simple dummy application. Instantiate the Editor and Debugger components. Simulate setting breakpoints, starting debugging, and stepping. Assert that the debugger state (e.g., paused line, call stack, variable values) is updated correctly and reflected potentially back in the Editor UI state (e.g., highlighted line). Hint: DAP interactions are often asynchronous JSON-RPC messages."
      },
      {
        "step 9": "Define detailed test scenarios for the interaction between the Editor and the Language Server Client (LSP). Scenarios should cover: 1) Opening a relevant file triggers LSP initialization and `textDocument/didOpen` notification. 2) Editing text triggers `textDocument/didChange`. 3) Requesting code completion (`textDocument/completion`) returns expected suggestions. 4) Requesting go-to-definition (`textDocument/definition`) navigates correctly or returns the correct location. 5) Diagnostics (errors/warnings) received from the server are displayed in the editor (e.g., underlines, markers)."
      },
      {
        "step 10": "Implement the integration test cases for the Editor -> Language Server Client interaction. Use a mock LSP server or a very simple real LSP server for a basic language if feasible. Instantiate the Editor and LSP client components. Simulate file operations and editor actions (typing, requesting completion/definition). Assert that the correct LSP messages are sent from the client and that responses/notifications from the (mock) server are correctly processed and reflected in the editor's state or UI feedback. Hint: Focus on the client's ability to communicate and interpret LSP messages correctly."
      },
      {
        "step 11": "Review all implemented integration tests. Ensure proper setup and teardown for each test or suite (e.g., using fixtures, `beforeEach`/`afterEach` hooks). Make sure tests use distinct resources where necessary (e.g., temporary files/directories for file operations) and clean them up reliably to avoid interference. Consolidate common setup logic if possible."
      },
      {
        "step 12": "Configure the test runner (e.g., Pytest, Jest) to discover and execute these integration tests. If not already done, you might want to tag or place them in a specific directory (`tests/integration`) to run them separately from unit tests. Update any CI/CD pipeline configuration files (e.g., `.github/workflows/main.yml`, `gitlab-ci.yml`) to include a stage for running integration tests. Hint: Pytest can use markers (`@pytest.mark.integration`), Jest can use test file naming conventions or directory structures."
      },
      {
        "step 13": "Execute the full suite of integration tests. Capture the output, including test results and any logs or errors generated during the test run."
      },
      {
        "step 14": "Analyze the integration test results. Identify any failing tests. For each failure, provide a summary of the expected vs. actual behavior and suggest potential causes related to the interaction between the involved components. Create tickets or issues for any bugs found. If all tests pass, report success."
      }
    ],
    "Task 5.4: Develop and Automate End-to-End Test Scenarios Simulating User Workflows": [
      {
        "step 1": "Analyze the IDE's architecture (e.g., web-based, desktop Electron, desktop native) and select an appropriate end-to-end (E2E) testing framework. **Hint:** Consider frameworks like Playwright (versatile for web and Electron), Cypress (web-focused), or potentially OS-level automation tools if it's a native desktop app. Install the chosen framework and its dependencies."
      },
      {
        "step 2": "Configure the chosen E2E testing framework for the IDE project. This includes setting up base URLs (if web-based), application paths (if desktop), screen resolution defaults, and any necessary environment variables. **Hint:** Create configuration files (e.g., `playwright.config.js`, `cypress.json`) and potentially helper scripts to launch the IDE in a testable state."
      },
      {
        "step 3": "Identify 3-5 critical user workflows for the IDE that cover core functionalities. Examples: 1) Create a new project/file, write simple code, save it. 2) Open an existing project/file, edit code, trigger a build/compile command (if applicable), check output. 3) Use the search/replace feature within a file. 4) Run/debug a simple program (if applicable), check output/debugger state. Document these workflows briefly."
      },
      {
        "step 4": "Implement the first E2E test case based on Workflow 1 (Create, Edit, Save). Write a script using the chosen framework to automate: launching the IDE, interacting with UI elements (menus, buttons, editor pane) or commands to create a file, typing text into the editor, triggering the save action, and verifying the file exists with the correct content. **Hint:** Use appropriate selectors (CSS, XPath, accessibility IDs), wait mechanisms (wait for element visibility/state), and file system assertions."
      },
      {
        "step 5": "Implement the second E2E test case based on Workflow 2 (Open, Edit, Build/Run). Write a script to automate: opening a pre-defined test project/file, making modifications, triggering the build/run command via UI or command palette, capturing the output (from a terminal panel, status bar, or output file), and asserting the expected outcome. **Hint:** Prepare necessary fixture files/projects beforehand. Handle asynchronous operations like build/run completion."
      },
      {
        "step 6": "Implement the third E2E test case based on Workflow 3 (Search/Replace). Write a script to automate: opening a file with known content, activating the search feature, entering search text, verifying highlights or matches, activating replace, entering replacement text, triggering replace (single or all), and verifying the file content has been updated correctly. **Hint:** Pay attention to focusing elements and simulating keyboard inputs accurately."
      },
      {
        "step 7": "Refactor the E2E test scripts for maintainability and reusability. Abstract common actions (e.g., opening file, saving file, getting editor content) into helper functions or classes. If using a UI framework, consider implementing the Page Object Model (POM) pattern. **Hint:** Group tests logically (e.g., by feature) and ensure clear naming conventions."
      },
      {
        "step 8": "Enhance the tests with more robust assertions. Instead of just checking for file existence, verify specific file content, UI element states (enabled/disabled, visible/hidden), output messages in integrated terminals or panels, and application state changes where possible. **Hint:** Use the assertion library provided by your E2E framework (e.g., Playwright's `expect`, Cypress's `should`). Add negative test scenarios where appropriate (e.g., saving fails if no filename)."
      },
      {
        "step 9": "Configure the test runner provided by the framework to execute all E2E tests. Set up command-line scripts (e.g., in `package.json` if Node-based) to easily run the entire E2E test suite. **Hint:** Explore options for parallel execution (if supported and safe for your tests) and reporting formats (e.g., JUnit XML for CI integration)."
      },
      {
        "step 10": "Document the E2E testing setup. Add comments to the test scripts explaining complex steps or non-obvious interactions. Create or update a README file explaining how to install dependencies, configure the environment (if needed), and run the E2E tests. **Hint:** Include instructions for running specific tests or suites."
      }
    ],
    "Task 5.5: Implement Automated UI Tests for Key Interface Elements and Interactions": [
      {
        "step 1": "Research and select an appropriate UI testing framework compatible with the IDE's technology stack (e.g., Electron, PyQt, Web-based). **Hint:** For Electron apps, consider Playwright or WebDriverIO. For PyQt, look into `pytest-qt`. Document the chosen framework and the rationale for its selection in the project's testing documentation."
      },
      {
        "step 2": "Install the selected UI testing framework (e.g., `npm install --save-dev playwright @playwright/test` if using Playwright with Node.js/Electron). Configure the framework to target the IDE application executable or build output. **Hint:** Refer to the chosen framework's documentation for setup instructions, especially regarding Electron application testing if applicable. Create a dedicated 'tests/ui' directory for these tests."
      },
      {
        "step 3": "Write the first basic UI test: Launch the IDE application and verify that the main window appears and essential UI panels (e.g., File Explorer, Editor Area, Status Bar) are visible. **Hint:** Use the framework's API to launch the application process and use selectors (IDs, classes, data-testid attributes) to locate and assert the presence of key elements. Ensure proper setup and teardown (closing the application) for each test."
      },
      {
        "step 4": "Implement UI tests for the File Explorer: \n1. Verify that clicking a folder expands/collapses its contents. \n2. Verify that clicking a file opens it in the editor area. \n3. Verify that right-clicking a file/folder shows a context menu (if implemented). \n**Hint:** You may need to interact with tree view elements. Use element state assertions (e.g., 'is visible', 'is expanded'). Add `data-testid` attributes to elements in the IDE's code if they are hard to select otherwise."
      },
      {
        "step 5": "Implement UI tests for the Code Editor: \n1. Open a sample file (programmatically or via File Explorer interaction). \n2. Simulate typing text into the editor. \n3. Verify the text appears correctly. \n4. Simulate saving the file (e.g., clicking a save button or using a keyboard shortcut command). Verify any visual feedback (e.g., dirty indicator disappearing). \n5. Test basic find functionality: open find, type text, verify highlighting or navigation. \n**Hint:** Use framework functions for keyboard input (`page.keyboard.type`), clicking elements (`page.click`), and checking element text content or attributes."
      },
      {
        "step 6": "Implement UI tests for the integrated Terminal (if applicable): \n1. Simulate opening the terminal panel. \n2. Verify the terminal prompt is visible. \n3. Simulate typing a simple command (e.g., `echo 'test'`) and pressing Enter. \n4. Verify the command's output appears in the terminal view. \n**Hint:** Interacting with terminal emulators can be tricky. Focus on sending input and checking the visible output text within the terminal's container element."
      },
      {
        "step 7": "Implement UI tests for core action buttons (e.g., Build, Run, Debug): \n1. Locate and simulate clicking the 'Build' button. \n2. Locate and simulate clicking the 'Run' button. \n**Hint:** Since these actions might trigger complex background processes, the test might only verify that the button click is registered (e.g., button state changes, a notification appears, or a specific event is logged/emitted). Mocking the underlying build/run process might be necessary for stable UI tests."
      },
      {
        "step 8": "Implement a UI test for the Settings interface: \n1. Simulate opening the settings view/dialog. \n2. Locate a simple setting control (e.g., theme selector dropdown, font size input). \n3. Simulate changing the setting. \n4. Verify the change is reflected (e.g., a class change on the body element for theme, input value updated). \n5. Close the settings view/dialog. \n**Hint:** Ensure selectors are robust enough to handle potential changes in the settings UI structure."
      },
      {
        "step 9": "Review all implemented UI tests for stability, reliability, and clarity. Refactor tests to use page object models or similar patterns if complexity increases, improving maintainability. Ensure tests clean up after themselves properly. **Hint:** Add comments explaining complex interactions or assertions. Ensure consistent use of selectors and wait strategies to avoid flaky tests."
      },
      {
        "step 10": "Integrate the UI test suite into the project's testing workflow. Update the main test script (e.g., `npm test` or `pytest`) to include running the UI tests. Configure CI/CD pipeline (if used) to execute UI tests, potentially on a specific environment or schedule due to their longer execution time. **Hint:** UI tests often require a graphical environment. Ensure the CI environment is configured correctly (e.g., using xvfb on Linux)."
      }
    ],
    "Task 5.6: Conduct Manual Exploratory Testing to Discover Edge Cases and Unforeseen Issues": [
      {
        "step 1": "Analyze the IDE's implemented features based on the current project state (e.g., file management, text editor capabilities, syntax highlighting, build system integration, debugging support, UI layout). Create a markdown file named `exploratory_testing_charter.md`. In this file, define specific 'missions' or areas of focus for exploratory testing. Examples: 'Robustness of file operations with unusual inputs', 'Editor performance and stability with large/complex files', 'Interaction between build processes and file editing', 'UI responsiveness under rapid interaction', 'Graceful handling of external tool failures (compiler/debugger)'. For each mission, list potential risks or types of edge cases to probe."
      },
      {
        "step 2": "Focus on 'File Operations'. Simulate or script interactions to test edge cases: creating/opening/saving files with names exceeding OS limits, containing special characters (`/`, `\\`, `:`, `*`, `?`, `\"`, `<`, `>`, `|`, control chars, Unicode), accessing read-only files/directories, handling non-existent paths gracefully. Simulate opening/editing extremely large files (e.g., generate a 500MB+ text file) and monitor IDE responsiveness and memory usage. Simulate rapid sequences of file creation/deletion/renaming. Log all unexpected behaviors (crashes, hangs, errors, data corruption) with steps to reproduce in a temporary log file."
      },
      {
        "step 3": "Focus on the 'Text Editor'. Simulate or script interactions to test its robustness: load files with invalid character encodings (e.g., mixed UTF-8/Latin-1, invalid byte sequences). Paste very large amounts of text (e.g., >10MB) at once. Perform rapid and long sequences of undo/redo operations (>100 times). Input and manipulate text containing diverse and complex Unicode characters (e.g., emojis, right-to-left scripts, combining characters). Load files with deliberately broken syntax for supported languages and observe syntax highlighting/parsing behavior (should not crash, ideally indicate errors). Test scrolling and editing performance near the beginning/end of very large files. Append findings to the temporary log file."
      },
      {
        "step 4": "Focus on 'Build/Run/Debug Integration'. Simulate or script interactions testing these features under adverse conditions: configure build commands with invalid paths or non-executable targets. Attempt to build projects known to contain errors (syntax errors, linker errors). If possible, simulate forceful interruption (e.g., sending SIGINT/SIGTERM) of ongoing build/run processes and check IDE state recovery. If debugging is implemented, test setting breakpoints in tricky locations (e.g., recursion, tight loops), rapidly stepping through code, inspecting potentially huge data structures, and simulating unexpected termination of the debuggee or debugger process. Append findings to the temporary log file."
      },
      {
        "step 5": "Focus on 'UI Interactions and Responsiveness'. Simulate or script interactions targeting the user interface: perform rapid resizing, maximizing, and minimizing of the main IDE window and internal panels/tabs. Simulate opening a large number of files/tabs concurrently (e.g., 50+). Trigger keyboard shortcuts repeatedly or in unusual contexts (e.g., during modal dialogs, while a process is running). If drag-and-drop is implemented, test dragging unexpected items or dropping in invalid locations. Analyze UI event handling code for potential race conditions if direct simulation is difficult. Append findings related to freezes, visual glitches, high CPU usage, or crashes to the temporary log file."
      },
      {
        "step 6": "Focus on 'Feature Interactions'. Design and simulate scenarios where multiple features are used concurrently or in rapid succession in potentially conflicting ways: edit a file that is actively being built. Rename/delete a file that is open in the editor or part of the current debug session. Initiate a project-wide search while a build is running. Change critical project settings (like compiler path) during an active debug session. Observe and log any deadlocks, inconsistent states, error messages, data loss, or crashes resulting from these interactions. Append findings to the temporary log file."
      },
      {
        "step 7": "Focus on 'Error Handling and Recovery'. Intentionally trigger error conditions and observe the IDE's response: simulate disk full errors during file saving (if possible via mocks or filesystem manipulation). Configure the IDE to use paths for essential external tools (compiler, linter, debugger) that do not exist or are incorrect. Provide malformed project or configuration files. If network access is involved, simulate network disconnections. Analyze how the IDE reports errors (e.g., clear messages, cryptic codes, silent failures) and whether it recovers to a stable state or requires a restart. Append findings to the temporary log file."
      },
      {
        "step 8": "Consolidate and report all findings. Process the temporary log file created in the previous steps. Create a final report named `exploratory_testing_report.md`. For each distinct issue identified, provide: a descriptive title, the feature area affected, detailed steps to reproduce the issue (based on the simulation performed), the observed behavior, the expected behavior, an estimated severity (e.g., Blocker, Critical, Major, Minor, Trivial), and any relevant error messages or logs captured. Structure the report for clarity, potentially grouping issues by feature or severity."
      }
    ],
    "Task 5.7: Organize and Conduct Usability Testing Sessions with Target Users": [
      {
        "step 1": "Define the target user profiles and key usability goals for the IDE based on the project's requirements and current features. Document these profiles (e.g., student developer, professional Python developer) and goals (e.g., ease of project creation, efficiency of code completion, clarity of debugger). Hint: Review any existing project documentation or personas. Focus goals on core IDE workflows implemented so far."
      },
      {
        "step 2": "Develop a set of 5-7 realistic task scenarios for usability testing, reflecting common activities performed by the target users within the IDE. Ensure tasks are specific, actionable, and cover the key usability goals defined in Step 1. Hint: Example tasks: 'Create a new Python project, add a file, write a simple function, and run it.', 'Use the debugger to step through a provided buggy script and identify the error.', 'Refactor a variable name across multiple files.'"
      },
      {
        "step 3": "Generate the necessary materials for conducting usability testing sessions. This includes: 1) A participant consent form template. 2) A pre-session questionnaire to gather background information. 3) A post-session questionnaire (e.g., including the System Usability Scale - SUS, or Single Ease Question - SEQ per task). 4) Clear instructions for each task scenario developed in Step 2. Hint: Search the web for standard usability testing templates and scales (like SUS). Consider generating these as plain text or markdown files."
      },
      {
        "step 4": "Draft a participant recruitment plan. Define the screening criteria based on the target user profiles (Step 1). Create screener questions to identify suitable participants. Suggest potential channels for recruitment (e.g., developer communities, university forums, internal contacts). Note: Actual recruitment is an external action requiring human intervention. Hint: Specify the desired number of participants (typically 5-8 per user group for qualitative usability testing)."
      },
      {
        "step 5": "Generate a logistics plan checklist for organizing the usability testing sessions. Include items like: scheduling coordination, choice of venue (remote/in-person), required hardware/software setup, remote testing tools (e.g., screen sharing, video conferencing software), session recording methods (screen, audio, video - ensure consent), and roles (facilitator, note-taker). Note: Executing this plan involves external actions."
      },
      {
        "step 6": "Generate a detailed facilitator's guide script for conducting a usability testing session. The script should include: introduction (purpose, process, confidentiality, recording), pre-session questionnaire administration, instructions for thinking aloud, presenting task scenarios one by one, neutral probing questions to ask if participants get stuck or make comments, post-task questions (e.g., SEQ), post-session questionnaire administration, and closing remarks/thank you. Hint: Emphasize that the facilitator should remain neutral and avoid leading the participant."
      },
      {
        "step 7": "Design a data collection and analysis plan. Specify how observations will be recorded (e.g., note-taking template focusing on actions, errors, comments, task completion). Define key metrics to collect (e.g., task success rate, time on task, error count, SUS score). Outline the analysis methodology (e.g., qualitative thematic analysis of observations and comments, quantitative analysis of metrics, categorization of usability issues by severity). Hint: Create a simple spreadsheet template for note-taking and data aggregation."
      },
      {
        "step 8": "Generate a template structure for the final Usability Test Report. The template should include standard sections: Introduction (Goals, Methodology), Participant Demographics, Key Findings (Positive and Negative, supported by data/quotes), Analysis (including metrics, issue severity), Recommendations for Improvement (prioritized), and Appendix (raw data summaries, questionnaires). Hint: Structure the report for clarity and actionability, focusing on evidence-based findings and concrete recommendations."
      }
    ],
    "Task 5.8: Set Up and Configure Bug Tracking System (if not already done)": [
      {
        "step 1": "Identify the Version Control System (VCS) host currently used for the IDE project (e.g., GitHub, GitLab, Bitbucket, local Git repository). Check if an issue tracking system associated with this host (like GitHub Issues or GitLab Issues) is already enabled or if any other bug tracking mechanism (e.g., a specific file, project management tool) is currently in use. Report your findings."
      },
      {
        "step 2": "Based on the VCS host identified, recommend using its integrated issue tracker (e.g., GitHub Issues, GitLab Issues) as the primary bug tracking system, explaining the benefits of integration (e.g., linking commits/PRs to issues). If no integrated option is suitable or available, research and recommend an alternative free or open-source bug tracking system, considering ease of setup and use. *Hint: Assume the integrated option (e.g., GitHub Issues) is preferred unless there's a strong reason against it.*"
      },
      {
        "step 3": "Define a standard set of labels for categorizing issues in the chosen tracking system. Create labels covering: Issue Type (`bug`, `feature-request`, `task`, `question`, `documentation`), Priority (`critical`, `high`, `medium`, `low`), IDE Component (`editor`, `debugger`, `file-explorer`, `terminal`, `ui`, `core`, `plugin-api`), and Status (`needs-triage`, `confirmed`, `in-progress`, `blocked`, `needs-review`). Output this list in a structured format (e.g., Markdown list or JSON). *Hint: These labels will help organize and prioritize work.*"
      },
      {
        "step 4": "Create standardized templates for submitting bug reports and feature requests. Design these in Markdown format. The bug report template should prompt for: Description, Steps to Reproduce, Expected Behavior, Actual Behavior, Environment (OS, IDE Version), and Logs/Screenshots. The feature request template should prompt for: Problem Description, Proposed Solution/Feature, Motivation/Use Case, and Alternatives Considered. *Hint: If using GitHub/GitLab, place these templates in `.github/ISSUE_TEMPLATE/` or `.gitlab/issue_templates/` respectively. Create files like `bug_report.md` and `feature_request.md`.*"
      },
      {
        "step 5": "Update the project's documentation (e.g., `README.md` or preferably `CONTRIBUTING.md`) to include guidelines on using the bug tracking system. This section should cover: how and where to submit new issues (linking to the tracker), how to use the defined labels and issue templates, the importance of clear descriptions and reproduction steps, and the process for linking commits/pull requests to issues (e.g., using keywords like `Fixes #123`, `Closes #123`)."
      },
      {
        "step 6": "Review the project's source code comments (searching for `TODO`, `FIXME`), existing documentation, and outputs from previous testing phases for any known bugs, unresolved issues, or planned enhancements that are not yet formally tracked. For each identified item, formulate a draft issue description using the appropriate template created in Step 4 and suggest relevant labels from Step 3. Present these drafts for review. *Hint: This helps populate the bug tracker initially. Actual creation might require manual action or specific API access.*"
      }
    ],
    "Task 5.9: Execute Defined Test Plans, Log Defects, and Track Test Coverage": [
      {
        "step 1": "Locate the comprehensive test plans defined in Task 5.1. These might be in Markdown files, documents, or a dedicated test management structure within the project repository. Identify the locations of unit, integration, end-to-end (E2E), and manual test cases."
      },
      {
        "step 2": "Prepare the testing environment. Ensure the latest version of the IDE code is built and accessible. Verify that all testing frameworks (e.g., pytest, Jest, Playwright, Selenium) and their dependencies, including any necessary drivers or browsers, are installed and correctly configured as specified in the project setup."
      },
      {
        "step 3": "Execute the automated unit and integration test suites. Use the configured test runner (e.g., `pytest`, `npm test`). Capture the detailed output, including pass/fail status for each test case and any error messages or stack traces for failures. *Hint: Redirect output to a log file for easier analysis.*"
      },
      {
        "step 4": "Execute the automated end-to-end (E2E) test suite using the appropriate framework (e.g., Playwright, Selenium, Cypress). Ensure tests run against the correct build or deployment of the IDE. Capture detailed results, including pass/fail status, error messages, and consider capturing screenshots or videos for failed tests if the framework supports it. *Hint: Store E2E results and artifacts in a dedicated directory.*"
      },
      {
        "step 5": "Process the manual test cases outlined in the test plan. Generate a checklist or structured document (e.g., Markdown table, CSV) detailing the steps, expected results, and providing space to record the actual results and pass/fail status for each manual test. *Note: Actual execution may require human intervention, but prepare the necessary documentation for tracking.*"
      },
      {
        "step 6": "Aggregate all test results. Combine the outputs from unit, integration, and E2E test runs. Create a consolidated report (e.g., in JSON or CSV format) listing each test case (automated and manual), its type, execution status (Pass, Fail, Skipped, Pending for manual), and references to any relevant logs or artifacts."
      },
      {
        "step 7": "Analyze the aggregated test results for failures. For each failed test case (from any category), create a detailed defect report. Use a standard template including: Defect ID, Summary, Steps to Reproduce, Expected Result, Actual Result, Severity/Priority (as defined in test plan), Environment Details, Associated Test Case ID, Logs/Screenshots (if available). *Hint: Store defects in a structured format like JSON, CSV, or prepare them for entry into an issue tracking system.*"
      },
      {
        "step 8": "Measure code coverage achieved by the automated tests (unit and integration). Re-run these tests using coverage measurement tools (e.g., `pytest --cov`, `jest --coverage`, `coverage.py run`). Generate a coverage report, preferably in multiple formats like HTML (for browsing) and XML/JSON (for machine processing). *Hint: Ensure coverage configuration excludes test files themselves and third-party libraries.*"
      },
      {
        "step 9": "Analyze the generated code coverage report. Determine the overall coverage percentage and identify specific modules, files, or functions with low coverage (<70% might be a starting threshold, adjust based on project standards). Document these findings."
      },
      {
        "step 10": "Generate a final Test Execution Summary Report (e.g., in Markdown). This report should include: \n- Date and time of execution.\n- Environment details.\n- Summary statistics (Total Tests, Passed, Failed, Skipped by type - Unit, Integration, E2E, Manual).\n- Link to the consolidated results file (from Step 6).\n- List of new defects logged (IDs and summaries) with links/references (from Step 7).\n- Overall code coverage percentage and link to the detailed coverage report (from Step 8/9).\n- Areas identified with low coverage (from Step 9)."
      }
    ],
    "Task 5.10: Triage, Prioritize, Assign, and Verify Bug Fixes": [
      {
        "step 1": "Access the consolidated bug report log generated during previous testing phases (unit, integration, E2E testing, static analysis, usability testing). Ensure all reported issues are accessible. Hint: This might be a file (e.g., `bugs.json`, `bugs.csv`), a database table, or stored in memory from a previous step."
      },
      {
        "step 2": "Initiate the Triage process. Iterate through each reported bug. For each bug, attempt to reproduce it using the provided steps and context. Validate if it's a genuine, non-duplicate issue within the IDE project. Mark reports that cannot be reproduced, are duplicates, or are feature requests rather than bugs."
      },
      {
        "step 3": "For each validated bug, assess and categorize its severity (e.g., Critical, High, Medium, Low) and impact (e.g., Blocker, Data Loss, Crash, Major Functionality Broken, Performance Degradation, UI/UX Issue, Minor Inconvenience). Append this severity and impact information to the bug report data. Hint: Define simple criteria: Critical = crash/data loss/blocker; High = major feature unusable; Medium = significant feature impaired/performance issue; Low = cosmetic/minor issue."
      },
      {
        "step 4": "Prioritize the list of validated bugs based primarily on severity and impact. Create a sorted list or add a priority field (e.g., P1, P2, P3, P4). Critical/Blocker bugs should be highest priority (P1), followed by High severity, then Medium, and finally Low. Hint: Consider factors like frequency of occurrence if that data is available."
      },
      {
        "step 5": "Update the status of the bugs in the prioritized list to reflect their readiness for fixing (e.g., 'Triaged', 'Prioritized', 'Ready for Development'). Persist this prioritized and updated bug list (e.g., overwrite the bug log file or update the database). This list now serves as the immediate backlog for fixing."
      },
      {
        "step 6": "Define a standard verification protocol for bug fixes. This protocol should specify that verification must include: (1) Executing the original steps to reproduce the bug to confirm it is resolved. (2) Executing related existing tests (unit, integration, E2E) to check for regressions. (3) Potentially adding a new test case specifically for the fixed bug, if not already covered. Document this protocol briefly."
      },
      {
        "step 7": "Simulate or perform the fix for the highest priority bug (P1) identified in Step 4. (If performing the fix is too complex for one step, create a placeholder comment indicating where the fix would occur). Then, apply the verification protocol defined in Step 6 to this specific fix. Execute the necessary checks and tests."
      },
      {
        "step 8": "Based on the outcome of Step 7, update the status of the verified bug in the bug list. If the fix is confirmed and no regressions are found, mark the bug as 'Verified' or 'Closed'. If the fix is incomplete or introduced new issues, mark it as 'Failed Verification' or 'Reopened', adding notes about the verification failure. Persist this final status update."
      }
    ],
    "Task 5.11: Establish and Execute Regression Test Suites after Code Changes and Bug Fixes": [
      {
        "step 1": "Analyze the existing test files within the project. Identify the testing frameworks being used (e.g., pytest, unittest, Jest, Cypress, Playwright) and the current organization of test cases (e.g., by module, by feature, by type - unit/integration/e2e)."
      },
      {
        "step 2": "Based on the analysis, propose a logical categorization for the existing tests to form distinct regression suites. Consider categories like 'core_unit', 'editor_integration', 'ui_e2e', 'file_management', 'build_system', 'debugger_features'. Document these proposed categories."
      },
      {
        "step 3": "If the primary testing framework supports tagging or marking (e.g., pytest markers, Jest tags), refactor the existing test files to apply the appropriate category tags defined in the previous step to each test or group of tests. If tagging isn't directly supported, organize tests into subdirectories corresponding to the categories."
      },
      {
        "step 4": "Create or update scripts (e.g., shell scripts, `package.json` scripts, Makefile targets) to execute specific regression test suites based on the categories/tags/directories established. Ensure there's a command to run a specific suite (e.g., `npm run test:ui_e2e` or `pytest -m editor_integration`) and a command to run *all* regression tests."
      },
      {
        "step 5": "Define and document a policy for regression testing. Specify *when* these suites should be run (e.g., 'Run relevant suite(s) after any code change impacting that module', 'Run all suites before merging feature branches to main', 'Run specific test related to a bug fix after applying the fix'). Add this policy to the project's `README.md` or a dedicated `TESTING.md` file."
      },
      {
        "step 6": "Update the project documentation (`README.md` or `TESTING.md`) to include clear instructions on how developers (or the AI agent itself) can execute the different regression test suites using the scripts created in Step 4. List the available categories/suites."
      },
      {
        "step 7": "Identify a recent bug fix or a simple, safe area for a minor code modification (e.g., refactoring a small utility function). Make the modification. If it was a bug fix, ensure a specific test exists that verifies the fix and is part of a regression suite. If it was a refactor, identify the relevant regression suite(s)."
      },
      {
        "step 8": "Execute the relevant regression test suite(s) identified in the previous step using the newly created scripts/commands. Verify that all tests pass, confirming that the recent change did not introduce regressions in the tested areas."
      },
      {
        "step 9": "As a final check, execute the command to run *all* regression test suites. Report the results, ensuring the entire suite passes, demonstrating the comprehensive regression testing capability."
      }
    ],
    "Task 5.12: Profile Application Performance: CPU Usage, Memory Consumption, I/O, Startup Time": [
      {
        "step 1": "Identify the primary programming language and UI framework used for the IDE project. Based on this, list the recommended built-in and third-party tools available for profiling CPU usage, memory consumption, I/O operations, and startup time. (Hint: Consider tools like `cProfile`, `memory_profiler`, `tracemalloc`, `py-spy` for Python; Chrome/Edge DevTools, `--prof`, `heapdump` for Electron/Node.js; Visual Studio Profiler, dotTrace for C#; JProfiler, VisualVM for Java; Valgrind, Perf, Instruments for C++; OS-level tools like `time`, `top`/`htop`, Task Manager, `iotop`, Resource Monitor)."
      },
      {
        "step 2": "Install any necessary profiling tools identified in the previous step that are not already part of the development environment or standard build process. Ensure they are compatible with the project's dependencies. (Hint: Use the appropriate package manager like pip, npm, apt, brew, etc.)"
      },
      {
        "step 3": "Measure the application's startup time. Run the IDE executable multiple times (e.g., 5-10 times) and record the time taken from launch until the main window is fully rendered and responsive. Calculate the average startup time. (Hint: Use the `time` command on Linux/macOS, `Measure-Command` in PowerShell on Windows, or implement simple timestamp logging at the start and end of the initialization sequence within the application code.) Document the results."
      },
      {
        "step 4": "Profile the CPU usage during an 'idle' state. Launch the IDE, open a small project or a single file, and let it sit idle for 60 seconds without any user interaction. Use an appropriate profiler or system monitoring tool to record the average and peak CPU usage during this period. (Hint: Use `top`/`htop`, Task Manager, or language-specific profilers configured for sampling.) Document the results."
      },
      {
        "step 5": "Profile the CPU usage under 'typical load'. Define a standard workflow (e.g., open a medium-sized source file, make minor edits, trigger syntax highlighting/checking, save the file). Execute this workflow while profiling CPU usage. Record the average and peak CPU usage during the workflow execution. (Hint: Use tools identified in Step 1, focusing on function-level CPU time if possible, like `cProfile` or Visual Studio Profiler.) Document the results."
      },
      {
        "step 6": "Profile the CPU usage under 'peak load'. Define a resource-intensive scenario (e.g., opening a very large file, building a complex project within the IDE, running a code analysis tool on the entire project). Execute this scenario while profiling CPU usage. Record the average and peak CPU usage. (Hint: Identify the most CPU-intensive functions or modules.) Document the results."
      },
      {
        "step 7": "Profile memory consumption during the 'idle' state. After launching the IDE and letting it idle (as in Step 4), measure its memory footprint (Resident Set Size/RSS, Private Working Set). (Hint: Use `top`/`htop`, Task Manager, `psutil`, or language-specific tools like `memory_profiler`, VisualVM, DevTools Memory tab.) Document the results."
      },
      {
        "step 8": "Profile memory consumption under 'typical' and 'peak' loads. Measure memory usage while executing the workflows defined in Step 5 and Step 6. Note any significant increases in memory consumption during or after these operations. (Hint: Pay attention to memory usage *after* the peak load task completes - does it return to a baseline?) Document the results."
      },
      {
        "step 9": "Investigate potential memory leaks. Design a test case involving repetitive actions that might allocate memory (e.g., repeatedly opening and closing files or projects, triggering code completion/analysis). Run this test case for an extended period or a high number of iterations while monitoring memory usage. Check if memory consumption grows unboundedly. (Hint: Use tools like `tracemalloc`, `objgraph`, heap snapshots in DevTools/VisualVM, Valgrind's Massif.) Document any findings."
      },
      {
        "step 10": "Profile Disk I/O operations. Focus on scenarios like: project loading/scanning, opening large files, saving files, and build processes (if applicable). Use appropriate tools to measure disk read/write bytes and operation counts during these scenarios. (Hint: Use OS-level tools like `iotop`, Resource Monitor, `dtrace`/`bpftrace`/`fs_usage`, or instrument application code handling file operations.) Document the results."
      },
      {
        "step 11": "Profile Network I/O operations (if applicable). If the IDE performs network operations (e.g., checking for updates, fetching dependencies, interacting with remote repositories, language server communication over network), profile the network traffic during these operations. Measure data sent/received. (Hint: Use tools like Wireshark, `netstat`, browser developer tools' Network tab if it's web-based, or OS Resource Monitor.) Document the results."
      },
      {
        "step 12": "Consolidate all collected performance data (Startup Time, CPU Usage [idle, typical, peak], Memory Consumption [idle, typical, peak, leaks], Disk I/O, Network I/O) into a structured summary report. Highlight key metrics and observations."
      },
      {
        "step 13": "Analyze the performance report to identify potential bottlenecks and areas for optimization. List the top 3-5 performance issues observed (e.g., slow startup, high idle CPU, excessive memory usage during specific actions, slow file operations, memory leaks)."
      }
    ],
    "Task 5.13: Identify Performance Bottlenecks using Profiling Tools": [
      {
        "step 1": "Analyze the IDE's architecture and primary features (e.g., text editor, file management, build integration, code completion, debugging). Identify the top 3-5 features or workflows that are most critical to user experience and most likely to exhibit performance issues (e.g., opening large projects, rendering large files, real-time syntax highlighting/linting, code completion suggestions, running build tasks). List these critical areas."
      },
      {
        "step 2": "Based on the IDE's technology stack (e.g., Electron, Node.js, Python, specific UI frameworks), select appropriate profiling tools. \n*Hint:* For Electron/Node.js, consider Chrome DevTools Performance tab, Node.js built-in profiler (`--prof`), or libraries like `0x`. For Python components, consider `cProfile`, `py-spy`, or `line_profiler`. If native components are involved, platform-specific tools like `perf` (Linux), `Instruments` (macOS), or `VTune` (Intel) might be needed. Document the chosen tools for each relevant part of the IDE."
      },
      {
        "step 3": "Define specific, repeatable test scenarios for each critical area identified in Step 1. For example: \n*   'Load Project': Measure time from initiating project load to the file explorer being fully populated for a sample large project.\n*   'Open Large File': Measure time from clicking a large file (e.g., >10MB text file) to it being fully rendered and editable.\n*   'Intensive Editing': Measure responsiveness (CPU usage, frame rate) during rapid typing, scrolling, and selection in a file with complex syntax highlighting.\n*   'Code Completion': Measure time from typing a trigger character to the completion list appearing for the first time in a specific context.\n*   'Run Build': Measure time and resource usage for executing a predefined build task within the IDE."
      },
      {
        "step 4": "Configure and run the selected profiling tools (from Step 2) while executing the defined test scenarios (from Step 3). Ensure you capture sufficient data for analysis. \n*Hint:* You might need to modify IDE launch scripts to enable profiling flags (e.g., `node --prof main.js`, `python -m cProfile -o profile.prof main.py`) or interact with the profiler interface (like Chrome DevTools). Capture output files (e.g., `.prof`, `.cpuprofile`, `.heapsnapshot`) or save profiling sessions."
      },
      {
        "step 5": "Analyze the captured profiling data for each scenario. Use the features of your chosen profiling tools to visualize the data (e.g., flame graphs, call trees, bottom-up/top-down views, memory allocation timelines). \n*Hint:* For Node.js `--prof`, use `node --prof-process <isolate-*.log>` to generate human-readable output. Chrome DevTools provides interactive analysis. `py-spy` can generate flame graphs. Focus on identifying functions or operations with high self-time, total time, or significant memory allocations/garbage collection activity."
      },
      {
        "step 6": "Identify and document the specific performance bottlenecks based on the analysis in Step 5. For each bottleneck, describe: \n*   The feature/scenario affected.\n*   The specific function(s), module(s), or algorithm(s) responsible.\n*   The nature of the bottleneck (e.g., CPU-bound, I/O-bound, memory leak, excessive GC).\n*   Include references to the relevant profiling data (e.g., screenshots of flame graphs, specific timing metrics). Store this documentation in a designated project file (e.g., `docs/performance_bottlenecks.md`)."
      }
    ],
    "Task 5.14: Optimize Identified Bottlenecks in Code, Algorithms, and Resource Management": [
      {
        "step 1": "Access and review the performance analysis reports and the list of identified bottlenecks generated in the previous tasks (e.g., Task 5.13). Load this information into your current context."
      },
      {
        "step 2": "Prioritize the identified bottlenecks based on their measured impact on performance (e.g., highest CPU time, greatest memory consumption, longest I/O wait times, UI responsiveness impact). List the top 3-5 bottlenecks you will focus on optimizing first."
      },
      {
        "step 3": "Select the highest priority bottleneck from your list. Analyze the specific code sections, algorithms, or resource management patterns associated with this bottleneck. Identify the root cause of the inefficiency."
      },
      {
        "step 4": "If the bottleneck identified in Step 3 is primarily related to inefficient code logic (e.g., complex loops, redundant calculations, inefficient data structure usage): Refactor the relevant code sections. *Hint: Apply techniques like loop optimization, strength reduction, using more efficient data structures (e.g., dictionaries for lookups), memoization/caching for repeated computations, or leveraging optimized library functions.*"
      },
      {
        "step 5": "If the bottleneck identified in Step 3 is primarily related to an inefficient algorithm: Analyze its time and space complexity in the context of its usage. Research and identify a more suitable algorithm. *Hint: Search the web for optimized algorithms for tasks like sorting, searching, parsing, graph traversal, etc. Consider the trade-offs.* Implement the improved algorithm, replacing the inefficient one."
      },
      {
        "step 6": "If the bottleneck identified in Step 3 is primarily related to resource management (e.g., memory leaks, excessive memory allocation/garbage collection, slow I/O, handle leaks): Refactor the code to improve resource handling. *Hint: Ensure deterministic cleanup of resources using context managers (`with` statement) or `try...finally` blocks. Optimize I/O operations (e.g., buffering, asynchronous I/O). Investigate object pooling for frequently created/destroyed objects. Use memory profiling tools again if needed to pinpoint leaks.*"
      },
      {
        "step 7": "After implementing the optimization (from Step 4, 5, or 6), re-run the specific performance tests or profiling scenarios that originally highlighted this bottleneck. Measure the performance characteristics (CPU, memory, time) again."
      },
      {
        "step 8": "Compare the new performance measurements with the baseline measurements from before the optimization. Verify that the bottleneck has been significantly reduced or eliminated and that no functional regressions have been introduced. Revert the changes if the optimization is ineffective or introduces issues."
      },
      {
        "step 9": "Select the next highest priority bottleneck from the list created in Step 2. Repeat the analysis, implementation, and verification process (Steps 3-8) for this bottleneck."
      },
      {
        "step 10": "Continue iterating through the prioritized bottlenecks (Steps 3-9) until the most significant performance issues have been addressed or further optimization yields diminishing returns."
      },
      {
        "step 11": "Update the project's documentation (e.g., in a `PERFORMANCE.md` file or code comments) to detail the bottlenecks identified, the specific optimizations applied, and the quantitative performance improvements achieved (e.g., 'Reduced syntax highlighting time for large files by 30%')."
      },
      {
        "step 12": "Commit the optimized code, associated tests, and updated documentation to the version control system."
      }
    ],
    "Task 5.15: Tune IDE Responsiveness, Background Task Handling, and UI Rendering": [
      {
        "step 1": "Set up and configure profiling tools appropriate for the IDE's technology stack (e.g., cProfile/Py-Spy for Python backend, browser DevTools Performance tab for web-based UI, platform-specific profilers like Instruments/VTune for native desktop apps). Document the chosen tools and setup process in the project's documentation."
      },
      {
        "step 2": "Perform initial profiling runs focusing on UI responsiveness. Measure the time taken for common user interactions like: typing in the editor, scrolling large files, opening/closing panels, triggering code completion, navigating menus, and resizing windows. Record baseline metrics."
      },
      {
        "step 3": "Perform profiling runs focusing on background task execution. Measure the time taken and resource consumption (CPU, memory) of tasks like: project indexing, file searching, real-time linting/error checking, build processes (if integrated), and version control operations. Identify any tasks significantly impacting UI responsiveness or consuming excessive resources."
      },
      {
        "step 4": "Analyze the profiling results from steps 2 and 3. Identify specific functions, methods, or modules that are performance bottlenecks, particularly those running on the main UI thread or causing delays in background task completion. Document these hotspots."
      },
      {
        "step 5": "Review the current architecture for handling background tasks (e.g., threading, `asyncio`, `multiprocessing`, dedicated worker processes, task queues). Evaluate if long-running or CPU-intensive tasks are correctly offloaded from the main UI thread."
      },
      {
        "step 6": "Refactor identified blocking operations currently running on the main UI thread to execute asynchronously or in separate background threads/processes. *Hint: Use appropriate concurrency primitives like `async`/`await`, `threading.Thread`, `multiprocessing.Process`, or framework-specific utilities (e.g., `QThread` in Qt, Web Workers in web apps).* Prioritize operations identified as major bottlenecks in step 4."
      },
      {
        "step 7": "Implement or enhance cancellation mechanisms for long-running background tasks. Ensure that tasks can be safely interrupted if they become obsolete (e.g., user closes the relevant file, starts a new search) or if the user explicitly requests cancellation. *Hint: Use flags, events, or framework-specific cancellation tokens.*"
      },
      {
        "step 8": "Implement debouncing or throttling for background tasks triggered frequently by user input, such as real-time linting or syntax checking on keypress. *Hint: Search the web for standard debouncing/throttling algorithm implementations or use library functions if available (e.g., Lodash `debounce`/`throttle` for web).* Adjust the delay times based on usability testing."
      },
      {
        "step 9": "Analyze UI rendering performance using framework-specific tools (e.g., React Profiler, Vue Devtools, Qt Inspector) or general profiling. Identify components or widgets that are slow to render or cause frequent, expensive redraws."
      },
      {
        "step 10": "If the IDE displays large lists or trees (e.g., file explorer, search results, outline views) that cause performance issues, implement virtualization (windowing) techniques. Render only the visible items, dynamically loading/unloading items as the user scrolls. *Hint: Search for 'list virtualization' or 'tree virtualization' libraries/patterns for your specific UI framework.*"
      },
      {
        "step 11": "Optimize UI component rendering logic. Minimize unnecessary re-renders by using techniques like memoization, caching component state, or using framework-specific directives/lifecycles (e.g., `React.memo`, `shouldComponentUpdate`, `PureComponent`, Vue's `v-once`). Focus on components identified as bottlenecks in step 9."
      },
      {
        "step 12": "Consider enabling hardware acceleration for rendering if supported by the UI framework and target platform, ensuring compatibility and testing for visual artifacts."
      },
      {
        "step 13": "Re-run the profiling scenarios from steps 2 and 3 after applying optimizations. Compare the new metrics against the baseline recorded in step 2 to quantify the improvements in UI responsiveness and background task efficiency."
      },
      {
        "step 14": "Perform subjective usability testing focused on perceived responsiveness. Interact with the IDE extensively, performing tasks that were previously slow or laggy, and verify that the user experience feels smoother and more immediate."
      },
      {
        "step 15": "Run the full existing test suite (unit, integration, E2E tests) to ensure that the performance optimizations have not introduced any functional regressions. Add new tests specifically targeting the optimized areas or background task handling if necessary."
      },
      {
        "step 16": "Update project documentation with details of the performance optimizations implemented, profiling results (before/after), and any new patterns or techniques introduced for background task handling or UI rendering."
      }
    ],
    "Task 5.16: Perform Security Audits and Basic Vulnerability Scanning": [
      {
        "step 1": "Identify the primary programming language(s) and core frameworks used in the IDE project (e.g., Python/PyQt, Node.js/Electron, Java/Swing). Research and list common security vulnerabilities and attack vectors associated with this specific tech stack. Pay special attention to areas like file system interaction, code execution (if applicable), inter-process communication (IPC, especially in Electron), extension loading, and handling user input/configuration files. Hint: Search the web for 'security best practices for [framework/language]' or 'common vulnerabilities in [framework/language]'."
      },
      {
        "step 2": "Based on the identified language(s), select and install appropriate Static Application Security Testing (SAST) tools. Hint: For Python, consider `bandit`. For JavaScript/TypeScript (Node.js/Electron), consider `eslint-plugin-security` or `Semgrep`. For Java, consider `SonarLint` integration (if feasible for the agent) or `SpotBugs` with FindSecBugs plugin. Follow the installation instructions for the chosen tool(s)."
      },
      {
        "step 3": "Configure and run the installed SAST tool(s) across the entire IDE codebase. Analyze the output report, focusing on high and medium severity warnings related to security (e.g., hardcoded secrets, insecure use of subprocesses, potential injection points, unsafe deserialization). Document the key findings."
      },
      {
        "step 4": "Select and install tools for scanning project dependencies for known vulnerabilities. Hint: For Node.js, use `npm audit` or `yarn audit`. For Python, use `safety check -r requirements.txt` or `pip-audit`. For Java (Maven/Gradle), consider OWASP Dependency-Check."
      },
      {
        "step 5": "Execute the dependency scanning tool(s). Analyze the report for vulnerabilities in third-party libraries, especially those with high severity ratings or known exploits. Document the vulnerable dependencies and the nature of their vulnerabilities."
      },
      {
        "step 6": "Perform a manual code review focused on input validation and sanitization. Identify all points where the IDE accepts external input (e.g., file paths opened, search terms, commands entered, configuration settings loaded). Verify that this input is strictly validated against expected formats and sanitized to prevent injection attacks (e.g., Command Injection, Path Traversal, Cross-Site Scripting (XSS) if web components are used)."
      },
      {
        "step 7": "Perform a manual code review focused on file system interactions. Examine how file paths are constructed and used. Ensure that functions like `os.path.join` (Python) or `path.join` (Node.js) are used correctly to prevent path traversal vulnerabilities. Check if file permissions are handled appropriately, especially when creating or modifying files."
      },
      {
        "step 8": "If the IDE includes features for executing user code, external commands, or build scripts, perform a manual code review of these specific features. Ensure that any use of functions like `subprocess.run`, `os.system` (Python), `child_process.exec`, `child_process.spawn` (Node.js), or `Runtime.exec` (Java) is done securely. Check for potential command injection vulnerabilities by ensuring user input is never directly passed to shell commands or is properly escaped/parameterized. Consider if sandboxing is necessary and feasible."
      },
      {
        "step 9": "If the IDE uses Inter-Process Communication (IPC), especially common in Electron apps, review the IPC handlers. Ensure that messages from less privileged contexts (like renderer processes in Electron) are treated as untrusted input in more privileged contexts (like the main process). Validate message contents and avoid exposing sensitive APIs directly via IPC."
      },
      {
        "step 10": "Consolidate all findings from the SAST scans (Step 3), dependency scans (Step 5), and manual code reviews (Steps 6-9) into a single security audit report. For each finding, describe the vulnerability, its location in the code, its potential impact, and assign a preliminary severity level (e.g., Critical, High, Medium, Low). Save this report as 'security_audit_report.md'."
      }
    ],
    "Task 5.17: Conduct Thorough Code Reviews for Quality, Standards, and Potential Issues": [
      {
        "step 1": "Configure and execute static analysis tools (e.g., linters like `pylint`/`flake8` for Python or `eslint` for JS/TS, and formatters like `black` or `prettier`) across the entire IDE project codebase. Report any violations found regarding coding standards, potential errors, and code style inconsistencies. *Hint: Ensure the linters are configured with appropriate rulesets for the project.*"
      },
      {
        "step 2": "Define a structured code review checklist. This checklist should cover key areas including: 1. Coding Style & Consistency (naming conventions, formatting). 2. Readability & Maintainability (clarity, complexity, comments). 3. Error Handling (robustness, logging). 4. Resource Management (memory leaks, file handles). 5. Performance (potential bottlenecks). 6. Security (input validation, command injection risks). 7. Documentation (docstrings, comments accuracy). 8. Architectural Adherence (separation of concerns, modularity)."
      },
      {
        "step 3": "Perform a detailed review of the core editor component(s) using the checklist defined in Step 2. Analyze code structure, logic, event handling, and interaction with other modules. *Hint: Pay attention to text manipulation logic, syntax highlighting implementation (if any), undo/redo functionality, and potential performance issues with large files or complex operations.*"
      },
      {
        "step 4": "Review the file management module(s) using the checklist. Examine file I/O operations, directory traversal, project structure handling, and interactions with the OS file system. *Hint: Check for proper error handling (e.g., permissions, file not found), resource management (closing files/handles), race conditions (if async I/O is used), and cross-platform compatibility issues.*"
      },
      {
        "step 5": "Review the build system and debugger integration modules using the checklist. Focus on how external processes are managed, how their output is parsed, and how state is synchronized with the IDE UI. *Hint: Critically examine command construction and execution for potential command injection vulnerabilities. Verify robust error handling and reporting from external tools.*"
      },
      {
        "step 6": "Review the main UI components (main window, panels, dialogs, custom widgets) using the checklist. Evaluate UI logic, event handling, state management, and separation from backend logic. *Hint: Look for potential UI freezes, memory leaks related to UI elements, inconsistent UI behavior, and adherence to established UI/UX guidelines (if any).* "
      },
      {
        "step 7": "Review shared utility functions, helper classes, and core libraries within the project using the checklist. Assess their design, reusability, clarity, and documentation. *Hint: Ensure utilities are well-tested (if unit tests exist), have clear interfaces, and do not introduce unnecessary dependencies.*"
      },
      {
        "step 8": "Conduct a specific security-focused review pass across all relevant components (especially build/debug integration, file handling, settings management). Use the 'Security' section of the checklist and look explicitly for common vulnerabilities. *Hint: Search the web for 'OWASP Top 10' and 'Common Weakness Enumeration (CWE)' relevant to desktop applications and the languages used. Check input validation, output encoding, and assumptions about external processes.*"
      },
      {
        "step 9": "Review all forms of documentation: inline comments, function/class docstrings, README files, and any other developer documentation. Verify accuracy, completeness, clarity, and consistency with the current codebase. *Hint: Ensure comments explain 'why' not just 'what', and that docstrings accurately describe parameters, return values, and exceptions.*"
      },
      {
        "step 10": "Consolidate all findings from the static analysis (Step 1) and the manual reviews (Steps 3-9) into a single, structured report. Categorize each finding (e.g., Bug, Security Vulnerability, Code Smell, Style Violation, Documentation Issue, Performance Concern) and note its location in the codebase."
      },
      {
        "step 11": "Prioritize the consolidated findings based on severity (e.g., Critical, High, Medium, Low) and potential impact on IDE functionality, stability, security, or maintainability. Justify the prioritization for each significant issue."
      },
      {
        "step 12": "For the highest priority issues identified (e.g., Critical and High severity), propose specific, actionable recommendations for fixing or refactoring the code. Include code snippets or detailed descriptions of the suggested changes where appropriate. *Hint: Link suggestions back to specific findings in the report.*"
      }
    ],
    "Task 5.18: Integrate and Run Static Code Analysis Tools, Address Reported Issues": [
      {
        "step 1": "Identify the primary programming language(s) used in the IDE's codebase (e.g., Python, JavaScript, TypeScript). Based on this, select appropriate static code analysis tools. Hint: For Python, consider Pylint, Flake8, MyPy. For JavaScript/TypeScript, consider ESLint, Prettier, TSLint (if applicable)."
      },
      {
        "step 2": "Install the selected static analysis tools as development dependencies. Hint: Use pip for Python (`pip install pylint flake8 mypy`) or npm/yarn for Node.js (`npm install --save-dev eslint prettier` or `yarn add --dev eslint prettier`). Update the project's dependency files (e.g., `requirements-dev.txt`, `package.json`)."
      },
      {
        "step 3": "Configure the chosen static analysis tools. Create configuration files (e.g., `.pylintrc`, `.flake8`, `.mypy.ini`, `.eslintrc.js`, `.prettierrc`) in the project's root directory. Hint: Start with default configurations or generate them using the tools (`pylint --generate-rcfile > .pylintrc`). Customize rules as needed, potentially ignoring specific directories (like `venv`, `node_modules`, build outputs) or specific error codes if justified."
      },
      {
        "step 4": "Integrate commands to run the static analysis tools into the project's build or scripting system. Hint: Add scripts to `package.json` (e.g., `\"lint\": \"eslint .\"`, `\"format\": \"prettier --write .\"`) or add targets to a `Makefile` (e.g., `lint: pylint src && flake8 src`). Ensure these scripts cover the relevant source code directories."
      },
      {
        "step 5": "Execute the configured static analysis tools across the entire relevant codebase (excluding dependencies and build artifacts). Hint: Run the scripts/commands defined in the previous step (e.g., `npm run lint`, `make lint`)."
      },
      {
        "step 6": "Analyze the reports generated by the static analysis tools. Identify all reported errors, warnings, style violations, potential bugs, and type errors."
      },
      {
        "step 7": "Systematically address the issues reported by the static analysis tools. Prioritize fixing errors and potential bugs, followed by warnings and style violations. Hint: This may involve refactoring code, adding type hints (for MyPy), fixing syntax errors, improving code style according to configured rules (or using tools like Prettier/Black to auto-format), or adding specific inline comments to suppress unavoidable warnings (e.g., `# pylint: disable=some-warning # Justification`)."
      },
      {
        "step 8": "After making corrections, re-run the static analysis tools to verify that the previously reported issues have been resolved and no new significant issues have been introduced."
      },
      {
        "step 9": "Commit the new configuration files, updated dependency lists, and all code changes made to address the static analysis issues to the version control system."
      }
    ],
    "Task 5.19: Perform Cross-Platform Testing on All Supported Operating Systems": [
      {
        "step 1": "Identify and list the specific target operating systems and their versions previously defined for the IDE project (e.g., Windows 10/11, macOS Monterey/Ventura/Sonoma, Ubuntu 20.04/22.04 LTS). Store this list for reference in subsequent steps."
      },
      {
        "step 2": "Describe the recommended strategy for setting up testing environments for each target OS. Consider options like Virtual Machines (e.g., VirtualBox, VMware), containerization (e.g., Docker, if applicable, mainly for Linux variations), or cloud-based testing platforms. Generate setup instructions or scripts where possible, acknowledging that manual setup might be required for some environments (especially macOS and Windows GUI testing)."
      },
      {
        "step 3": "Review the existing build process. Generate or update build scripts/configurations (e.g., using CMake, Electron Builder, PyInstaller, platform-specific build tools) to produce distributable packages or installers specifically tailored for each target OS (e.g., .exe/.msi for Windows, .dmg/.app for macOS, .deb/.rpm/.AppImage for Linux)."
      },
      {
        "step 4": "Compile a comprehensive cross-platform test plan. This plan should include: \n    a) Running existing automated test suites (unit, integration) on each platform. \n    b) Manual test cases covering core IDE functionality (file operations, code editing, syntax highlighting, build/run/debug cycles, version control integration, settings management, plugin loading). \n    c) Specific checks for platform-specific UI/UX conventions (dialog boxes, menus, file pickers, keyboard shortcuts, look-and-feel). \n    d) Performance checks (startup time, responsiveness during editing/building)."
      },
      {
        "step 5": "Prepare commands or scripts to execute the automated test suites within each of the configured target OS environments. Ensure the scripts handle environment setup (dependencies) and report results clearly, indicating the platform they ran on. Hint: Adapt existing test runner commands for cross-platform execution, considering path differences and environment variables."
      },
      {
        "step 6": "Generate a detailed checklist based on the manual test cases defined in the test plan (Step 4). Structure the checklist so a human tester can easily follow it on each target OS. Include specific instructions to look for visual glitches, inconsistent behavior, or platform-specific errors. Hint: Use Markdown or a similar format for clarity."
      },
      {
        "step 7": "Define a standardized format for reporting issues found during cross-platform testing. Each report should include: OS, OS Version, IDE Version, Steps to Reproduce, Expected Behavior, Actual Behavior, Screenshots/Logs (if applicable). Instruct the AI to be prepared to process test results (automated logs, hypothetical manual reports) in this format."
      },
      {
        "step 8": "Analyze the codebase for potential platform-specific pitfalls. Focus on areas like: file system interactions (path separators, case sensitivity), external process management, network communication, UI rendering logic (if using cross-platform UI toolkits, check for known platform-specific bugs), dependency management, and any direct calls to OS-specific APIs. Document potential risk areas."
      },
      {
        "step 9": "Based on hypothetical or actual test results indicating platform-specific bugs, analyze the relevant code sections identified in Step 8 (or elsewhere) and propose code modifications to fix the issues. Ensure proposed fixes maintain compatibility with *all* supported platforms. Hint: Use conditional compilation/logic (`if os.name == 'nt'`, etc.) or platform-abstraction layers where necessary."
      },
      {
        "step 10": "Simulate receiving a bug report for a specific platform (e.g., 'File dialog crashes on Ubuntu 22.04'). Apply the fix proposed in Step 9 (or generate a fix if none exists). Then, update the relevant build script (Step 3) and test execution command (Step 5/6) to verify the fix specifically on the affected platform, while also ensuring regression tests pass on other platforms."
      },
      {
        "step 11": "Update project documentation (e.g., README, build instructions, known issues list) to reflect the outcomes of cross-platform testing. Include any platform-specific setup requirements, workarounds for known issues, or limitations identified."
      }
    ],
    "Task 5.20: Test Compatibility with Different Language Versions, Runtimes, and Build Tools": [
      {
        "step 1": "Analyze the IDE's current capabilities and list all programming languages, specific language features (e.g., async/await in Python), runtimes (e.g., Node.js, specific JVMs), and build tools (e.g., Maven, Gradle, npm, pip, CMake) that the IDE currently supports or integrates with. Store this list for reference in subsequent steps."
      },
      {
        "step 2": "Based on the list from Step 1, define a matrix of target environments for compatibility testing. For each supported language, select a range of relevant versions (e.g., current LTS, latest stable, one older version). For each relevant build tool, select common versions. Prioritize combinations commonly used by developers. Document this test matrix."
      },
      {
        "step 3": "Choose a strategy for creating isolated test environments for the configurations defined in the test matrix. Hint: Using containerization tools like Docker is highly recommended. Alternatively, consider version managers (like `pyenv`, `nvm`, `sdkman`) or virtual machines. Outline the chosen strategy."
      },
      {
        "step 4": "For the first environment configuration in your test matrix (e.g., Python 3.8 with pip), set up the isolated environment using the strategy from Step 3. Hint: If using Docker, write a Dockerfile that installs the specific language version, runtime, and any necessary build tools. Build the container image."
      },
      {
        "step 5": "Create a minimal sample project suitable for the environment configured in Step 4 (e.g., a simple Python script `hello.py` using Python 3.8 features, maybe with a dependency listed in `requirements.txt`). This project should allow testing core IDE features like syntax highlighting, code execution, and potentially debugging and build tool integration."
      },
      {
        "step 6": "Execute compatibility tests for the first environment. Mount or copy the sample project into the isolated environment. Use the IDE's functionalities (or script interactions simulating them) to perform actions like: opening the project, checking syntax highlighting for version-specific features, running the main script, installing dependencies using the relevant build tool (e.g., `pip install -r requirements.txt` triggered via an IDE action or terminal integration), and performing a build if applicable. Record detailed results, including successes, failures, error messages, and unexpected behavior."
      },
      {
        "step 7": "Repeat Steps 4-6 for each subsequent environment configuration defined in your test matrix. Ensure each environment is clean and isolated. Systematically work through different language versions, runtimes, and build tool combinations."
      },
      {
        "step 8": "Specifically test the integration points with build tools across different versions. For example: If the IDE supports Maven, test project creation/import, dependency resolution, and build execution using both an older Maven version (e.g., 3.6.x) and a newer one (e.g., 3.9.x) within appropriate Java environments (e.g., Java 8, Java 17)."
      },
      {
        "step 9": "Compile all recorded results from the compatibility tests into a comprehensive report. The report should clearly list each tested configuration (Language Version, Runtime, Build Tool, OS if relevant), the specific IDE features tested, the outcome (Pass/Fail), and detailed descriptions of any failures or incompatibilities discovered. Hint: Categorize issues (e.g., 'Syntax Highlighting Error', 'Runtime Execution Failure', 'Build Tool Integration Bug')."
      },
      {
        "step 10": "Review the compatibility report. For each identified issue, create a detailed bug report or issue ticket in your project's issue tracking system (if available). Include steps to reproduce, the environment configuration, expected behavior, and actual behavior."
      }
    ],
    "Task 5.21: Review, Refine, and Finalize User Documentation and Help Guides": [
      {
        "step 1": "Locate all existing user documentation files within the project repository. Common locations include the root directory (e.g., `README.md`), a `/docs` folder, or specific documentation generation outputs. List the files found."
      },
      {
        "step 2": "Review the located documentation files (`README.md`, getting started guides, feature descriptions, etc.) for accuracy. Compare the described features, UI elements, commands, and workflows against the current state of the IDE's codebase and functionality. Identify and list any discrepancies or outdated information."
      },
      {
        "step 3": "Update the documentation to correct the inaccuracies identified in the previous step. Ensure that descriptions of features, installation instructions, configuration options, and usage examples accurately reflect the latest version of the IDE."
      },
      {
        "step 4": "Assess the documentation for completeness. Cross-reference the documented features with the implemented features list (refer to project requirements or feature tracking). Identify and list any significant features, common use cases, or troubleshooting tips that are missing from the documentation."
      },
      {
        "step 5": "Add the missing sections or information identified in the previous step to the appropriate documentation files. Ensure comprehensive coverage of the IDE's core functionalities and how users can effectively utilize them."
      },
      {
        "step 6": "Review the documentation for clarity, conciseness, and readability. Rewrite complex sentences, eliminate jargon where possible (or provide clear definitions), ensure consistent terminology, and use an active voice. Aim for language easily understood by the target developer audience. Hint: Consider using techniques like breaking down long paragraphs and using bullet points or numbered lists."
      },
      {
        "step 7": "Verify the correctness and clarity of all code examples, configuration snippets, and step-by-step instructions provided in the documentation. Ensure they are syntactically correct, easy to follow, and produce the expected results within the IDE environment."
      },
      {
        "step 8": "Review the overall structure and navigation of the documentation. Ensure there is a clear entry point (like `README.md`), a logical flow between topics, a table of contents (if applicable), and appropriate cross-linking between related sections to help users find information easily."
      },
      {
        "step 9": "Identify areas where visual aids like screenshots (e.g., demonstrating UI elements) or diagrams (e.g., illustrating architecture or workflow) would significantly improve understanding. Add descriptive placeholders (e.g., `[Screenshot: Creating a new project]`, `[Diagram: Debugger workflow]`) in the relevant documentation sections."
      },
      {
        "step 10": "Perform a final proofreading pass on all documentation files. Check for and correct any remaining grammatical errors, spelling mistakes, typos, and formatting inconsistencies (e.g., code block styling, heading levels, link formatting). Hint: Consider using automated spell/grammar checking tools if available."
      },
      {
        "step 11": "Ensure all documentation files are saved in the appropriate standard format (e.g., Markdown `.md`) and are located in the designated documentation directory (e.g., `/docs` or project root). Consolidate and finalize the documentation structure."
      }
    ],
    "Task 5.22: Define Release Readiness Criteria (Quality Gates, Bug Thresholds)": [
      {
        "step 1": "Create a new Markdown file named `RELEASE_CRITERIA.md` in the project's root or documentation directory. This file will document the standards and conditions required for releasing a new version of the IDE."
      },
      {
        "step 2": "In `RELEASE_CRITERIA.md`, create a section titled '## Quality Gates'. Define the specific automated and manual checks that must pass before a release candidate can proceed. List each gate and its pass condition. \n*Hint: Consider gates like: Build Success (Must pass 100%), Unit Tests (Must pass 100%, Coverage > X%), Integration Tests (Must pass 100%), End-to-End Tests (Must pass 95%+ for core workflows), Static Code Analysis (No new critical/major issues), Security Scan (No critical/high vulnerabilities), Performance Benchmarks (Meet defined targets - see next steps). Specify initial target percentages/conditions.*"
      },
      {
        "step 3": "Add a section titled '## Bug Severity Levels' to `RELEASE_CRITERIA.md`. Define the different levels used to classify bugs found during testing. \n*Hint: Use standard definitions like: Blocker (Prevents core functionality, no workaround), Critical (Crashes, data loss, severe security issue), Major (Major feature non-functional, difficult workaround), Minor (Minor feature non-functional, easy workaround), Trivial (UI glitch, cosmetic issue).* Clearly describe each level."
      },
      {
        "step 4": "Create a section titled '## Bug Thresholds for Release' in `RELEASE_CRITERIA.md`. Define the maximum number of open bugs allowed for each severity level for a version to be considered releasable. \n*Hint: Specify different thresholds for different release types if applicable (e.g., Alpha, Beta, Stable/GA). Example for Stable: 0 Blocker, 0 Critical, <= 5 Major, <= 20 Minor. State these as initial targets.*"
      },
      {
        "step 5": "Add a section titled '## Performance Criteria' to `RELEASE_CRITERIA.md`. Define the key performance indicators (KPIs) and their acceptable target values for release. \n*Hint: Consider metrics like: IDE Startup Time (< X seconds), Average Memory Usage (< Y MB under typical load), File Open Time (< Z ms for large files), UI Responsiveness (Key actions < W ms). Note that these initial values may need adjustment after performance testing (Task 5.10-5.14).*"
      },
      {
        "step 6": "Create a section titled '## Code Quality Standards' in `RELEASE_CRITERIA.md`. Define the minimum acceptable standards based on code analysis tools. \n*Hint: Specify targets like: Minimum Code Coverage (e.g., > 85% overall, > 90% for critical modules), Maximum Code Complexity (e.g., Cyclomatic complexity < 15), Static Analysis (Zero tolerance for specific high-priority rule violations identified by linters/analyzers used in the project).* Refer to the tools configured in previous steps."
      },
      {
        "step 7": "Add a section titled '## Documentation Requirements' to `RELEASE_CRITERIA.md`. Specify the documentation artifacts that must be completed, reviewed, and up-to-date for a release. \n*Hint: Include items like: User Manual/Guide, Installation Instructions, API Documentation (if applicable), Release Notes, Contribution Guidelines (if open source).* Define the expected state (e.g., 'Reviewed and Approved', 'Up-to-date with Release Features')."
      },
      {
        "step 8": "Create a section titled '## Feature Completeness' in `RELEASE_CRITERIA.md`. State the requirement that all features planned and committed for the specific release milestone must be fully implemented, tested (passing relevant quality gates), and documented according to the defined standards."
      },
      {
        "step 9": "Review the entire `RELEASE_CRITERIA.md` file for clarity, consistency, and completeness. Ensure that the criteria are measurable and provide a clear definition of 'done' for a releasable version of the IDE. Add a concluding statement emphasizing that these criteria are subject to review and revision as the project evolves."
      }
    ]
  },
  "Phase 6: Packaging, Documentation & Release": {
    "Task 6.1: Define target platforms and packaging formats (e.g., Windows Installer, macOS DMG, Linux AppImage/deb/rpm)": [
      {
        "step 1": "Analyze the project's technology stack (e.g., programming language, GUI framework) and potential user base to determine the most relevant target operating systems. List the proposed target platforms (e.g., Windows 10+, macOS 11+, Ubuntu 20.04+). Hint: Consider the cross-platform capabilities of the tools/libraries used in the IDE's development."
      },
      {
        "step 2": "For each target operating system identified in Step 1, research the standard and popular application packaging formats available. List the potential formats for each OS. Hint: Search the web for 'Windows application packaging formats', 'macOS application distribution options', 'Linux packaging standards'. Consider formats like MSI, EXE (via NSIS/Inno Setup), DMG, PKG, App Store, AppImage, deb, rpm, Flatpak, Snap."
      },
      {
        "step 3": "Evaluate the pros and cons of the potential packaging formats identified in Step 2 for each target OS. Consider factors such as ease of creation/maintenance (using tools like `electron-builder`, `pyinstaller`, `jpackage`, `msitools`, `linuxdeployqt`, etc.), user installation experience, automatic updates, system integration, sandboxing/permissions, and distribution methods (direct download, app stores)."
      },
      {
        "step 4": "Based on the evaluation in Step 3, select the primary packaging format(s) you will aim to produce for each target operating system. Justify your choices. Hint: For Linux, consider offering a universal format like AppImage alongside distribution-specific formats like deb and rpm if feasible. For macOS and Windows, consider the standard user expectations (DMG/PKG and MSI/EXE installer)."
      },
      {
        "step 5": "Create a new markdown file named `PACKAGING_STRATEGY.md` in the project's root directory or within a `docs/` subdirectory. Document the chosen target platforms and the selected packaging format(s) for each platform, including the rationale behind each choice as determined in Step 4. Ensure this documentation is clear and concise."
      }
    ],
    "Task 6.2: Configure build system for creating distributable packages": [
      {
        "step 1": "Analyze the project's structure and configuration files (e.g., `package.json`, `requirements.txt`, `CMakeLists.txt`, file extensions in `src/`) to confirm the primary programming language and UI framework being used for the IDE. Also, determine the target operating systems (assume Windows, macOS, and Linux if not explicitly specified elsewhere in the project documentation)."
      },
      {
        "step 2": "Based on the identified technology stack (e.g., Python/Tkinter, Electron/TypeScript, C++/Qt) and target platforms, select the most appropriate packaging tool(s) capable of creating native installers or standalone executables (e.g., MSI/EXE, DMG, DEB/RPM/AppImage). *Hint: Consider tools like PyInstaller/cx_Freeze for Python, Electron Builder for Electron, CMake/CPack for C++, JPackage for Java. Briefly document the chosen tool(s) and the reason for selection in a temporary note or update a relevant design document.*"
      },
      {
        "step 3": "Install the selected packaging tool(s) and add them as development dependencies to the project. *Hint: Use `pip install --save-dev <tool>` and update `requirements-dev.txt` for Python, or `npm install --save-dev <tool>` / `yarn add --dev <tool>` for Node.js/Electron projects.*"
      },
      {
        "step 4": "Create or modify the necessary configuration file(s) for the chosen packaging tool(s). Start with essential settings: application name, version (try to fetch dynamically from project metadata if possible, e.g., `package.json` version), the main entry point script or executable, and the target output directory (e.g., `dist/` or `release/`). *Hint: Generate a template if the tool supports it (e.g., `pyi-makespec your_main_script.py` for PyInstaller). For Electron Builder, configure the `build` section in `package.json` or use `electron-builder.yml`.*"
      },
      {
        "step 5": "Configure the packaging tool to correctly bundle all required application source code files (typically from `src/`) and automatically include necessary runtime dependencies. Ensure any non-code files directly used by the source (e.g., default configurations, templates) are also included. *Hint: PyInstaller often detects Python imports; check its `hiddenimports` and `datas` options. Electron Builder usually bundles the app source and Node modules automatically; check `files` pattern. For CPack, this relies heavily on correct `install()` commands in `CMakeLists.txt`.*"
      },
      {
        "step 6": "Configure the packaging tool to include application assets such as icons, license files, and documentation. Specify platform-specific icon formats (e.g., `.ico` for Windows, `.icns` for macOS). Include the main `LICENSE` file and potentially a `README.md`. *Hint: Look for options like `icon`, `files`, `extraResources` in Electron Builder; `icon`, `add-data` (`datas` in spec file) for PyInstaller; `install(FILES ...)` and CPack variables like `CPACK_PACKAGE_ICON` for CMake/CPack.*"
      },
      {
        "step 7": "Define platform-specific packaging configurations. Specify the desired output formats for each target OS (e.g., `nsis` or `msi` for Windows, `dmg` for macOS, `deb`, `rpm`, `AppImage` for Linux). If code signing details (certificates, identities) are available or placeholders exist, configure the signing process for Windows and macOS builds. *Hint: Electron Builder uses `win`, `mac`, `linux` keys. CPack uses different Generators (`-G <Generator>`). PyInstaller might need separate runs or OS-specific configurations within the `.spec` file.*"
      },
      {
        "step 8": "Create automation scripts to streamline the build and packaging process. Add entries to `package.json` (`scripts` section) for Node.js projects, or create shell scripts (e.g., `build_dist.sh`, `build_dist.bat`) for other environments. These scripts should ideally handle cleaning previous builds, running the packager for specified targets, and placing artifacts in the designated output directory. *Example script commands: `electron-builder --win --mac --linux`, `pyinstaller main.spec --distpath=dist`, `cmake --build . --target package` or `cpack -C Release`.*"
      },
      {
        "step 9": "Execute the build/packaging script for one target platform (preferably the current OS) to test the configuration. Verify that the process runs without errors and produces the expected distributable file (e.g., installer or archive) in the correct output directory. Examine the contents of the package briefly if possible (e.g., extract archive, check file structure)."
      },
      {
        "step 10": "Review and refine the packaging configuration files, adding comments to explain complex or non-obvious settings. Update the project's main `README.md` or create a `BUILDING.md` file with clear instructions on how developers can build the distributable packages, including any prerequisites (tools to install) and the exact commands to run using the scripts created in step 8."
      }
    ],
    "Task 6.3: Implement code signing for relevant platforms (macOS, Windows)": [
      {
        "step 1": "Identify the primary build/packaging tool currently used in the project (e.g., Electron Builder, Tauri CLI, PyInstaller, cx_Freeze) and locate its main configuration file(s) (e.g., `electron-builder.yml`, `package.json` build section, `tauri.conf.json`, `pyinstaller.spec`). State the tool and file path(s) identified."
      },
      {
        "step 2": "Modify the identified build configuration file(s) to enable code signing for macOS builds. Use environment variables as placeholders for sensitive information. Specifically, configure settings related to the signing identity/certificate name. (Hint: For Electron Builder, look for the `mac.identity` option. For Tauri, signing is often configured via environment variables like `APPLE_SIGNING_IDENTITY`. Consult the documentation for the specific build tool if unsure. Use placeholders like `env(MACOS_CERT_NAME)` or `$MACOS_CERT_NAME`.)"
      },
      {
        "step 3": "Configure macOS notarization within the build configuration. This usually requires an Apple ID, an app-specific password, and potentially a Team ID. Use environment variables as placeholders: `APPLE_ID`, `APPLE_APP_SPECIFIC_PASSWORD`, `APPLE_TEAM_ID`. (Hint: For Electron Builder, configure the `mac.notarize` object. For Tauri, set `APPLE_ID`, `APPLE_PASSWORD`, `APPLE_TEAM_ID` environment variables during the build. Ensure notarization runs *after* signing.)"
      },
      {
        "step 4": "Modify the build configuration file(s) to enable code signing for Windows builds. Use environment variables as placeholders for the certificate file path (PFX format expected) and the certificate password: `WINDOWS_CERT_PATH`, `WINDOWS_CERT_PASSWORD`. You might also need to specify the certificate subject name or thumbprint. (Hint: For Electron Builder, configure `win.certificateFile`, `win.certificatePassword`, and potentially `win.certificateSubjectName` or `win.certificateThumbprint`. For PyInstaller, you might need to use post-build hooks with `signtool.exe`.)"
      },
      {
        "step 5": "Update the primary build script (e.g., in `package.json` scripts) or the CI/CD workflow configuration file (e.g., `.github/workflows/release.yml`, `.gitlab-ci.yml`) to ensure the code signing process is triggered correctly during release builds. Explicitly list the required environment variables (`MACOS_CERT_NAME`, `MACOS_CERT_PASSWORD`, `APPLE_ID`, `APPLE_APP_SPECIFIC_PASSWORD`, `APPLE_TEAM_ID`, `WINDOWS_CERT_PATH`, `WINDOWS_CERT_PASSWORD`) as comments in the script/workflow file, indicating they need to be provided securely (e.g., via CI/CD secrets)."
      },
      {
        "step 6": "Integrate signature verification steps into the build script or CI/CD workflow to run after the signing process completes for both macOS and Windows builds. Use platform-specific tools. (Hint: For macOS, use `codesign --verify --verbose <path/to/app>` and `spctl --assess --type execute <path/to/app>`. For Windows, use `signtool verify /pa <path/to/exe>`. Note that `signtool.exe` must be available in the Windows build environment, often via the Windows SDK.) Make these verification steps conditional based on the build target platform."
      },
      {
        "step 7": "Update the project's documentation (e.g., `README.md`, `BUILDING.md`, or a new `RELEASE.md` file). Add a section detailing the code signing setup. Include: (1) A brief explanation of why code signing is done. (2) Prerequisites for the user performing the release (obtaining Apple Developer ID and Authenticode certificates). (3) A list of the environment variables that must be set in the secure build environment for signing and notarization to work."
      }
    ],
    "Task 6.4: Build release candidate packages for all target platforms": [
      {
        "step 1": "Ensure all necessary build dependencies, particularly the packaging tool (likely 'electron-builder'), are installed and up-to-date based on the project's `package.json` or equivalent configuration. Run `npm install` or `yarn install` if needed."
      },
      {
        "step 2": "Locate the build configuration file (e.g., `electron-builder.yml` or the `build` section in `package.json`). Review and update the configuration to ensure it targets the desired platforms (Windows, macOS, Linux) and formats (e.g., `nsis` for win, `dmg` for mac, `AppImage`, `deb`, `rpm` for linux). Verify that essential metadata like application name, icons, and author information are correctly specified. *Hint:* Consult the documentation for your specific packaging tool (e.g., `electron-builder`)."
      },
      {
        "step 3": "Update the project version number in `package.json` to reflect a release candidate build. Use a format like `X.Y.Z-rc.N` (e.g., `1.0.0-rc.1`). *Hint:* Follow Semantic Versioning (SemVer) conventions for pre-releases. Commit this version change to your version control system."
      },
      {
        "step 4": "Clean the project's build output directory (commonly named `dist` or `release`) by removing any existing files or subdirectories from previous builds. *Hint:* Use a command like `rm -rf dist`."
      },
      {
        "step 5": "Execute the build command defined in your project's `package.json` scripts (e.g., `npm run build:dist` or `yarn electron-builder --win --mac --linux`) to generate packages for all configured target platforms. *Hint:* Note that building packages for all platforms simultaneously might require specific host OS environments (e.g., macOS is required to build signed macOS packages) or a CI/CD pipeline (like GitHub Actions). If building locally, you may need to build for different platforms separately or only build for those supported by your current OS. Be aware that this build process can take a significant amount of time."
      },
      {
        "step 6": "After the build process completes, navigate to the build output directory (e.g., `dist`). List the contents and verify that the expected package files for the targeted platforms and formats (e.g., `.exe`, `.msi`, `.dmg`, `.zip`, `.AppImage`, `.deb`, `.rpm`) have been successfully generated."
      },
      {
        "step 7": "Create or update a markdown file (e.g., `BUILD_ARTIFACTS_RC.md`) in the project root or a `docs` folder. List all the generated release candidate package files, including their full names and relative paths within the build output directory. This list will be useful for testing and release notes."
      }
    ],
    "Task 6.5: Test installation, functionality, and uninstallation on target platforms": [
      {
        "step 1": "Identify the target operating systems (e.g., Windows 10/11, macOS Monterey/Ventura, Ubuntu 20.04/22.04 LTS) and the specific package/installer files generated in the previous packaging step (e.g., `ide_installer.exe`, `IDE.dmg`, `ide_amd64.deb`, `IDE.AppImage`) for each platform. List these pairings in a temporary file or internal state."
      },
      {
        "step 2": "Simulate or describe the process for testing the installation on Windows using the identified package (`.exe` or `.msi`). Execute the installer, follow the on-screen prompts (noting default installation paths and options), verify successful completion, check for the application's presence in the expected installation directory, and confirm the creation of shortcuts (Start Menu, Desktop if applicable). Document any errors, warnings, or unexpected behavior during this process in a structured format (e.g., a section in a `TESTING_REPORT.md` file)."
      },
      {
        "step 3": "Simulate or describe performing basic functionality tests on the installed Windows application. This includes: launching the IDE, creating a new simple project (e.g., a Python 'Hello World' script), opening the main source file, verifying basic syntax highlighting, editing the file (e.g., changing the output string), saving the file, attempting to run or build the project (verify expected output or build success/failure), and opening the settings/preferences dialog. Document any crashes, freezes, UI glitches, incorrect behavior, or error messages encountered in the testing report."
      },
      {
        "step 4": "Simulate or describe the process for testing the uninstallation on Windows. Use the standard Windows 'Add or remove programs' feature or any provided uninstaller executable. Follow the prompts, verify successful completion, and then check that the main application directory, shortcuts, and relevant Start Menu entries have been removed. *Hint:* Also check common user data locations like `%APPDATA%` or `%LOCALAPPDATA%` for leftover configuration files if applicable, and note if they remain. Document any errors during uninstallation or leftover artifacts in the testing report."
      },
      {
        "step 5": "Simulate or describe the process for testing the installation on macOS using the identified package (`.dmg`). Mount the DMG file, drag the application bundle (`.app`) to the `/Applications` folder, eject the DMG, and attempt to launch the application from `/Applications`. *Hint:* Check for any gatekeeper warnings or code signing issues if signing was implemented. Document any errors or unexpected behavior in the testing report."
      },
      {
        "step 6": "Simulate or describe performing the same basic functionality tests as detailed in 'step 3' (launch, create project, edit, save, run, settings) but on the installed macOS application. Document any macOS-specific issues (e.g., menu bar integration problems, file system access prompts, UI inconsistencies) in the testing report."
      },
      {
        "step 7": "Simulate or describe the process for testing the uninstallation on macOS. Drag the application bundle from the `/Applications` folder to the Trash and empty the Trash. Verify the `.app` bundle is removed. *Hint:* Check standard user data locations like `~/Library/Application Support/YourAppName` or `~/Library/Preferences/your.bundle.id.plist` for leftover files. Document any errors or leftover artifacts in the testing report."
      },
      {
        "step 8": "Simulate or describe the process for testing the installation on Linux using the identified package (e.g., `.deb`, `.rpm`, `.AppImage`, or `.tar.gz`). For `.deb`: `sudo dpkg -i package.deb && sudo apt-get install -f`. For `.rpm`: `sudo rpm -i package.rpm` or `sudo dnf install package.rpm`. For `.AppImage`: `chmod +x image.AppImage && ./image.AppImage`. For archives: `tar -xzf archive.tar.gz` and run the main executable. Verify the application can be launched (e.g., from the command line or application menu if a `.desktop` file was included). *Hint:* Pay attention to dependency errors during installation. Document any errors, warnings, or required manual steps in the testing report."
      },
      {
        "step 9": "Simulate or describe performing the same basic functionality tests as detailed in 'step 3' (launch, create project, edit, save, run, settings) but on the installed Linux application. Document any Linux-specific issues (e.g., file system permissions, theme integration problems, display server issues - X11/Wayland) in the testing report."
      },
      {
        "step 10": "Simulate or describe the process for testing the uninstallation on Linux. For `.deb`: `sudo apt remove package_name`. For `.rpm`: `sudo rpm -e package_name` or `sudo dnf remove package_name`. For `.AppImage`: Delete the file. For archives: Delete the extracted directory. Verify the application is removed. *Hint:* Check standard user data locations like `~/.config/YourAppName` or `~/.local/share/YourAppName` for leftover files. Document any errors or leftover artifacts in the testing report."
      },
      {
        "step 11": "Consolidate all documented findings from the installation, functionality, and uninstallation tests across Windows, macOS, and Linux into the `TESTING_REPORT.md` file. Structure the report clearly by platform and test type (Install, Functionality, Uninstall). For each issue found, provide a clear description, steps to reproduce (if possible), the expected behavior, and the actual behavior observed."
      }
    ],
    "Task 6.6: Write user documentation: Installation Guide": [
      {
        "step 1": "Analyze the project's packaging configuration (e.g., `setup.py`, `pyproject.toml`, `package.json`, `electron-builder.json`, `Dockerfile`, build scripts in `scripts/` or `Makefile`) established in Task 6.1 and subsequent build tasks. Identify the target operating systems (Windows, macOS, Linux) and the specific installation methods/artifacts produced (e.g., `.exe` installer, `.dmg` file, `.deb`/`.rpm` package, PyPI package, NPM package, Docker image, source distribution)."
      },
      {
        "step 2": "Based on the identified installation methods and target platforms, determine the prerequisites for each. Check dependency files (`requirements.txt`, `package.json`), build configurations, and potential runtime requirements (e.g., specific Python version, Node.js version, Git, Docker Desktop, C++ build tools). List these prerequisites clearly."
      },
      {
        "step 3": "Create a new file named `installation.md` within the `docs/` directory (create the directory if it doesn't exist). Use Markdown format for this guide. Add a main title (e.g., `# Installation Guide`) and a brief introductory paragraph explaining the purpose of the document."
      },
      {
        "step 4": "Structure the `installation.md` file with top-level sections for Prerequisites, followed by sections for each supported operating system (e.g., `## Windows`, `## macOS`, `## Linux`). If installation from source or via Docker is platform-independent, create separate top-level sections for those (e.g., `## Installing from Source`, `## Running with Docker`)."
      },
      {
        "step 5": "Populate the 'Prerequisites' section. List the general prerequisites identified in step 2, and mention any platform-specific ones if applicable. Hint: Link to official download pages for required tools like Python, Node.js, Git, or Docker where appropriate."
      },
      {
        "step 6": "For each supported operating system section (Windows, macOS, Linux), create subsections for the specific installation methods identified in step 1 (e.g., `### Using the Installer (.exe/.msi)`, `### Using the Disk Image (.dmg)`, `### Using the Debian Package (.deb)`). Write clear, step-by-step instructions for each method. Include: \n    - Where to download the artifact (use a placeholder like `[Download Link]` if the final URL isn't known yet).\n    - Exact commands to run (use Markdown code blocks ```bash ... ```).\n    - Screenshots or descriptions of GUI installer steps if applicable (use placeholder text like `[Screenshot: Installer Welcome Screen]`).\n    - Any post-installation configuration needed."
      },
      {
        "step 7": "If installation via a package manager (like `pip` or `npm`) is supported, add instructions under the relevant OS sections or in a general section. Include the exact installation command (e.g., `pip install your-ide-package`, `npm install -g your-ide-package`). Mention any virtual environment recommendations for `pip`."
      },
      {
        "step 8": "If installation from source is a supported method, populate the 'Installing from Source' section. Include steps for:\n    - Cloning the repository (e.g., `git clone [repository URL]`).\n    - Installing build-time and runtime dependencies (e.g., `pip install -r requirements-dev.txt`, `npm install`).\n    - Running the build process (referencing build scripts created earlier, e.g., `python setup.py install`, `npm run build`).\n    - How to run the IDE after building from source."
      },
      {
        "step 9": "If a Docker image is provided, populate the 'Running with Docker' section. Include steps for:\n    - Pulling the image from a registry (e.g., `docker pull your-dockerhub-username/your-ide:latest`).\n    - Running the container, including necessary volume mounts or port mappings (e.g., `docker run -v $(pwd):/workspace -p 8080:8080 your-dockerhub-username/your-ide:latest`). Mention how to access the IDE (e.g., via `localhost:8080`)."
      },
      {
        "step 10": "Add a new section named `## Verifying the Installation`. Provide simple steps users can take to confirm the IDE is installed and working correctly. This could involve running a command in the terminal (e.g., `your-ide --version`, `your-ide --help`) or locating and launching the application icon."
      },
      {
        "step 11": "Add a new section named `## Troubleshooting`. List a few common installation problems and their potential solutions (e.g., missing dependencies, PATH issues, permissions errors, firewall blocking network access if applicable). Base this on potential issues foreseen during prerequisite analysis and build process."
      },
      {
        "step 12": "Review the complete `docs/installation.md` file. Check for clarity, accuracy, consistency in terminology, correctness of commands, formatting (especially code blocks and links), and completeness based on the supported platforms and methods. Ensure the instructions accurately reflect the build artifacts and processes established in previous tasks."
      }
    ],
    "Task 6.7: Write user documentation: Getting Started Guide & Core Features": [
      {
        "step 1": "Analyze the project structure and identify the main entry point, configuration files, and core feature modules (e.g., file explorer, editor, build system integration, debugger, VCS). List these identified components."
      },
      {
        "step 2": "Create a directory named 'docs' in the project root if it doesn't exist. Inside 'docs', create two Markdown files: 'getting_started.md' and 'core_features.md'."
      },
      {
        "step 3": "In 'docs/getting_started.md', write the 'Installation' section. Detail the steps required to install the IDE. Include instructions for different potential methods (e.g., cloning the repository, using a package manager if applicable, running a setup script). Ensure prerequisites (e.g., specific Python version, system dependencies) are clearly listed. Hint: Refer to any existing setup scripts (e.g., `setup.py`, `install.sh`) or package manager configurations (`requirements.txt`, `pyproject.toml`)."
      },
      {
        "step 4": "Append the 'Configuration' section to 'docs/getting_started.md'. Explain any necessary initial configuration steps after installation. Describe configuration files (location, format - e.g., JSON, INI), environment variables, or settings within the IDE interface itself. Provide examples for common configuration options (e.g., setting project paths, configuring external tools like compilers or debuggers). Hint: Check the codebase for modules handling configuration loading or settings management."
      },
      {
        "step 5": "Append the 'Running the IDE' section to 'docs/getting_started.md'. Describe how to launch the IDE from the command line or via an executable. Briefly explain the main components of the initial user interface (e.g., main window layout, menu bar, status bar, default panels like file explorer or editor). Add a placeholder like '<!-- Add screenshot of initial IDE window here -->' where a visual aid would be beneficial."
      },
      {
        "step 6": "In 'docs/core_features.md', write an introductory paragraph summarizing the main capabilities of the IDE. Then, create level 2 headings (##) for each core feature identified in Step 1 (e.g., 'File Explorer', 'Code Editor', 'Build & Run', 'Debugger', 'Version Control')."
      },
      {
        "step 7": "Under the 'File Explorer' heading in 'docs/core_features.md', describe how users can browse directories, open files, create new files/directories, rename, and delete items. Mention any specific UI elements or keyboard shortcuts related to the file explorer. Hint: Examine the source code related to the file tree widget or file operations."
      },
      {
        "step 8": "Under the 'Code Editor' heading in 'docs/core_features.md', detail the editor's functionalities. Include information on syntax highlighting (supported languages), code completion (how it's triggered, scope), find/replace functionality, code folding, line numbers, and any other significant editing features implemented. Add placeholders like '<!-- Add screenshot of editor with syntax highlighting here -->' where appropriate. Hint: Review the code implementing the text editor widget and associated features like language servers or lexers."
      },
      {
        "step 9": "Under the 'Build & Run' heading in 'docs/core_features.md', explain how users can configure build commands, trigger builds, run their projects, and view output/errors. Describe relevant UI elements (e.g., buttons, output panels, configuration dialogs). Hint: Check the code related to process execution, project settings, and output panels."
      },
      {
        "step 10": "Under the 'Debugger' heading in 'docs/core_features.md', describe the debugging capabilities. Explain how to set/remove breakpoints, start a debugging session, step through code (step over, step into, step out), inspect variables, and view the call stack. Mention any supported debug protocols (e.g., DAP) or specific debugger integrations. Hint: Analyze the debugger integration module and UI components."
      },
      {
        "step 11": "Under the 'Version Control' heading in 'docs/core_features.md', document the integration with version control systems (likely Git). Explain how users can view file status (modified, staged), stage changes, commit changes, view diffs, and potentially pull/push. Hint: Look for code interacting with Git commands or libraries like `gitpython`."
      },
      {
        "step 12": "Create or update the main `README.md` file in the project root. Include a brief description of the IDE, a link to the 'Getting Started' guide (`docs/getting_started.md`), and a link to the 'Core Features' guide (`docs/core_features.md`). Ensure basic project information (like license, contribution guidelines if available) is present or linked."
      },
      {
        "step 13": "Review all created/updated Markdown files ('README.md', 'docs/getting_started.md', 'docs/core_features.md') for clarity, consistency, and grammatical errors. Ensure formatting is correct Markdown. Hint: Consider using a Markdown linter (like `markdownlint-cli`) if available in the environment to check for formatting issues. Add cross-links between sections where relevant (e.g., link from the editor section to the debugger section if breakpoints are set in the editor)."
      }
    ],
    "Task 6.8: Write user documentation: Configuration & Customization": [
      {
        "step 1": "Analyze the IDE's codebase (specifically configuration modules, settings UI components, key binding handlers, theme managers, plugin systems if implemented) to identify all user-configurable aspects. List these aspects along with their configuration methods (e.g., JSON config file `settings.json`, specific UI panel, environment variables)."
      },
      {
        "step 2": "Create a new Markdown file named `configuration.md` within the `docs/user_guide/` directory (or the established documentation structure). Create an outline for this document including sections like: Introduction, Configuration Files, Settings UI (if applicable), Key Bindings, Appearance Customization (Themes, Fonts), Editor Settings, Language-Specific Settings, Plugin/Extension Management (if applicable), Project Settings, and Examples."
      },
      {
        "step 3": "Write the 'Introduction' section, briefly explaining the importance of configuration and the different ways settings can be adjusted in the IDE."
      },
      {
        "step 4": "Write the 'Configuration Files' section. Detail the location (default path, how users can find it), format (e.g., JSON, YAML), and overall structure of the main configuration file(s). Provide a documented example snippet showing common settings and their expected values/types. Explain the precedence if multiple configuration files exist (e.g., user vs. default)."
      },
      {
        "step 5": "If a graphical settings UI exists, write the 'Settings UI' section. Describe how to access the settings panel and navigate its different sections. Include screenshots or descriptions of key UI elements related to configuration."
      },
      {
        "step 6": "Write the 'Key Bindings' section. Explain how users can view the default key bindings, how to customize existing ones, and how to add new custom key bindings. Specify the format for defining key bindings in the configuration file or UI. Provide clear examples (e.g., changing the 'Save' shortcut, adding a shortcut for a custom command)."
      },
      {
        "step 7": "Write the 'Appearance Customization' section. Explain how to change the color theme (e.g., light/dark modes, specific theme names), UI fonts, editor fonts, font sizes, and any other relevant visual settings. Reference the corresponding configuration keys or UI options."
      },
      {
        "step 8": "Write the 'Editor Settings' section. Document common editor configurations such as indentation style (tabs/spaces), tab width, enabling/disabling line numbers, word wrap, auto-save options, bracket matching, etc. Show how to configure these via file or UI."
      },
      {
        "step 9": "Write the 'Language-Specific Settings' section. Explain how users can configure settings that apply only to specific programming languages, such as paths to linters/formatters, build commands, debugger configurations, or language server settings. Show the structure for defining these language-specific overrides in the configuration."
      },
      {
        "step 10": "If the IDE has a plugin/extension system, write the 'Plugin/Extension Management' section. Explain how to find, install, enable/disable, update, and remove plugins. Also, describe how to configure individual plugins if they expose settings."
      },
      {
        "step 11": "Write the 'Project Settings' section. Explain if and how users can define project-specific settings (e.g., via a `.ide_settings` file in the project root) that override global configurations. Describe the mechanism and precedence rules."
      },
      {
        "step 12": "Add an 'Examples' section or integrate practical examples throughout the relevant sections. Include snippets demonstrating common customization tasks like setting up a Python linter, changing the theme and font size, or creating a custom key binding."
      },
      {
        "step 13": "Review the entire `configuration.md` document for clarity, accuracy, completeness, and consistency with the actual IDE behavior and other documentation sections. Ensure code examples are correct and formatting is clean. Add cross-references to other relevant documentation pages if necessary."
      }
    ],
    "Task 6.9: Write developer documentation: Contribution Guidelines & Code Structure": [
      {
        "step 1": "Create a new file named `CONTRIBUTING.md` in the root directory of the project."
      },
      {
        "step 2": "Define the main sections for `CONTRIBUTING.md`. Include placeholders for: Introduction (briefly welcoming contributors), Code of Conduct (linking to `CODE_OF_CONDUCT.md` if it exists), How to Contribute, Reporting Bugs, Suggesting Enhancements, Your First Code Contribution (optional, guidance for beginners), Setting Up Development Environment, Code Style Guide, Pull Request Process, and License (referencing the `LICENSE` file)."
      },
      {
        "step 3": "Draft the 'Introduction' and 'Code of Conduct' sections in `CONTRIBUTING.md`. Ensure the Code of Conduct section links to the `CODE_OF_CONDUCT.md` file (if available)."
      },
      {
        "step 4": "Draft the 'How to Contribute' section. Describe the typical workflow: Fork the repository, create a new branch for your feature/fix (e.g., `git checkout -b feature/amazing-feature` or `fix/bug-fix`), make changes, run tests, commit changes, push the branch, and open a Pull Request. *Hint: Mention that PRs should target the main development branch (e.g., `main` or `develop`).*"
      },
      {
        "step 5": "Draft the 'Reporting Bugs' section. Specify that bugs should be reported via GitHub Issues. Detail the information required in a bug report: clear title, description, steps to reproduce, expected behavior, actual behavior, IDE version, OS, and any relevant logs or screenshots. *Hint: Consider suggesting the use of a bug report issue template if one exists or will be created.*"
      },
      {
        "step 6": "Draft the 'Suggesting Enhancements' section. Specify that enhancement suggestions should also be made via GitHub Issues. Guide users to provide context, motivation, and detailed descriptions of the proposed feature or improvement. *Hint: Consider suggesting the use of a feature request issue template.*"
      },
      {
        "step 7": "Draft the 'Setting Up Development Environment' section. Briefly describe the steps needed to get the project running locally for development. Include prerequisites (e.g., specific Node.js/Python version, package managers like npm/pip), commands for installing dependencies, and any build or compilation steps. *Hint: Link to more detailed setup instructions if they exist elsewhere (e.g., in the main `README.md` or a dedicated setup guide).* "
      },
      {
        "step 8": "Draft the 'Code Style Guide' section. Specify the primary programming languages used and the corresponding style guides (e.g., PEP 8 for Python, standard JavaScript style, etc.). Mention any linters or formatters configured in the project (e.g., Black, Flake8, ESLint, Prettier) and how contributors should use them (e.g., pre-commit hooks, manual commands). *Hint: Analyze project configuration files (like `pyproject.toml`, `.eslintrc.js`, `.prettierrc`) to identify configured tools.*"
      },
      {
        "step 9": "Draft the 'Pull Request Process' section. Detail the requirements for submitting a PR: ensure code builds and tests pass (`npm test` or `pytest`), update documentation if necessary, write clear commit messages, ensure the PR has a descriptive title and description. Mention the code review process and that contributors should address feedback. *Hint: Reference the PR template if one exists.*"
      },
      {
        "step 10": "Create a directory named `docs` in the project root if it doesn't already exist."
      },
      {
        "step 11": "Create a new file named `code_structure.md` inside the `docs` directory."
      },
      {
        "step 12": "Outline the main sections for `docs/code_structure.md`. Include placeholders for: High-Level Overview, Main Directories/Modules, UI Components (if applicable), Backend/Core Logic, Language Server Integration (if applicable), Plugin System (if applicable), Testing Structure, and Key Dependencies."
      },
      {
        "step 13": "Draft the 'High-Level Overview' section in `docs/code_structure.md`. Describe the overall architecture (e.g., Monolith, Microservices, MVC, MVVM, event-driven) and the core technologies/frameworks used (e.g., Electron, Python, TypeScript, React, Qt)."
      },
      {
        "step 14": "Analyze the project's source code directory structure (e.g., `src`, `app`, `core`, `packages`). Draft the 'Main Directories/Modules' section, listing key directories and briefly explaining the purpose and contents of each one. *Hint: Focus on top-level directories within the primary source code folder.*"
      },
      {
        "step 15": "If the IDE has a distinct UI layer, draft the 'UI Components' section. Describe where UI code resides, the UI framework used (e.g., React, Vue, HTML/CSS, Tkinter, Qt), and how components are organized."
      },
      {
        "step 16": "Draft the 'Backend/Core Logic' section. Describe the non-UI parts of the IDE, such as file system interaction, core editor logic, process management, settings management, etc. Identify the main modules responsible for these functions."
      },
      {
        "step 17": "If applicable, draft sections describing the 'Language Server Integration' and/or 'Plugin System' architecture. Explain how these systems are integrated and where the relevant code can be found."
      },
      {
        "step 18": "Draft the 'Testing Structure' section. Explain where tests are located (e.g., `tests/`, `__tests__/`), how they are organized (e.g., by module, by type: unit/integration/e2e), and the testing frameworks/tools used (e.g., `pytest`, `jest`, `unittest`, `Cypress`). Include the command(s) to run tests."
      },
      {
        "step 19": "Review both `CONTRIBUTING.md` and `docs/code_structure.md` for clarity, accuracy, completeness, and consistent formatting. Ensure all placeholders are filled and links (like to the Code of Conduct or License) are correct."
      },
      {
        "step 20": "Add a link within `CONTRIBUTING.md` (perhaps in the 'How to Contribute' or 'Your First Code Contribution' section) pointing developers to `docs/code_structure.md` for help understanding the codebase."
      }
    ],
    "Task 6.10: Set up documentation hosting (e.g., GitHub Pages, ReadTheDocs)": [
      {
        "step 1": "Verify the documentation build process. Confirm that running the documentation generation command (e.g., `sphinx-build -b html docs/source docs/_build/html`, adjust paths as necessary based on project structure established in Task 6.9) successfully creates HTML output in the expected build directory (e.g., `docs/_build/html`). If the build fails or the directory is missing, troubleshoot the documentation generation setup before proceeding."
      },
      {
        "step 2": "Choose GitHub Pages as the hosting platform. We will configure deployment using GitHub Actions. Create the necessary directory structure for the workflow file: `.github/workflows/`."
      },
      {
        "step 3": "Create a new workflow file named `docs-deploy.yml` inside the `.github/workflows/` directory. Define the trigger conditions: activate the workflow on pushes to the `main` branch."
      },
      {
        "step 4": "Define the `build` job within `docs-deploy.yml`. This job should: \n1. Check out the repository code using `actions/checkout@v4`.\n2. Set up the appropriate Python version using `actions/setup-python@v4`.\n3. Install project dependencies, including documentation tools (e.g., Sphinx, theme). Hint: Use the `requirements-docs.txt` file created previously if available, otherwise list necessary packages like `sphinx`, `sphinx-rtd-theme` etc.\n4. Execute the documentation build command identified in Step 1 (e.g., `sphinx-build -b html docs/source docs/_build/html`). Ensure the output path matches expectations."
      },
      {
        "step 5": "Add a step to the `build` job in `docs-deploy.yml` to upload the generated HTML documentation as a build artifact. Use the `actions/upload-pages-artifact@v2` action. Configure the `path` parameter to point to the directory containing the built HTML files (e.g., `docs/_build/html`)."
      },
      {
        "step 6": "Define a `deploy` job in `docs-deploy.yml` that runs after the `build` job (`needs: build`). Configure this job to run on the `ubuntu-latest` environment. Set the necessary permissions for deployment: `permissions: pages: write id-token: write`."
      },
      {
        "step 7": "Configure the `deploy` job steps. \n1. Add a step to download the artifact uploaded by the `build` job (this is implicitly handled by `deploy-pages` but good to be aware of). \n2. Use the `actions/deploy-pages@v3` action to deploy the artifact to GitHub Pages."
      },
      {
        "step 8": "Add instructions for the user (as comments in the code or in a separate setup note) on how to configure the GitHub repository settings. The user needs to navigate to 'Settings' > 'Pages' and set the 'Build and deployment' source to 'GitHub Actions'. This step typically requires manual intervention in the GitHub UI."
      },
      {
        "step 9": "Update the main `README.md` file. Add a 'Documentation' section that includes a link to the hosted documentation site. The URL format is typically `https://<username>.github.io/<repository-name>/` or `https://<orgname>.github.io/<repository-name>/`. Add a placeholder note that the exact URL should be confirmed after the first successful deployment."
      },
      {
        "step 10": "Enhance the `README.md` by adding a GitHub Actions status badge for the `docs-deploy.yml` workflow. You can generate the Markdown for the badge from the 'Actions' tab in the GitHub repository after the workflow has run at least once, or use the standard format: `[![Docs CI/CD](https://github.com/<username>/<repository-name>/actions/workflows/docs-deploy.yml/badge.svg)](https://github.com/<username>/<repository-name>/actions/workflows/docs-deploy.yml)`. Replace placeholders accordingly."
      },
      {
        "step 11": "Commit the new workflow file (`.github/workflows/docs-deploy.yml`) and the updated `README.md` to the repository. Push the changes to the `main` branch to trigger the first documentation deployment workflow."
      }
    ],
    "Task 6.11: Finalize versioning scheme and write release notes (changelog)": [
      {
        "step 1": "Review the project's current versioning approach. If no formal scheme is defined, adopt Semantic Versioning (SemVer - MAJOR.MINOR.PATCH). Determine the appropriate next version number (e.g., `1.0.0` for the first release, or increment based on changes since the last tag following SemVer rules: MAJOR for incompatible API changes, MINOR for backward-compatible features, PATCH for backward-compatible bug fixes). Store this decided version number for subsequent steps."
      },
      {
        "step 2": "Gather all significant changes made since the last release tag or the beginning of the project if this is the first release. Hint: Use `git log --oneline <last_tag>..HEAD` or `git log --oneline` if no tags exist. Analyze commit messages, linked issues, and pull requests to identify new features, bug fixes, performance improvements, refactorings, and any breaking changes."
      },
      {
        "step 3": "Locate or create a `CHANGELOG.md` file in the project's root directory. Ensure it follows the 'Keep a Changelog' format (refer to keepachangelog.com). If creating the file, add the basic structure including the 'Unreleased' section template."
      },
      {
        "step 4": "Draft the release notes for the new version determined in Step 1 within the `CHANGELOG.md` file. Move relevant changes gathered in Step 2 from the 'Unreleased' section (or directly add them) into a new version section (e.g., `## [1.0.0] - YYYY-MM-DD`). Categorize changes under headings like `Added`, `Changed`, `Fixed`, `Removed`, `Deprecated`, `Security`. Write clear, concise descriptions for each change, referencing issue numbers if applicable. Clearly document any breaking changes."
      },
      {
        "step 5": "Search the codebase for all files where the project's version number is defined or used. Update the version number in these files to the new version decided in Step 1. Hint: Common locations include `package.json`, `pyproject.toml`, `setup.py`, `__init__.py`, configuration files, build scripts, and potentially UI elements like an 'About' dialog."
      },
      {
        "step 6": "Stage the updated `CHANGELOG.md` file and all other files modified in Step 5 using `git add`. Commit these changes with a descriptive message. Hint: Use a message like 'chore: Finalize version X.Y.Z and update changelog'."
      }
    ],
    "Task 6.12: Create final release build/tag in version control": [
      {
        "step 1": "Ensure you are on the main branch and it is fully up-to-date with the remote repository. Verify there are no uncommitted changes. Hint: Use `git checkout main` (or `master`), `git pull origin main`, and `git status` to confirm."
      },
      {
        "step 2": "Identify the definitive final version number for this release (e.g., `v1.0.0`). Hint: Check project configuration files like `package.json`, `pyproject.toml`, `setup.py`, a dedicated `VERSION` file, or build scripts where the version was likely set in previous steps (like Task 6.1 or 6.2)."
      },
      {
        "step 3": "Create an annotated Git tag for the confirmed version number. The tag message should clearly indicate this is a release and optionally include a brief summary. Hint: Use `git tag -a v<version_number> -m \"Release v<version_number>: <Brief summary of the release>\". You can source the summary from the `CHANGELOG.md` file created earlier."
      },
      {
        "step 4": "Push the newly created annotated tag to the remote repository (`origin`). Hint: Use `git push origin v<version_number>`."
      },
      {
        "step 5": "Verify that the tag has been successfully pushed to the remote repository. Hint: You can check the project's repository page on the hosting platform (e.g., GitHub, GitLab) or use `git ls-remote --tags origin`."
      },
      {
        "step 6": "Prepare the necessary information for creating a formal release on the code hosting platform (e.g., GitHub Releases, GitLab Releases). Locate the final `CHANGELOG.md` or release notes file and identify the paths to any distributable artifacts (installers, binaries, archives) generated during the build process (Task 6.11). Hint: This step gathers information. Creating the actual platform release might be a manual action or require subsequent steps using platform-specific APIs/CLIs, depending on available tools and permissions."
      }
    ],
    "Task 6.13: Build final, signed release packages/installers": [
      {
        "step 1": "Review the project's build configuration files (e.g., `package.json` for Electron Builder, `pyinstaller.spec`, custom build scripts) to confirm the packaging tools being used and identify any existing configurations related to code signing for Windows, macOS, and Linux."
      },
      {
        "step 2": "Configure the build process for Windows code signing. Ensure the necessary environment variables or configuration settings are securely set for the release build, pointing to the code signing certificate (e.g., `CSC_LINK` for Electron Builder or equivalent) and its password (e.g., `CSC_KEY_PASSWORD`). Also, verify the timestamp server URL configuration if applicable. Hint: Prefer using environment variables or a secure secrets management system for sensitive information like passwords."
      },
      {
        "step 3": "Configure the build process for macOS code signing and notarization. Ensure the necessary environment variables or configuration settings are securely set, including the Apple Developer ID certificate name (e.g., `CSC_NAME`), Apple ID (`APPLE_ID`), app-specific password (`APPLE_ID_PASSWORD`), and Team ID (`APPLE_TEAM_ID` - often needed for notarization). Hint: Ensure the signing certificate is available in the keychain on the build machine if required by the tooling. Use secure methods for credentials."
      },
      {
        "step 4": "Determine if Linux package signing (e.g., GPG signing for `.deb` or `.rpm` packages) is required based on previous decisions or project standards. If yes, configure the build process to use the appropriate GPG key ID and passphrase, potentially involving tools like `dpkg-sig`, `rpmsign`, or specific options within your packaging tool (like Electron Builder's `linux.sign`). Hint: Securely provide the GPG passphrase during the build, possibly via environment variables or a GPG agent."
      },
      {
        "step 5": "Identify and execute the specific command(s) required to create the final *release* build, ensuring that code signing (and notarization for macOS) is explicitly enabled. Target all desired platforms (e.g., Windows, macOS, Linux specified via flags like `--win --mac --linux` or similar). Hint: Look for flags like `--publish never` or specific release profiles in your build tool documentation to prevent accidental publishing. Ensure the build environment has access to all necessary certificates and credentials configured in previous steps."
      },
      {
        "step 6": "After the build completes, locate the generated Windows installer/package (e.g., `.exe`, `.msi`). Verify its code signature using appropriate tools. Hint: On Windows, you can use `signtool verify /pa /v <path_to_installer>` (from the Windows SDK) or check the 'Digital Signatures' tab in the file's properties."
      },
      {
        "step 7": "Locate the generated macOS application bundle (`.app`) or disk image (`.dmg`). Verify its code signature and notarization status. Hint: On macOS, use `codesign --verify --deep --strict --verbose=2 /path/to/YourApp.app` to check the signature and `spctl --assess --type execute /path/to/YourApp.app` (or the `.dmg`) to check Gatekeeper acceptance (which implies notarization if required)."
      },
      {
        "step 8": "If Linux package signing was performed, locate the generated packages (e.g., `.deb`, `.rpm`). Verify their signatures using the appropriate tools. Hint: Use `dpkg-sig --verify <package>.deb` for Debian packages or `rpm --checksig <package>.rpm` for RPM packages."
      },
      {
        "step 9": "Identify the output directory containing all the verified, signed release artifacts (installers, packages, application bundles). Consolidate these artifacts and prepare them for distribution, potentially by copying them to a designated, secure 'release' directory or uploading them to a secure storage location."
      }
    ],
    "Task 6.14: Set up release distribution channel (e.g., GitHub Releases, website downloads)": [
      {
        "step 1": "Identify and list the paths to all packaged application artifacts (e.g., installers like `.exe`, `.dmg`, `.deb`; archives like `.zip`, `.tar.gz`) generated in previous packaging steps (Tasks 6.1-6.5). These artifacts will be uploaded as release assets."
      },
      {
        "step 2": "Create a new GitHub Actions workflow file at `.github/workflows/release.yml` or modify an existing CI/CD workflow file. Configure this workflow to trigger automatically when a new tag matching a version pattern (e.g., `v*.*.*`) is pushed to the repository. Hint: Use the `on.push.tags` event trigger."
      },
      {
        "step 3": "Within the release workflow, define a job named `create_release`. Add steps to: \n1. Check out the code (`actions/checkout`). \n2. (Optional, if build/package isn't done elsewhere) Set up the necessary build environment (Node.js, Python, etc.) and run the build and packaging commands to generate the release artifacts identified in Step 1. \n3. Use a GitHub Action like `actions/create-release@v1` to create a new draft release associated with the pushed tag. Configure its `tag_name`, `release_name`, `body` (potentially sourcing from `CHANGELOG.md` or commit messages), `draft: true`, and `prerelease: false` inputs. Hint: Use `${{ github.ref }}` for the tag name."
      },
      {
        "step 4": "Add subsequent steps within the `create_release` job to upload each build artifact (identified in Step 1) to the newly created release. Use an action like `actions/upload-release-asset@v1`. For each artifact, configure the `upload_url` (using the output from the `create-release` step), `asset_path` (path to the artifact file), `asset_name` (desired name on the release page, e.g., `my-ide-windows-x64.exe`), and `asset_content_type`. Hint: You might need multiple upload steps or use glob patterns if artifact names are consistent."
      },
      {
        "step 5": "Refine the release notes generation for the `actions/create-release` step. If a `CHANGELOG.md` file is maintained (Task 6.13), investigate methods to automatically extract the relevant section for the current tag and use it as the release body. Alternatively, configure it to generate notes based on commit messages between the current and previous tag. Hint: Search for GitHub Actions or tools that automate changelog extraction for releases."
      },
      {
        "step 6": "Create a temporary, non-production tag (e.g., `v0.0.0-test`) and push it to the GitHub repository (`git tag v0.0.0-test && git push origin v0.0.0-test`). Monitor the execution of the `release.yml` workflow in the GitHub Actions tab. Verify that it successfully creates a draft release, uploads all expected assets, and includes appropriate release notes. Delete the test tag and the draft release from GitHub afterwards (`git tag -d v0.0.0-test && git push --delete origin v0.0.0-test`)."
      },
      {
        "step 7": "Update the main `README.md` file. Add a 'Downloads' or 'Releases' section that clearly links to the project's GitHub Releases page (e.g., `https://github.com/your-username/your-repo/releases`). Explain briefly that users can find pre-built versions there."
      },
      {
        "step 8": "As an alternative or fallback, create a document named `docs/MANUAL_RELEASE_PROCESS.md`. Detail the manual steps required to create a release on GitHub: navigating to the Releases page, drafting a new release, selecting the tag, titling the release, writing/pasting release notes, manually uploading the packaged artifacts, and publishing the release. This ensures a release can be made even if the automation fails."
      }
    ],
    "Task 6.15: Upload release artifacts to distribution channel": [
      {
        "step 1": "Identify the target distribution channel for the release artifacts. Common choices include GitHub Releases, a dedicated download server, or platform-specific app stores. If not specified previously, assume GitHub Releases for the project's repository. Confirm the repository URL and the specific Git tag corresponding to this release (e.g., 'v1.0.0')."
      },
      {
        "step 2": "Locate the release artifact files generated in the previous task (Task 6.14). These might include installers (.exe, .dmg, .deb, .rpm), executables, compressed archives (.zip, .tar.gz), and potentially source code archives. List the full paths to all files intended for upload."
      },
      {
        "step 3": "Prepare for authentication with the chosen distribution channel (assuming GitHub Releases). Ensure you have the necessary credentials (e.g., a GitHub Personal Access Token with 'repo' scope). Hint: Use secure methods like environment variables (e.g., `GITHUB_TOKEN`) or a credential manager. Avoid hardcoding secrets. Consider using the official GitHub CLI tool (`gh`) for easier authentication and interaction. If `gh` is not installed, prompt for installation or use appropriate API calls with libraries like `requests` or a GitHub client library."
      },
      {
        "step 4": "Create a *draft* release entry on the distribution platform (e.g., GitHub Releases). Use the Git tag identified in Step 1. Set a clear release title (e.g., 'IDE Version X.Y.Z'). Populate the release description by summarizing the key changes, features, and bug fixes for this version. Hint: Refer to the 'CHANGELOG.md' file (created in Task 6.13) to generate this description. Use the `gh release create` command with the `--draft` flag if using the GitHub CLI, or the relevant API endpoint."
      },
      {
        "step 5": "Upload each release artifact file identified in Step 2 to the draft release entry created in Step 4. Iterate through the list of artifact paths and upload them one by one. Hint: If using the GitHub CLI, use the `gh release upload <tag> <file_path>` command for each artifact. If using APIs, make sure to handle potential upload errors and retries."
      },
      {
        "step 6": "Review the draft release on the platform (e.g., GitHub Releases page). Verify that the tag, title, description, and all intended artifacts are present and correct. Make any necessary edits to the draft release information."
      },
      {
        "step 7": "Publish the release. Transition the release entry from a draft state to a published state, making it publicly visible. Hint: If using the GitHub CLI, use `gh release edit <tag> --draft=false`. If using the API, update the 'draft' status of the release object."
      },
      {
        "step 8": "Verify the successful publication. Access the public release page URL and confirm that the release is visible and that all artifacts are listed and downloadable. Optionally, attempt to download one or two artifacts to ensure they are accessible and uncorrupted."
      }
    ],
    "Task 6.16: Announce the release (website, blog post, social media)": [
      {
        "step 1": "Analyze the project's recent changes (referencing `CHANGELOG.md`, commit history, and previous task outputs) to identify the key features, improvements, and bug fixes included in the new release (assume version v1.0.0 for this initial major release unless specified otherwise). Define the target audience, the primary call to action (e.g., link to download page, documentation), and the core message for the announcement. List any available visual assets (screenshots, GIFs created in previous steps) relevant to the new features. Store this plan in a temporary file (e.g., `announcement_plan.txt`)."
      },
      {
        "step 2": "Locate the project's website source files. Draft concise announcement text for the website's homepage or news section based on the `announcement_plan.txt`. Include the release version, highlight 1-2 key features, and provide the main call-to-action link. If visual assets are available and appropriate, incorporate one. Update the relevant HTML/Markdown file(s) in the website source directory with this announcement content. Hint: Ensure the changes integrate cleanly with the existing website structure and styling."
      },
      {
        "step 3": "Create a new file for the release blog post (e.g., `docs/blog/posts/YYYY-MM-DD-release-v1.0.0.md` or similar, depending on the established blog structure). Write a detailed blog post based on `announcement_plan.txt`. Structure the post with sections for Introduction, Key Features (elaborate with details/examples), Notable Bug Fixes, Getting Started/Upgrading instructions, Future Plans (optional), Acknowledgements (if applicable), and a clear Call to Action. Format the post using Markdown. Incorporate relevant visual assets where they add value. Hint: Reference `CHANGELOG.md` for accuracy. Aim for an engaging and informative tone."
      },
      {
        "step 4": "Draft social media announcement posts based on the `announcement_plan.txt` and the blog post content. Create variations tailored for: \n1. Twitter: Short, impactful message (~280 chars), highlight one key feature, include the link to the blog post or website, use relevant hashtags (e.g., #IDE #DevTools #[ProjectName] #NewRelease), and mention including a visual.\n2. LinkedIn: Slightly more formal tone, focus on developer productivity/benefits, include the link, and mention including a visual.\n3. Reddit: Identify 2-3 relevant subreddits (e.g., r/programming, r/opensource, language-specific ones). Draft a post suitable for Reddit, often a brief summary linking to the blog post, adhering to potential subreddit rules (which you should assume based on common practices). \nSave these drafts in a file named `social_media_drafts.txt`."
      },
      {
        "step 5": "Review the generated website update code, the blog post file (`YYYY-MM-DD-release-v1.0.0.md`), and the `social_media_drafts.txt` for accuracy, clarity, grammar, spelling, and functional links. Ensure consistency in messaging across all platforms. Commit the updated website files and the new blog post file to the project repository with a descriptive commit message (e.g., 'docs: Add website and blog announcement for v1.0.0 release'). Add a note in `social_media_drafts.txt` indicating that the posts are ready for manual publishing on the respective platforms."
      }
    ],
    "Task 6.17: Establish public feedback and bug reporting mechanism (e.g., Issue Tracker)": [
      {
        "step 1": "Determine the primary code hosting platform (e.g., GitHub, GitLab) and repository URL for the IDE project. This information is crucial for setting up the issue tracker correctly. Store this URL for subsequent steps."
      },
      {
        "step 2": "Create a directory structure `.github/ISSUE_TEMPLATE` in the project's root directory if it doesn't already exist. This directory will hold the templates for bug reports and feature requests."
      },
      {
        "step 3": "Create a Markdown file named `BUG_REPORT.md` inside the `.github/ISSUE_TEMPLATE` directory. Populate this file with a structured template for users reporting bugs. \n**Hint:** Include sections like 'Describe the bug', 'Steps to Reproduce', 'Expected behavior', 'Actual behavior', 'Screenshots (Optional)', 'Environment (please complete the following information)', 'Additional context'. Use Markdown comments (`<!-- ... -->`) to guide the user filling out the template. Search the web for examples of effective GitHub bug report templates."
      },
      {
        "step 4": "Create a Markdown file named `FEATURE_REQUEST.md` inside the `.github/ISSUE_TEMPLATE` directory. Populate this file with a structured template for users requesting new features.\n**Hint:** Include sections like 'Is your feature request related to a problem?', 'Describe the solution you'd like', 'Describe alternatives you've considered', 'Additional context'. Use Markdown comments (`<!-- ... -->`) for guidance. Search the web for examples of good feature request templates."
      },
      {
        "step 5": "Create or update the `CONTRIBUTING.md` file in the project root directory. Add a dedicated section explaining how users should report bugs or suggest features. \n**Hint:** Reference the new issue templates (bug report, feature request). Explain the importance of providing clear details. Include a direct link to the repository's 'Issues' tab (use the URL identified in Step 1). Mention checking for existing issues before creating a new one."
      },
      {
        "step 6": "Update the main `README.md` file. Add a 'Contributing' or 'Feedback & Issues' section. \n**Hint:** Briefly explain that contributions and feedback are welcome. Include links to the `CONTRIBUTING.md` file and directly to the repository's 'Issues' tab for convenience."
      },
      {
        "step 7": "Create a new Markdown file, perhaps in a `docs/` directory (e.g., `docs/ISSUE_LABELS.md`), or add a section to `CONTRIBUTING.md`, documenting a proposed initial set of issue labels and their intended use. \n**Hint:** Suggest labels like `bug`, `enhancement`, `documentation`, `question`, `help-wanted`, `good-first-issue`. Explain what each label signifies. This guides maintainers and contributors."
      },
      {
        "step 8": "Verify if a `CODE_OF_CONDUCT.md` file exists in the root directory or `.github/` directory. If not, create one. \n**Hint:** Use a standard template like the Contributor Covenant (search the web for 'Contributor Covenant template'). Ensure `CONTRIBUTING.md` and `README.md` link to this file."
      },
      {
        "step 9": "Review all the files created or modified in the previous steps (`.github/ISSUE_TEMPLATE/BUG_REPORT.md`, `.github/ISSUE_TEMPLATE/FEATURE_REQUEST.md`, `CONTRIBUTING.md`, `README.md`, `docs/ISSUE_LABELS.md`, `CODE_OF_CONDUCT.md`) for clarity, correctness, and proper Markdown formatting."
      },
      {
        "step 10": "Commit all the newly created and modified files related to the issue tracking setup and contribution guidelines to the version control system with a descriptive commit message (e.g., 'feat: Add issue templates and contributing guidelines')."
      }
    ]
  }
}